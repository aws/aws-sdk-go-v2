// Code generated by smithy-go-codegen DO NOT EDIT.

package types

import (
	"time"
)

// Specifies the training algorithm to use in a CreateTrainingJob () request. For
// more information about algorithms provided by Amazon SageMaker, see Algorithms
// (https://docs.aws.amazon.com/sagemaker/latest/dg/algos.html). For information
// about using your own algorithms, see Using Your Own Algorithms with Amazon
// SageMaker
// (https://docs.aws.amazon.com/sagemaker/latest/dg/your-algorithms.html).
type AlgorithmSpecification struct {
	// The input mode that the algorithm supports. For the input modes that Amazon
	// SageMaker algorithms support, see Algorithms
	// (https://docs.aws.amazon.com/sagemaker/latest/dg/algos.html). If an algorithm
	// supports the File input mode, Amazon SageMaker downloads the training data from
	// S3 to the provisioned ML storage Volume, and mounts the directory to docker
	// volume for training container. If an algorithm supports the Pipe input mode,
	// Amazon SageMaker streams data directly from S3 to the container. In File mode,
	// make sure you provision ML storage volume with sufficient capacity to
	// accommodate the data download from S3. In addition to the training data, the ML
	// storage volume also stores the output model. The algorithm container use ML
	// storage volume to also store intermediate information, if any. For distributed
	// algorithms using File mode, training data is distributed uniformly, and your
	// training duration is predictable if the input data objects size is approximately
	// same. Amazon SageMaker does not split the files any further for model training.
	// If the object sizes are skewed, training won't be optimal as the data
	// distribution is also skewed where one host in a training cluster is overloaded,
	// thus becoming bottleneck in training.
	TrainingInputMode TrainingInputMode
	// To generate and save time-series metrics during training, set to true. The
	// default is false and time-series metrics aren't generated except in the
	// following cases:
	//
	//     * You use one of the Amazon SageMaker built-in
	// algorithms
	//
	//     * You use one of the following Prebuilt Amazon SageMaker Docker
	// Images
	// (https://docs.aws.amazon.com/sagemaker/latest/dg/pre-built-containers-frameworks-deep-learning.html):
	//
	//
	// * Tensorflow (version >= 1.15)
	//
	//         * MXNet (version >= 1.6)
	//
	//         *
	// PyTorch (version >= 1.3)
	//
	//     * You specify at least one MetricDefinition ()
	EnableSageMakerMetricsTimeSeries *bool
	// The name of the algorithm resource to use for the training job. This must be an
	// algorithm resource that you created or subscribe to on AWS Marketplace. If you
	// specify a value for this parameter, you can't specify a value for TrainingImage.
	AlgorithmName *string
	// A list of metric definition objects. Each object specifies the metric name and
	// regular expressions used to parse algorithm logs. Amazon SageMaker publishes
	// each metric to Amazon CloudWatch.
	MetricDefinitions []*MetricDefinition
	// The registry path of the Docker image that contains the training algorithm. For
	// information about docker registry paths for built-in algorithms, see Algorithms
	// Provided by Amazon SageMaker: Common Parameters
	// (https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-algo-docker-registry-paths.html).
	// Amazon SageMaker supports both registry/repository[:tag] and
	// registry/repository[@digest] image path formats. For more information, see Using
	// Your Own Algorithms with Amazon SageMaker
	// (https://docs.aws.amazon.com/sagemaker/latest/dg/your-algorithms.html).
	TrainingImage *string
}

// Specifies the validation and image scan statuses of the algorithm.
type AlgorithmStatusDetails struct {
	// The status of algorithm validation.
	ValidationStatuses []*AlgorithmStatusItem
	// The status of the scan of the algorithm's Docker image container.
	ImageScanStatuses []*AlgorithmStatusItem
}

// Represents the overall status of an algorithm.
type AlgorithmStatusItem struct {
	// The current status.
	Status DetailedAlgorithmStatus
	// if the overall status is Failed, the reason for the failure.
	FailureReason *string
	// The name of the algorithm for which the overall status is being reported.
	Name *string
}

// Provides summary information about an algorithm.
type AlgorithmSummary struct {
	// A timestamp that shows when the algorithm was created.
	CreationTime *time.Time
	// A brief description of the algorithm.
	AlgorithmDescription *string
	// The overall status of the algorithm.
	AlgorithmStatus AlgorithmStatus
	// The Amazon Resource Name (ARN) of the algorithm.
	AlgorithmArn *string
	// The name of the algorithm that is described by the summary.
	AlgorithmName *string
}

// Defines a training job and a batch transform job that Amazon SageMaker runs to
// validate your algorithm. The data provided in the validation profile is made
// available to your buyers on AWS Marketplace.
type AlgorithmValidationProfile struct {
	// The TrainingJobDefinition object that describes the training job that Amazon
	// SageMaker runs to validate your algorithm.
	TrainingJobDefinition *TrainingJobDefinition
	// The name of the profile for the algorithm. The name must have 1 to 63
	// characters. Valid characters are a-z, A-Z, 0-9, and - (hyphen).
	ProfileName *string
	// The TransformJobDefinition object that describes the transform job that Amazon
	// SageMaker runs to validate your algorithm.
	TransformJobDefinition *TransformJobDefinition
}

// Specifies configurations for one or more training jobs that Amazon SageMaker
// runs to test the algorithm.
type AlgorithmValidationSpecification struct {
	// An array of AlgorithmValidationProfile objects, each of which specifies a
	// training job and batch transform job that Amazon SageMaker runs to validate your
	// algorithm.
	ValidationProfiles []*AlgorithmValidationProfile
	// The IAM roles that Amazon SageMaker uses to run the training jobs.
	ValidationRole *string
}

// Configures how labels are consolidated across human workers and processes output
// data.
type AnnotationConsolidationConfig struct {
	// The Amazon Resource Name (ARN) of a Lambda function implements the logic for
	// annotation consolidation
	// (https://docs.aws.amazon.com/sagemaker/latest/dg/sms-annotation-consolidation.html)
	// and to process output data. This parameter is required for all labeling jobs.
	// For built-in task types
	// (https://docs.aws.amazon.com/sagemaker/latest/dg/sms-task-types.html), use one
	// of the following Amazon SageMaker Ground Truth Lambda function ARNs for
	// AnnotationConsolidationLambdaArn. For custom labeling workflows, see
	// Post-annotation Lambda
	// (https://docs.aws.amazon.com/sagemaker/latest/dg/sms-custom-templates-step3.html#sms-custom-templates-step3-postlambda).
	// <p> <b>Bounding box</b> - Finds the most similar boxes from different workers
	// based on the Jaccard index of the boxes.</p> <ul> <li> <p>
	// <code>arn:aws:lambda:us-east-1:432418664414:function:ACS-BoundingBox</code> </p>
	// <p> <code>arn:aws:lambda:us-east-2:266458841044:function:ACS-BoundingBox</code>
	// </p> <p>
	// <code>arn:aws:lambda:us-west-2:081040173940:function:ACS-BoundingBox</code> </p>
	// <p> <code>arn:aws:lambda:eu-west-1:568282634449:function:ACS-BoundingBox</code>
	// </p> <p>
	// <code>arn:aws:lambda:ap-northeast-1:477331159723:function:ACS-BoundingBox</code>
	// </p> <p>
	// <code>arn:aws:lambda:ap-southeast-2:454466003867:function:ACS-BoundingBox</code>
	// </p> <p>
	// <code>arn:aws:lambda:ap-south-1:565803892007:function:ACS-BoundingBox</code>
	// </p> <p>
	// <code>arn:aws:lambda:eu-central-1:203001061592:function:ACS-BoundingBox</code>
	// </p> <p>
	// <code>arn:aws:lambda:ap-northeast-2:845288260483:function:ACS-BoundingBox</code>
	// </p> <p>
	// <code>arn:aws:lambda:eu-west-2:487402164563:function:ACS-BoundingBox</code> </p>
	// <p>
	// <code>arn:aws:lambda:ap-southeast-1:377565633583:function:ACS-BoundingBox</code>
	// </p> <p>
	// <code>arn:aws:lambda:ca-central-1:918755190332:function:ACS-BoundingBox</code>
	// </p> </li> </ul> <p> <b>Image classification</b> - Uses a variant of the
	// Expectation Maximization approach to estimate the true class of an image based
	// on annotations from individual workers.</p> <ul> <li> <p>
	// <code>arn:aws:lambda:us-east-1:432418664414:function:ACS-ImageMultiClass</code>
	// </p> <p>
	// <code>arn:aws:lambda:us-east-2:266458841044:function:ACS-ImageMultiClass</code>
	// </p> <p>
	// <code>arn:aws:lambda:us-west-2:081040173940:function:ACS-ImageMultiClass</code>
	// </p> <p>
	// <code>arn:aws:lambda:eu-west-1:568282634449:function:ACS-ImageMultiClass</code>
	// </p> <p>
	// <code>arn:aws:lambda:ap-northeast-1:477331159723:function:ACS-ImageMultiClass</code>
	// </p> <p>
	// <code>arn:aws:lambda:ap-southeast-2:454466003867:function:ACS-ImageMultiClass</code>
	// </p> <p>
	// <code>arn:aws:lambda:ap-south-1:565803892007:function:ACS-ImageMultiClass</code>
	// </p> <p>
	// <code>arn:aws:lambda:eu-central-1:203001061592:function:ACS-ImageMultiClass</code>
	// </p> <p>
	// <code>arn:aws:lambda:ap-northeast-2:845288260483:function:ACS-ImageMultiClass</code>
	// </p> <p>
	// <code>arn:aws:lambda:eu-west-2:487402164563:function:ACS-ImageMultiClass</code>
	// </p> <p>
	// <code>arn:aws:lambda:ap-southeast-1:377565633583:function:ACS-ImageMultiClass</code>
	// </p> <p>
	// <code>arn:aws:lambda:ca-central-1:918755190332:function:ACS-ImageMultiClass</code>
	// </p> </li> </ul> <p> <b>Multi-label image classification</b> - Uses a variant of
	// the Expectation Maximization approach to estimate the true classes of an image
	// based on annotations from individual workers.</p> <ul> <li> <p>
	// <code>arn:aws:lambda:us-east-1:432418664414:function:ACS-ImageMultiClassMultiLabel</code>
	// </p> <p>
	// <code>arn:aws:lambda:us-east-2:266458841044:function:ACS-ImageMultiClassMultiLabel</code>
	// </p> <p>
	// <code>arn:aws:lambda:us-west-2:081040173940:function:ACS-ImageMultiClassMultiLabel</code>
	// </p> <p>
	// <code>arn:aws:lambda:eu-west-1:568282634449:function:ACS-ImageMultiClassMultiLabel</code>
	// </p> <p>
	// <code>arn:aws:lambda:ap-northeast-1:477331159723:function:ACS-ImageMultiClassMultiLabel</code>
	// </p> <p>
	// <code>arn:aws:lambda:ap-southeast-2:454466003867:function:ACS-ImageMultiClassMultiLabel</code>
	// </p> <p>
	// <code>arn:aws:lambda:ap-south-1:565803892007:function:ACS-ImageMultiClassMultiLabel</code>
	// </p> <p>
	// <code>arn:aws:lambda:eu-central-1:203001061592:function:ACS-ImageMultiClassMultiLabel</code>
	// </p> <p>
	// <code>arn:aws:lambda:ap-northeast-2:845288260483:function:ACS-ImageMultiClassMultiLabel</code>
	// </p> <p>
	// <code>arn:aws:lambda:eu-west-2:487402164563:function:ACS-ImageMultiClassMultiLabel</code>
	// </p> <p>
	// <code>arn:aws:lambda:ap-southeast-1:377565633583:function:ACS-ImageMultiClassMultiLabel</code>
	// </p> <p>
	// <code>arn:aws:lambda:ca-central-1:918755190332:function:ACS-ImageMultiClassMultiLabel</code>
	// </p> </li> </ul> <p> <b>Semantic segmentation</b> - Treats each pixel in an
	// image as a multi-class classification and treats pixel annotations from workers
	// as "votes" for the correct label.</p> <ul> <li> <p>
	// <code>arn:aws:lambda:us-east-1:432418664414:function:ACS-SemanticSegmentation</code>
	// </p> <p>
	// <code>arn:aws:lambda:us-east-2:266458841044:function:ACS-SemanticSegmentation</code>
	// </p> <p>
	// <code>arn:aws:lambda:us-west-2:081040173940:function:ACS-SemanticSegmentation</code>
	// </p> <p>
	// <code>arn:aws:lambda:eu-west-1:568282634449:function:ACS-SemanticSegmentation</code>
	// </p> <p>
	// <code>arn:aws:lambda:ap-northeast-1:477331159723:function:ACS-SemanticSegmentation</code>
	// </p> <p>
	// <code>arn:aws:lambda:ap-southeast-2:454466003867:function:ACS-SemanticSegmentation</code>
	// </p> <p>
	// <code>arn:aws:lambda:ap-south-1:565803892007:function:ACS-SemanticSegmentation</code>
	// </p> <p>
	// <code>arn:aws:lambda:eu-central-1:203001061592:function:ACS-SemanticSegmentation</code>
	// </p> <p>
	// <code>arn:aws:lambda:ap-northeast-2:845288260483:function:ACS-SemanticSegmentation</code>
	// </p> <p>
	// <code>arn:aws:lambda:eu-west-2:487402164563:function:ACS-SemanticSegmentation</code>
	// </p> <p>
	// <code>arn:aws:lambda:ap-southeast-1:377565633583:function:ACS-SemanticSegmentation</code>
	// </p> <p>
	// <code>arn:aws:lambda:ca-central-1:918755190332:function:ACS-SemanticSegmentation</code>
	// </p> </li> </ul> <p> <b>Text classification</b> - Uses a variant of the
	// Expectation Maximization approach to estimate the true class of text based on
	// annotations from individual workers.</p> <ul> <li> <p>
	// <code>arn:aws:lambda:us-east-1:432418664414:function:ACS-TextMultiClass</code>
	// </p> <p>
	// <code>arn:aws:lambda:us-east-2:266458841044:function:ACS-TextMultiClass</code>
	// </p> <p>
	// <code>arn:aws:lambda:us-west-2:081040173940:function:ACS-TextMultiClass</code>
	// </p> <p>
	// <code>arn:aws:lambda:eu-west-1:568282634449:function:ACS-TextMultiClass</code>
	// </p> <p>
	// <code>arn:aws:lambda:ap-northeast-1:477331159723:function:ACS-TextMultiClass</code>
	// </p> <p>
	// <code>arn:aws:lambda:ap-southeast-2:454466003867:function:ACS-TextMultiClass</code>
	// </p> <p>
	// <code>arn:aws:lambda:ap-south-1:565803892007:function:ACS-TextMultiClass</code>
	// </p> <p>
	// <code>arn:aws:lambda:eu-central-1:203001061592:function:ACS-TextMultiClass</code>
	// </p> <p>
	// <code>arn:aws:lambda:ap-northeast-2:845288260483:function:ACS-TextMultiClass</code>
	// </p> <p>
	// <code>arn:aws:lambda:eu-west-2:487402164563:function:ACS-TextMultiClass</code>
	// </p> <p>
	// <code>arn:aws:lambda:ap-southeast-1:377565633583:function:ACS-TextMultiClass</code>
	// </p> <p>
	// <code>arn:aws:lambda:ca-central-1:918755190332:function:ACS-TextMultiClass</code>
	// </p> </li> </ul> <p> <b>Multi-label text classification</b> - Uses a variant of
	// the Expectation Maximization approach to estimate the true classes of text based
	// on annotations from individual workers.</p> <ul> <li> <p>
	// <code>arn:aws:lambda:us-east-1:432418664414:function:ACS-TextMultiClassMultiLabel</code>
	// </p> <p>
	// <code>arn:aws:lambda:us-east-2:266458841044:function:ACS-TextMultiClassMultiLabel</code>
	// </p> <p>
	// <code>arn:aws:lambda:us-west-2:081040173940:function:ACS-TextMultiClassMultiLabel</code>
	// </p> <p>
	// <code>arn:aws:lambda:eu-west-1:568282634449:function:ACS-TextMultiClassMultiLabel</code>
	// </p> <p>
	// <code>arn:aws:lambda:ap-northeast-1:477331159723:function:ACS-TextMultiClassMultiLabel</code>
	// </p> <p>
	// <code>arn:aws:lambda:ap-southeast-2:454466003867:function:ACS-TextMultiClassMultiLabel</code>
	// </p> <p>
	// <code>arn:aws:lambda:ap-south-1:565803892007:function:ACS-TextMultiClassMultiLabel</code>
	// </p> <p>
	// <code>arn:aws:lambda:eu-central-1:203001061592:function:ACS-TextMultiClassMultiLabel</code>
	// </p> <p>
	// <code>arn:aws:lambda:ap-northeast-2:845288260483:function:ACS-TextMultiClassMultiLabel</code>
	// </p> <p>
	// <code>arn:aws:lambda:eu-west-2:487402164563:function:ACS-TextMultiClassMultiLabel</code>
	// </p> <p>
	// <code>arn:aws:lambda:ap-southeast-1:377565633583:function:ACS-TextMultiClassMultiLabel</code>
	// </p> <p>
	// <code>arn:aws:lambda:ca-central-1:918755190332:function:ACS-TextMultiClassMultiLabel</code>
	// </p> </li> </ul> <p> <b>Named entity recognition</b> - Groups similar selections
	// and calculates aggregate boundaries, resolving to most-assigned label.</p> <ul>
	// <li> <p>
	// <code>arn:aws:lambda:us-east-1:432418664414:function:ACS-NamedEntityRecognition</code>
	// </p> <p>
	// <code>arn:aws:lambda:us-east-2:266458841044:function:ACS-NamedEntityRecognition</code>
	// </p> <p>
	// <code>arn:aws:lambda:us-west-2:081040173940:function:ACS-NamedEntityRecognition</code>
	// </p> <p>
	// <code>arn:aws:lambda:eu-west-1:568282634449:function:ACS-NamedEntityRecognition</code>
	// </p> <p>
	// <code>arn:aws:lambda:ap-northeast-1:477331159723:function:ACS-NamedEntityRecognition</code>
	// </p> <p>
	// <code>arn:aws:lambda:ap-southeast-2:454466003867:function:ACS-NamedEntityRecognition</code>
	// </p> <p>
	// <code>arn:aws:lambda:ap-south-1:565803892007:function:ACS-NamedEntityRecognition</code>
	// </p> <p>
	// <code>arn:aws:lambda:eu-central-1:203001061592:function:ACS-NamedEntityRecognition</code>
	// </p> <p>
	// <code>arn:aws:lambda:ap-northeast-2:845288260483:function:ACS-NamedEntityRecognition</code>
	// </p> <p>
	// <code>arn:aws:lambda:eu-west-2:487402164563:function:ACS-NamedEntityRecognition</code>
	// </p> <p>
	// <code>arn:aws:lambda:ap-southeast-1:377565633583:function:ACS-NamedEntityRecognition</code>
	// </p> <p>
	// <code>arn:aws:lambda:ca-central-1:918755190332:function:ACS-NamedEntityRecognition</code>
	// </p> </li> </ul> <p> <b>Named entity recognition</b> - Groups similar selections
	// and calculates aggregate boundaries, resolving to most-assigned label.</p> <ul>
	// <li> <p>
	// <code>arn:aws:lambda:us-east-1:432418664414:function:ACS-NamedEntityRecognition</code>
	// </p> <p>
	// <code>arn:aws:lambda:us-east-2:266458841044:function:ACS-NamedEntityRecognition</code>
	// </p> <p>
	// <code>arn:aws:lambda:us-west-2:081040173940:function:ACS-NamedEntityRecognition</code>
	// </p> <p>
	// <code>arn:aws:lambda:eu-west-1:568282634449:function:ACS-NamedEntityRecognition</code>
	// </p> <p>
	// <code>arn:aws:lambda:ap-northeast-1:477331159723:function:ACS-NamedEntityRecognition</code>
	// </p> <p>
	// <code>arn:aws:lambda:ap-southeast-2:454466003867:function:ACS-NamedEntityRecognition</code>
	// </p> <p>
	// <code>arn:aws:lambda:ap-south-1:565803892007:function:ACS-NamedEntityRecognition</code>
	// </p> <p>
	// <code>arn:aws:lambda:eu-central-1:203001061592:function:ACS-NamedEntityRecognition</code>
	// </p> <p>
	// <code>arn:aws:lambda:ap-northeast-2:845288260483:function:ACS-NamedEntityRecognition</code>
	// </p> <p>
	// <code>arn:aws:lambda:eu-west-2:487402164563:function:ACS-NamedEntityRecognition</code>
	// </p> <p>
	// <code>arn:aws:lambda:ap-southeast-1:377565633583:function:ACS-NamedEntityRecognition</code>
	// </p> <p>
	// <code>arn:aws:lambda:ca-central-1:918755190332:function:ACS-NamedEntityRecognition</code>
	// </p> </li> </ul> <p> <b>Video Classification</b> - Use this task type when you
	// need workers to classify videos using predefined labels that you specify.
	// Workers are shown videos and are asked to choose one label for each video.</p>
	// <ul> <li> <p>
	// <code>arn:aws:lambda:us-east-1:432418664414:function:ACS-VideoMultiClass</code>
	// </p> <p>
	// <code>arn:aws:lambda:us-east-2:266458841044:function:ACS-VideoMultiClass</code>
	// </p> <p>
	// <code>arn:aws:lambda:us-west-2:081040173940:function:ACS-VideoMultiClass</code>
	// </p> <p>
	// <code>arn:aws:lambda:eu-west-1:568282634449:function:ACS-VideoMultiClass</code>
	// </p> <p>
	// <code>arn:aws:lambda:ap-northeast-1:477331159723:function:ACS-VideoMultiClass</code>
	// </p> <p>
	// <code>arn:aws:lambda:ap-southeast-2:454466003867:function:ACS-VideoMultiClass</code>
	// </p> <p>
	// <code>arn:aws:lambda:ap-south-1:565803892007:function:ACS-VideoMultiClass</code>
	// </p> <p>
	// <code>arn:aws:lambda:eu-central-1:203001061592:function:ACS-VideoMultiClass</code>
	// </p> <p>
	// <code>arn:aws:lambda:ap-northeast-2:845288260483:function:ACS-VideoMultiClass</code>
	// </p> <p>
	// <code>arn:aws:lambda:eu-west-2:487402164563:function:ACS-VideoMultiClass</code>
	// </p> <p>
	// <code>arn:aws:lambda:ap-southeast-1:377565633583:function:ACS-VideoMultiClass</code>
	// </p> <p>
	// <code>arn:aws:lambda:ca-central-1:918755190332:function:ACS-VideoMultiClass</code>
	// </p> </li> </ul> <p> <b>Video Frame Object Detection</b> - Use this task type to
	// have workers identify and locate objects in a sequence of video frames (images
	// extracted from a video) using bounding boxes. For example, you can use this task
	// to ask workers to identify and localize various objects in a series of video
	// frames, such as cars, bikes, and pedestrians.</p> <ul> <li> <p>
	// <code>arn:aws:lambda:us-east-1:432418664414:function:ACS-VideoObjectDetection</code>
	// </p> <p>
	// <code>arn:aws:lambda:us-east-2:266458841044:function:ACS-VideoObjectDetection</code>
	// </p> <p>
	// <code>arn:aws:lambda:us-west-2:081040173940:function:ACS-VideoObjectDetection</code>
	// </p> <p>
	// <code>arn:aws:lambda:eu-west-1:568282634449:function:ACS-VideoObjectDetection</code>
	// </p> <p>
	// <code>arn:aws:lambda:ap-northeast-1:477331159723:function:ACS-VideoObjectDetection</code>
	// </p> <p>
	// <code>arn:aws:lambda:ap-southeast-2:454466003867:function:ACS-VideoObjectDetection</code>
	// </p> <p>
	// <code>arn:aws:lambda:ap-south-1:565803892007:function:ACS-VideoObjectDetection</code>
	// </p> <p>
	// <code>arn:aws:lambda:eu-central-1:203001061592:function:ACS-VideoObjectDetection</code>
	// </p> <p>
	// <code>arn:aws:lambda:ap-northeast-2:845288260483:function:ACS-VideoObjectDetection</code>
	// </p> <p>
	// <code>arn:aws:lambda:eu-west-2:487402164563:function:ACS-VideoObjectDetection</code>
	// </p> <p>
	// <code>arn:aws:lambda:ap-southeast-1:377565633583:function:ACS-VideoObjectDetection</code>
	// </p> <p>
	// <code>arn:aws:lambda:ca-central-1:918755190332:function:ACS-VideoObjectDetection</code>
	// </p> </li> </ul> <p> <b>Video Frame Object Tracking</b> - Use this task type to
	// have workers track the movement of objects in a sequence of video frames (images
	// extracted from a video) using bounding boxes. For example, you can use this task
	// to ask workers to track the movement of objects, such as cars, bikes, and
	// pedestrians. </p> <ul> <li> <p>
	// <code>arn:aws:lambda:us-east-1:432418664414:function:ACS-VideoObjectTracking</code>
	// </p> <p>
	// <code>arn:aws:lambda:us-east-2:266458841044:function:ACS-VideoObjectTracking</code>
	// </p> <p>
	// <code>arn:aws:lambda:us-west-2:081040173940:function:ACS-VideoObjectTracking</code>
	// </p> <p>
	// <code>arn:aws:lambda:eu-west-1:568282634449:function:ACS-VideoObjectTracking</code>
	// </p> <p>
	// <code>arn:aws:lambda:ap-northeast-1:477331159723:function:ACS-VideoObjectTracking</code>
	// </p> <p>
	// <code>arn:aws:lambda:ap-southeast-2:454466003867:function:ACS-VideoObjectTracking</code>
	// </p> <p>
	// <code>arn:aws:lambda:ap-south-1:565803892007:function:ACS-VideoObjectTracking</code>
	// </p> <p>
	// <code>arn:aws:lambda:eu-central-1:203001061592:function:ACS-VideoObjectTracking</code>
	// </p> <p>
	// <code>arn:aws:lambda:ap-northeast-2:845288260483:function:ACS-VideoObjectTracking</code>
	// </p> <p>
	// <code>arn:aws:lambda:eu-west-2:487402164563:function:ACS-VideoObjectTracking</code>
	// </p> <p>
	// <code>arn:aws:lambda:ap-southeast-1:377565633583:function:ACS-VideoObjectTracking</code>
	// </p> <p>
	// <code>arn:aws:lambda:ca-central-1:918755190332:function:ACS-VideoObjectTracking</code>
	// </p> </li> </ul> <p> <b>3D point cloud object detection</b> - Use this task type
	// when you want workers to classify objects in a 3D point cloud by drawing 3D
	// cuboids around objects. For example, you can use this task type to ask workers
	// to identify different types of objects in a point cloud, such as cars, bikes,
	// and pedestrians.</p> <ul> <li> <p>
	// <code>arn:aws:lambda:us-east-1:432418664414:function:ACS-3DPointCloudObjectDetection</code>
	// </p> <p>
	// <code>arn:aws:lambda:us-east-2:266458841044:function:ACS-3DPointCloudObjectDetection</code>
	// </p> <p>
	// <code>arn:aws:lambda:us-west-2:081040173940:function:ACS-3DPointCloudObjectDetection</code>
	// </p> <p>
	// <code>arn:aws:lambda:eu-west-1:568282634449:function:ACS-3DPointCloudObjectDetection</code>
	// </p> <p>
	// <code>arn:aws:lambda:ap-northeast-1:477331159723:function:ACS-3DPointCloudObjectDetection</code>
	// </p> <p>
	// <code>arn:aws:lambda:ap-southeast-2:454466003867:function:ACS-3DPointCloudObjectDetection</code>
	// </p> <p>
	// <code>arn:aws:lambda:ap-south-1:565803892007:function:ACS-3DPointCloudObjectDetection</code>
	// </p> <p>
	// <code>arn:aws:lambda:eu-central-1:203001061592:function:ACS-3DPointCloudObjectDetection</code>
	// </p> <p>
	// <code>arn:aws:lambda:ap-northeast-2:845288260483:function:ACS-3DPointCloudObjectDetection</code>
	// </p> <p>
	// <code>arn:aws:lambda:eu-west-2:487402164563:function:ACS-3DPointCloudObjectDetection</code>
	// </p> <p>
	// <code>arn:aws:lambda:ap-southeast-1:377565633583:function:ACS-3DPointCloudObjectDetection</code>
	// </p> <p>
	// <code>arn:aws:lambda:ca-central-1:918755190332:function:ACS-3DPointCloudObjectDetection</code>
	// </p> </li> </ul> <p> <b>3D point cloud object tracking</b> - Use this task type
	// when you want workers to draw 3D cuboids around objects that appear in a
	// sequence of 3D point cloud frames. For example, you can use this task type to
	// ask workers to track the movement of vehicles across multiple point cloud
	// frames. </p> <ul> <li> <p>
	// <code>arn:aws:lambda:us-east-1:432418664414:function:ACS-3DPointCloudObjectTracking</code>
	// </p> <p>
	// <code>arn:aws:lambda:us-east-2:266458841044:function:ACS-3DPointCloudObjectTracking</code>
	// </p> <p>
	// <code>arn:aws:lambda:us-west-2:081040173940:function:ACS-3DPointCloudObjectTracking</code>
	// </p> <p>
	// <code>arn:aws:lambda:eu-west-1:568282634449:function:ACS-3DPointCloudObjectTracking</code>
	// </p> <p>
	// <code>arn:aws:lambda:ap-northeast-1:477331159723:function:ACS-3DPointCloudObjectTracking</code>
	// </p> <p>
	// <code>arn:aws:lambda:ap-southeast-2:454466003867:function:ACS-3DPointCloudObjectTracking</code>
	// </p> <p>
	// <code>arn:aws:lambda:ap-south-1:565803892007:function:ACS-3DPointCloudObjectTracking</code>
	// </p> <p>
	// <code>arn:aws:lambda:eu-central-1:203001061592:function:ACS-3DPointCloudObjectTracking</code>
	// </p> <p>
	// <code>arn:aws:lambda:ap-northeast-2:845288260483:function:ACS-3DPointCloudObjectTracking</code>
	// </p> <p>
	// <code>arn:aws:lambda:eu-west-2:487402164563:function:ACS-3DPointCloudObjectTracking</code>
	// </p> <p>
	// <code>arn:aws:lambda:ap-southeast-1:377565633583:function:ACS-3DPointCloudObjectTracking</code>
	// </p> <p>
	// <code>arn:aws:lambda:ca-central-1:918755190332:function:ACS-3DPointCloudObjectTracking</code>
	// </p> </li> </ul> <p> <b>3D point cloud semantic segmentation</b> - Use this task
	// type when you want workers to create a point-level semantic segmentation masks
	// by painting objects in a 3D point cloud using different colors where each color
	// is assigned to one of the classes you specify.</p> <ul> <li> <p>
	// <code>arn:aws:lambda:us-east-1:432418664414:function:ACS-3DPointCloudSemanticSegmentation</code>
	// </p> <p>
	// <code>arn:aws:lambda:us-east-2:266458841044:function:ACS-3DPointCloudSemanticSegmentation</code>
	// </p> <p>
	// <code>arn:aws:lambda:us-west-2:081040173940:function:ACS-3DPointCloudSemanticSegmentation</code>
	// </p> <p>
	// <code>arn:aws:lambda:eu-west-1:568282634449:function:ACS-3DPointCloudSemanticSegmentation</code>
	// </p> <p>
	// <code>arn:aws:lambda:ap-northeast-1:477331159723:function:ACS-3DPointCloudSemanticSegmentation</code>
	// </p> <p>
	// <code>arn:aws:lambda:ap-southeast-2:454466003867:function:ACS-3DPointCloudSemanticSegmentation</code>
	// </p> <p>
	// <code>arn:aws:lambda:ap-south-1:565803892007:function:ACS-3DPointCloudSemanticSegmentation</code>
	// </p> <p>
	// <code>arn:aws:lambda:eu-central-1:203001061592:function:ACS-3DPointCloudSemanticSegmentation</code>
	// </p> <p>
	// <code>arn:aws:lambda:ap-northeast-2:845288260483:function:ACS-3DPointCloudSemanticSegmentation</code>
	// </p> <p>
	// <code>arn:aws:lambda:eu-west-2:487402164563:function:ACS-3DPointCloudSemanticSegmentation</code>
	// </p> <p>
	// <code>arn:aws:lambda:ap-southeast-1:377565633583:function:ACS-3DPointCloudSemanticSegmentation</code>
	// </p> <p>
	// <code>arn:aws:lambda:ca-central-1:918755190332:function:ACS-3DPointCloudSemanticSegmentation</code>
	// </p> </li> </ul> <p> <b>Use the following ARNs for Label Verification and
	// Adjustment Jobs</b> </p> <p>Use label verification and adjustment jobs to review
	// and adjust labels. To learn more, see <a
	// href="https://docs.aws.amazon.com/sagemaker/latest/dg/sms-verification-data.html">Verify
	// and Adjust Labels </a>.</p> <p> <b>Semantic segmentation adjustment</b> - Treats
	// each pixel in an image as a multi-class classification and treats pixel adjusted
	// annotations from workers as "votes" for the correct label.</p> <ul> <li> <p>
	// <code>arn:aws:lambda:us-east-1:432418664414:function:ACS-AdjustmentSemanticSegmentation</code>
	// </p> <p>
	// <code>arn:aws:lambda:us-east-2:266458841044:function:ACS-AdjustmentSemanticSegmentation</code>
	// </p> <p>
	// <code>arn:aws:lambda:us-west-2:081040173940:function:ACS-AdjustmentSemanticSegmentation</code>
	// </p> <p>
	// <code>arn:aws:lambda:eu-west-1:568282634449:function:ACS-AdjustmentSemanticSegmentation</code>
	// </p> <p>
	// <code>arn:aws:lambda:ap-northeast-1:477331159723:function:ACS-AdjustmentSemanticSegmentation</code>
	// </p> <p>
	// <code>arn:aws:lambda:ap-southeast-2:454466003867:function:ACS-AdjustmentSemanticSegmentation</code>
	// </p> <p>
	// <code>arn:aws:lambda:ap-south-1:565803892007:function:ACS-AdjustmentSemanticSegmentation</code>
	// </p> <p>
	// <code>arn:aws:lambda:eu-central-1:203001061592:function:ACS-AdjustmentSemanticSegmentation</code>
	// </p> <p>
	// <code>arn:aws:lambda:ap-northeast-2:845288260483:function:ACS-AdjustmentSemanticSegmentation</code>
	// </p> <p>
	// <code>arn:aws:lambda:eu-west-2:487402164563:function:ACS-AdjustmentSemanticSegmentation</code>
	// </p> <p>
	// <code>arn:aws:lambda:ap-southeast-1:377565633583:function:ACS-AdjustmentSemanticSegmentation</code>
	// </p> <p>
	// <code>arn:aws:lambda:ca-central-1:918755190332:function:ACS-AdjustmentSemanticSegmentation</code>
	// </p> </li> </ul> <p> <b>Semantic segmentation verification</b> - Uses a variant
	// of the Expectation Maximization approach to estimate the true class of
	// verification judgment for semantic segmentation labels based on annotations from
	// individual workers.</p> <ul> <li> <p>
	// <code>arn:aws:lambda:us-east-1:432418664414:function:ACS-VerificationSemanticSegmentation</code>
	// </p> <p>
	// <code>arn:aws:lambda:us-east-2:266458841044:function:ACS-VerificationSemanticSegmentation</code>
	// </p> <p>
	// <code>arn:aws:lambda:us-west-2:081040173940:function:ACS-VerificationSemanticSegmentation</code>
	// </p> <p>
	// <code>arn:aws:lambda:eu-west-1:568282634449:function:ACS-VerificationSemanticSegmentation</code>
	// </p> <p>
	// <code>arn:aws:lambda:ap-northeast-1:477331159723:function:ACS-VerificationSemanticSegmentation</code>
	// </p> <p>
	// <code>arn:aws:lambda:ap-southeast-2:454466003867:function:ACS-VerificationSemanticSegmentation</code>
	// </p> <p>
	// <code>arn:aws:lambda:ap-south-1:565803892007:function:ACS-VerificationSemanticSegmentation</code>
	// </p> <p>
	// <code>arn:aws:lambda:eu-central-1:203001061592:function:ACS-VerificationSemanticSegmentation</code>
	// </p> <p>
	// <code>arn:aws:lambda:ap-northeast-2:845288260483:function:ACS-VerificationSemanticSegmentation</code>
	// </p> <p>
	// <code>arn:aws:lambda:eu-west-2:487402164563:function:ACS-VerificationSemanticSegmentation</code>
	// </p> <p>
	// <code>arn:aws:lambda:ap-southeast-1:377565633583:function:ACS-VerificationSemanticSegmentation</code>
	// </p> <p>
	// <code>arn:aws:lambda:ca-central-1:918755190332:function:ACS-VerificationSemanticSegmentation</code>
	// </p> </li> </ul> <p> <b>Bounding box verification</b> - Uses a variant of the
	// Expectation Maximization approach to estimate the true class of verification
	// judgement for bounding box labels based on annotations from individual
	// workers.</p> <ul> <li> <p>
	// <code>arn:aws:lambda:us-east-1:432418664414:function:ACS-VerificationBoundingBox</code>
	// </p> <p>
	// <code>arn:aws:lambda:us-east-2:266458841044:function:ACS-VerificationBoundingBox</code>
	// </p> <p>
	// <code>arn:aws:lambda:us-west-2:081040173940:function:ACS-VerificationBoundingBox</code>
	// </p> <p>
	// <code>arn:aws:lambda:eu-west-1:568282634449:function:ACS-VerificationBoundingBox</code>
	// </p> <p>
	// <code>arn:aws:lambda:ap-northeast-1:477331159723:function:ACS-VerificationBoundingBox</code>
	// </p> <p>
	// <code>arn:aws:lambda:ap-southeast-2:454466003867:function:ACS-VerificationBoundingBox</code>
	// </p> <p>
	// <code>arn:aws:lambda:ap-south-1:565803892007:function:ACS-VerificationBoundingBox</code>
	// </p> <p>
	// <code>arn:aws:lambda:eu-central-1:203001061592:function:ACS-VerificationBoundingBox</code>
	// </p> <p>
	// <code>arn:aws:lambda:ap-northeast-2:845288260483:function:ACS-VerificationBoundingBox</code>
	// </p> <p>
	// <code>arn:aws:lambda:eu-west-2:487402164563:function:ACS-VerificationBoundingBox</code>
	// </p> <p>
	// <code>arn:aws:lambda:ap-southeast-1:377565633583:function:ACS-VerificationBoundingBox</code>
	// </p> <p>
	// <code>arn:aws:lambda:ca-central-1:918755190332:function:ACS-VerificationBoundingBox</code>
	// </p> </li> </ul> <p> <b>Bounding box adjustment</b> - Finds the most similar
	// boxes from different workers based on the Jaccard index of the adjusted
	// annotations.</p> <ul> <li> <p>
	// <code>arn:aws:lambda:us-east-1:432418664414:function:ACS-AdjustmentBoundingBox</code>
	// </p> <p>
	// <code>arn:aws:lambda:us-east-2:266458841044:function:ACS-AdjustmentBoundingBox</code>
	// </p> <p>
	// <code>arn:aws:lambda:us-west-2:081040173940:function:ACS-AdjustmentBoundingBox</code>
	// </p> <p>
	// <code>arn:aws:lambda:eu-west-1:568282634449:function:ACS-AdjustmentBoundingBox</code>
	// </p> <p>
	// <code>arn:aws:lambda:ap-northeast-1:477331159723:function:ACS-AdjustmentBoundingBox</code>
	// </p> <p>
	// <code>arn:aws:lambda:ap-southeast-2:454466003867:function:ACS-AdjustmentBoundingBox</code>
	// </p> <p>
	// <code>arn:aws:lambda:ap-south-1:565803892007:function:ACS-AdjustmentBoundingBox</code>
	// </p> <p>
	// <code>arn:aws:lambda:eu-central-1:203001061592:function:ACS-AdjustmentBoundingBox</code>
	// </p> <p>
	// <code>arn:aws:lambda:ap-northeast-2:845288260483:function:ACS-AdjustmentBoundingBox</code>
	// </p> <p>
	// <code>arn:aws:lambda:eu-west-2:487402164563:function:ACS-AdjustmentBoundingBox</code>
	// </p> <p>
	// <code>arn:aws:lambda:ap-southeast-1:377565633583:function:ACS-AdjustmentBoundingBox</code>
	// </p> <p>
	// <code>arn:aws:lambda:ca-central-1:918755190332:function:ACS-AdjustmentBoundingBox</code>
	// </p> </li> </ul> <p> <b>Video Frame Object Detection Adjustment</b> - Use this
	// task type when you want workers to adjust bounding boxes that workers have added
	// to video frames to classify and localize objects in a sequence of video
	// frames.</p> <ul> <li> <p>
	// <code>arn:aws:lambda:us-east-1:432418664414:function:ACS-AdjustmentVideoObjectDetection</code>
	// </p> <p>
	// <code>arn:aws:lambda:us-east-2:266458841044:function:ACS-AdjustmentVideoObjectDetection</code>
	// </p> <p>
	// <code>arn:aws:lambda:us-west-2:081040173940:function:ACS-AdjustmentVideoObjectDetection</code>
	// </p> <p>
	// <code>arn:aws:lambda:eu-west-1:568282634449:function:ACS-AdjustmentVideoObjectDetection</code>
	// </p> <p>
	// <code>arn:aws:lambda:ap-northeast-1:477331159723:function:ACS-AdjustmentVideoObjectDetection</code>
	// </p> <p>
	// <code>arn:aws:lambda:ap-southeast-2:454466003867:function:ACS-AdjustmentVideoObjectDetection</code>
	// </p> <p>
	// <code>arn:aws:lambda:ap-south-1:565803892007:function:ACS-AdjustmentVideoObjectDetection</code>
	// </p> <p>
	// <code>arn:aws:lambda:eu-central-1:203001061592:function:ACS-AdjustmentVideoObjectDetection</code>
	// </p> <p>
	// <code>arn:aws:lambda:ap-northeast-2:845288260483:function:ACS-AdjustmentVideoObjectDetection</code>
	// </p> <p>
	// <code>arn:aws:lambda:eu-west-2:487402164563:function:ACS-AdjustmentVideoObjectDetection</code>
	// </p> <p>
	// <code>arn:aws:lambda:ap-southeast-1:377565633583:function:ACS-AdjustmentVideoObjectDetection</code>
	// </p> <p>
	// <code>arn:aws:lambda:ca-central-1:918755190332:function:ACS-AdjustmentVideoObjectDetection</code>
	// </p> </li> </ul> <p> <b>Video Frame Object Tracking Adjustment</b> - Use this
	// task type when you want workers to adjust bounding boxes that workers have added
	// to video frames to track object movement across a sequence of video frames.</p>
	// <ul> <li> <p>
	// <code>arn:aws:lambda:us-east-1:432418664414:function:ACS-AdjustmentVideoObjectTracking</code>
	// </p> <p>
	// <code>arn:aws:lambda:us-east-2:266458841044:function:ACS-AdjustmentVideoObjectTracking</code>
	// </p> <p>
	// <code>arn:aws:lambda:us-west-2:081040173940:function:ACS-AdjustmentVideoObjectTracking</code>
	// </p> <p>
	// <code>arn:aws:lambda:eu-west-1:568282634449:function:ACS-AdjustmentVideoObjectTracking</code>
	// </p> <p>
	// <code>arn:aws:lambda:ap-northeast-1:477331159723:function:ACS-AdjustmentVideoObjectTracking</code>
	// </p> <p>
	// <code>arn:aws:lambda:ap-southeast-2:454466003867:function:ACS-AdjustmentVideoObjectTracking</code>
	// </p> <p>
	// <code>arn:aws:lambda:ap-south-1:565803892007:function:ACS-AdjustmentVideoObjectTracking</code>
	// </p> <p>
	// <code>arn:aws:lambda:eu-central-1:203001061592:function:ACS-AdjustmentVideoObjectTracking</code>
	// </p> <p>
	// <code>arn:aws:lambda:ap-northeast-2:845288260483:function:ACS-AdjustmentVideoObjectTracking</code>
	// </p> <p>
	// <code>arn:aws:lambda:eu-west-2:487402164563:function:ACS-AdjustmentVideoObjectTracking</code>
	// </p> <p>
	// <code>arn:aws:lambda:ap-southeast-1:377565633583:function:ACS-AdjustmentVideoObjectTracking</code>
	// </p> <p>
	// <code>arn:aws:lambda:ca-central-1:918755190332:function:ACS-AdjustmentVideoObjectTracking</code>
	// </p> </li> </ul> <p> <b>3D point cloud object detection adjustment</b> - Use
	// this task type when you want workers to adjust 3D cuboids around objects in a 3D
	// point cloud. </p> <ul> <li> <p>
	// <code>arn:aws:lambda:us-east-1:432418664414:function:ACS-Adjustment3DPointCloudObjectDetection</code>
	// </p> <p>
	// <code>arn:aws:lambda:us-east-2:266458841044:function:ACS-Adjustment3DPointCloudObjectDetection</code>
	// </p> <p>
	// <code>arn:aws:lambda:us-west-2:081040173940:function:ACS-Adjustment3DPointCloudObjectDetection</code>
	// </p> <p>
	// <code>arn:aws:lambda:eu-west-1:568282634449:function:ACS-Adjustment3DPointCloudObjectDetection</code>
	// </p> <p>
	// <code>arn:aws:lambda:ap-northeast-1:477331159723:function:ACS-Adjustment3DPointCloudObjectDetection</code>
	// </p> <p>
	// <code>arn:aws:lambda:ap-southeast-2:454466003867:function:ACS-Adjustment3DPointCloudObjectDetection</code>
	// </p> <p>
	// <code>arn:aws:lambda:ap-south-1:565803892007:function:ACS-Adjustment3DPointCloudObjectDetection</code>
	// </p> <p>
	// <code>arn:aws:lambda:eu-central-1:203001061592:function:ACS-Adjustment3DPointCloudObjectDetection</code>
	// </p> <p>
	// <code>arn:aws:lambda:ap-northeast-2:845288260483:function:ACS-Adjustment3DPointCloudObjectDetection</code>
	// </p> <p>
	// <code>arn:aws:lambda:eu-west-2:487402164563:function:ACS-Adjustment3DPointCloudObjectDetection</code>
	// </p> <p>
	// <code>arn:aws:lambda:ap-southeast-1:377565633583:function:ACS-Adjustment3DPointCloudObjectDetection</code>
	// </p> <p>
	// <code>arn:aws:lambda:ca-central-1:918755190332:function:ACS-Adjustment3DPointCloudObjectDetection</code>
	// </p> </li> </ul> <p> <b>3D point cloud object tracking adjustment</b> - Use this
	// task type when you want workers to adjust 3D cuboids around objects that appear
	// in a sequence of 3D point cloud frames.</p> <ul> <li> <p>
	// <code>arn:aws:lambda:us-east-1:432418664414:function:ACS-Adjustment3DPointCloudObjectTracking</code>
	// </p> <p>
	// <code>arn:aws:lambda:us-east-2:266458841044:function:ACS-Adjustment3DPointCloudObjectTracking</code>
	// </p> <p>
	// <code>arn:aws:lambda:us-west-2:081040173940:function:ACS-Adjustment3DPointCloudObjectTracking</code>
	// </p> <p>
	// <code>arn:aws:lambda:eu-west-1:568282634449:function:ACS-Adjustment3DPointCloudObjectTracking</code>
	// </p> <p>
	// <code>arn:aws:lambda:ap-northeast-1:477331159723:function:ACS-Adjustment3DPointCloudObjectTracking</code>
	// </p> <p>
	// <code>arn:aws:lambda:ap-southeast-2:454466003867:function:ACS-Adjustment3DPointCloudObjectTracking</code>
	// </p> <p>
	// <code>arn:aws:lambda:ap-south-1:565803892007:function:ACS-Adjustment3DPointCloudObjectTracking</code>
	// </p> <p>
	// <code>arn:aws:lambda:eu-central-1:203001061592:function:ACS-Adjustment3DPointCloudObjectTracking</code>
	// </p> <p>
	// <code>arn:aws:lambda:ap-northeast-2:845288260483:function:ACS-Adjustment3DPointCloudObjectTracking</code>
	// </p> <p>
	// <code>arn:aws:lambda:eu-west-2:487402164563:function:ACS-Adjustment3DPointCloudObjectTracking</code>
	// </p> <p>
	// <code>arn:aws:lambda:ap-southeast-1:377565633583:function:ACS-Adjustment3DPointCloudObjectTracking</code>
	// </p> <p>
	// <code>arn:aws:lambda:ca-central-1:918755190332:function:ACS-Adjustment3DPointCloudObjectTracking</code>
	// </p> </li> </ul> <p> <b>3D point cloud semantic segmentation adjustment</b> -
	// Use this task type when you want workers to adjust a point-level semantic
	// segmentation masks using a paint tool.</p> <ul> <li> <p>
	// <code>arn:aws:lambda:us-east-1:432418664414:function:ACS-Adjustment3DPointCloudSemanticSegmentation</code>
	// </p> <p>
	// <code>arn:aws:lambda:us-east-2:266458841044:function:ACS-Adjustment3DPointCloudSemanticSegmentation</code>
	// </p> <p>
	// <code>arn:aws:lambda:us-west-2:081040173940:function:ACS-Adjustment3DPointCloudSemanticSegmentation</code>
	// </p> <p>
	// <code>arn:aws:lambda:eu-west-1:568282634449:function:ACS-Adjustment3DPointCloudSemanticSegmentation</code>
	// </p> <p>
	// <code>arn:aws:lambda:ap-northeast-1:477331159723:function:ACS-Adjustment3DPointCloudSemanticSegmentation</code>
	// </p> <p>
	// <code>arn:aws:lambda:ap-southeast-2:454466003867:function:ACS-Adjustment3DPointCloudSemanticSegmentation</code>
	// </p> <p>
	// <code>arn:aws:lambda:ap-south-1:565803892007:function:ACS-Adjustment3DPointCloudSemanticSegmentation</code>
	// </p> <p>
	// <code>arn:aws:lambda:eu-central-1:203001061592:function:ACS-Adjustment3DPointCloudSemanticSegmentation</code>
	// </p> <p>
	// <code>arn:aws:lambda:ap-northeast-2:845288260483:function:ACS-Adjustment3DPointCloudSemanticSegmentation</code>
	// </p> <p>
	// <code>arn:aws:lambda:eu-west-2:487402164563:function:ACS-Adjustment3DPointCloudSemanticSegmentation</code>
	// </p> <p>
	// <code>arn:aws:lambda:ap-southeast-1:377565633583:function:ACS-Adjustment3DPointCloudSemanticSegmentation</code>
	// </p> <p>
	// <code>arn:aws:lambda:ca-central-1:918755190332:function:ACS-Adjustment3DPointCloudSemanticSegmentation</code>
	// </p> </li> </ul>
	AnnotationConsolidationLambdaArn *string
}

// The app's details.
type AppDetails struct {
	// The name of the app.
	AppName *string
	// The creation time.
	CreationTime *time.Time
	// The domain ID.
	DomainId *string
	// The type of app.
	AppType AppType
	// The user profile name.
	UserProfileName *string
	// The status.
	Status AppStatus
}

// Configuration to run a processing job in a specified container image.
type AppSpecification struct {
	// The arguments for a container used to run a processing job.
	ContainerArguments []*string
	// The container image to be run by the processing job.
	ImageUri *string
	// The entrypoint for a container used to run a processing job.
	ContainerEntrypoint []*string
}

// An AutoPilot job will return recommendations, or candidates. Each candidate has
// futher details about the steps involed, and the status.
type AutoMLCandidate struct {
	// The candidate name.
	CandidateName *string
	// The failure reason.
	FailureReason *string
	// The candidate's status.
	CandidateStatus CandidateStatus
	// The objective status.
	ObjectiveStatus ObjectiveStatus
	// The candidate result from a job.
	FinalAutoMLJobObjectiveMetric *FinalAutoMLJobObjectiveMetric
	// The end time.
	EndTime *time.Time
	// The inference containers.
	InferenceContainers []*AutoMLContainerDefinition
	// The creation time.
	CreationTime *time.Time
	// The last modified time.
	LastModifiedTime *time.Time
	// The candidate's steps.
	CandidateSteps []*AutoMLCandidateStep
}

// Information about the steps for a Candidate, and what step it is working on.
type AutoMLCandidateStep struct {
	// The name for the Candidate's step.
	CandidateStepName *string
	// Whether the Candidate is at the transform, training, or processing step.
	CandidateStepType CandidateStepType
	// The ARN for the Candidate's step.
	CandidateStepArn *string
}

// Similar to Channel. A channel is a named input source that training algorithms
// can consume. Refer to Channel for detailed descriptions.
type AutoMLChannel struct {
	// The name of the target variable in supervised learning, a.k.a. 'y'.
	TargetAttributeName *string
	// The data source.
	DataSource *AutoMLDataSource
	// You can use Gzip or None. The default value is None.
	CompressionType CompressionType
}

// A list of container definitions that describe the different containers that make
// up one AutoML candidate. Refer to ContainerDefinition for more details.
type AutoMLContainerDefinition struct {
	// Environment variables to set in the container. Refer to ContainerDefinition for
	// more details.
	Environment map[string]*string
	// The location of the model artifacts. Refer to ContainerDefinition for more
	// details.
	ModelDataUrl *string
	// The ECR path of the container. Refer to ContainerDefinition for more details.
	Image *string
}

// The data source for the AutoPilot job.
type AutoMLDataSource struct {
	// The Amazon S3 location of the input data. The input data must be in CSV format
	// and contain at least 1000 rows.
	S3DataSource *AutoMLS3DataSource
}

// Artifacts that are generation during a job.
type AutoMLJobArtifacts struct {
	// The URL to the notebook location.
	DataExplorationNotebookLocation *string
	// The URL to the notebook location.
	CandidateDefinitionNotebookLocation *string
}

// How long a job is allowed to run, or how many candidates a job is allowed to
// generate.
type AutoMLJobCompletionCriteria struct {
	// The maximum time, in seconds, a job is allowed to run.
	MaxRuntimePerTrainingJobInSeconds *int32
	// The maximum number of times a training job is allowed to run.
	MaxCandidates *int32
	// The maximum time, in seconds, an AutoML job is allowed to wait for a trial to
	// complete. It must be equal to or greater than MaxRuntimePerTrainingJobInSeconds.
	MaxAutoMLJobRuntimeInSeconds *int32
}

// A collection of settings used for a job.
type AutoMLJobConfig struct {
	// How long a job is allowed to run, or how many candidates a job is allowed to
	// generate.
	CompletionCriteria *AutoMLJobCompletionCriteria
	// Security configuration for traffic encryption or Amazon VPC settings.
	SecurityConfig *AutoMLSecurityConfig
}

// Applies a metric to minimize or maximize for the job's objective.
type AutoMLJobObjective struct {
	// The name of the metric.
	MetricName AutoMLMetricEnum
}

// Provides a summary about a job.
type AutoMLJobSummary struct {
	// The ARN of the job.
	AutoMLJobArn *string
	// The failure reason.
	FailureReason *string
	// The name of the object you are requesting.
	AutoMLJobName *string
	// The end time.
	EndTime *time.Time
	// When the job was created.
	CreationTime *time.Time
	// When the job was last modified.
	LastModifiedTime *time.Time
	// The job's secondary status.
	AutoMLJobSecondaryStatus AutoMLJobSecondaryStatus
	// The job's status.
	AutoMLJobStatus AutoMLJobStatus
}

// The output data configuration.
type AutoMLOutputDataConfig struct {
	// The AWS KMS encryption key ID.
	KmsKeyId *string
	// The Amazon S3 output path. Must be 128 characters or less.
	S3OutputPath *string
}

// The Amazon S3 data source.
type AutoMLS3DataSource struct {
	// The data type.
	S3DataType AutoMLS3DataType
	// The URL to the Amazon S3 data source.
	S3Uri *string
}

// Security options.
type AutoMLSecurityConfig struct {
	// VPC configuration.
	VpcConfig *VpcConfig
	// Whether to use traffic encryption between the container layers.
	EnableInterContainerTrafficEncryption *bool
	// The key used to encrypt stored data.
	VolumeKmsKeyId *string
}

//
type CaptureContentTypeHeader struct {
	//
	CsvContentTypes []*string
	//
	JsonContentTypes []*string
}

//
type CaptureOption struct {
	//
	CaptureMode CaptureMode
}

// A list of categorical hyperparameters to tune.
type CategoricalParameterRange struct {
	// A list of the categories for the hyperparameter.
	Values []*string
	// The name of the categorical hyperparameter to tune.
	Name *string
}

// Defines the possible values for a categorical hyperparameter.
type CategoricalParameterRangeSpecification struct {
	// The allowed categories for the hyperparameter.
	Values []*string
}

// A channel is a named input source that training algorithms can consume.
type Channel struct {
	// The MIME type of the data.
	ContentType *string
	// (Optional) The input mode to use for the data channel in a training job. If you
	// don't set a value for InputMode, Amazon SageMaker uses the value set for
	// TrainingInputMode. Use this parameter to override the TrainingInputMode setting
	// in a AlgorithmSpecification () request when you have a channel that needs a
	// different input mode from the training job's general setting. To download the
	// data from Amazon Simple Storage Service (Amazon S3) to the provisioned ML
	// storage volume, and mount the directory to a Docker volume, use File input mode.
	// To stream data directly from Amazon S3 to the container, choose Pipe input mode.
	// To use a model for incremental training, choose File input model.
	InputMode TrainingInputMode
	// A configuration for a shuffle option for input data in a channel. If you use
	// S3Prefix for S3DataType, this shuffles the results of the S3 key prefix matches.
	// If you use ManifestFile, the order of the S3 object references in the
	// ManifestFile is shuffled. If you use AugmentedManifestFile, the order of the
	// JSON lines in the AugmentedManifestFile is shuffled. The shuffling order is
	// determined using the Seed value. For Pipe input mode, shuffling is done at the
	// start of every epoch. With large datasets this ensures that the order of the
	// training data is different for each epoch, it helps reduce bias and possible
	// overfitting. In a multi-node training job when ShuffleConfig is combined with
	// S3DataDistributionType of ShardedByS3Key, the data is shuffled across nodes so
	// that the content sent to a particular node on the first epoch might be sent to a
	// different node on the second epoch.
	ShuffleConfig *ShuffleConfig
	// Specify RecordIO as the value when input data is in raw format but the training
	// algorithm requires the RecordIO format. In this case, Amazon SageMaker wraps
	// each individual S3 object in a RecordIO record. If the input data is already in
	// RecordIO format, you don't need to set this attribute. For more information, see
	// Create a Dataset Using RecordIO
	// (https://mxnet.apache.org/api/architecture/note_data_loading#data-format). In
	// File mode, leave this field unset or set it to None.
	RecordWrapperType RecordWrapper
	// The name of the channel.
	ChannelName *string
	// If training data is compressed, the compression type. The default value is None.
	// CompressionType is used only in Pipe input mode. In File mode, leave this field
	// unset or set it to None.
	CompressionType CompressionType
	// The location of the channel data.
	DataSource *DataSource
}

// Defines a named input source, called a channel, to be used by an algorithm.
type ChannelSpecification struct {
	// The supported MIME types for the data.
	SupportedContentTypes []*string
	// Indicates whether the channel is required by the algorithm.
	IsRequired *bool
	// The allowed compression types, if data compression is used.
	SupportedCompressionTypes []CompressionType
	// A brief description of the channel.
	Description *string
	// The allowed input mode, either FILE or PIPE. In FILE mode, Amazon SageMaker
	// copies the data from the input source onto the local Amazon Elastic Block Store
	// (Amazon EBS) volumes before starting your training algorithm. This is the most
	// commonly used input mode. In PIPE mode, Amazon SageMaker streams input data from
	// the source directly to your algorithm without using the EBS volume.
	SupportedInputModes []TrainingInputMode
	// The name of the channel.
	Name *string
}

// Contains information about the output location for managed spot training
// checkpoint data.
type CheckpointConfig struct {
	// (Optional) The local directory where checkpoints are written. The default
	// directory is /opt/ml/checkpoints/.
	LocalPath *string
	// Identifies the S3 path where you want Amazon SageMaker to store checkpoints. For
	// example, s3://bucket-name/key-name-prefix.
	S3Uri *string
}

// Specifies summary information about a Git repository.
type CodeRepositorySummary struct {
	// The Amazon Resource Name (ARN) of the Git repository.
	CodeRepositoryArn *string
	// The date and time that the Git repository was created.
	CreationTime *time.Time
	// The date and time that the Git repository was last modified.
	LastModifiedTime *time.Time
	// Configuration details for the Git repository, including the URL where it is
	// located and the ARN of the AWS Secrets Manager secret that contains the
	// credentials used to access the repository.
	GitConfig *GitConfig
	// The name of the Git repository.
	CodeRepositoryName *string
}

// Use this parameter to configure your Amazon Cognito workforce. A single Cognito
// workforce is created using and corresponds to a single  Amazon Cognito user pool
// (https://docs.aws.amazon.com/cognito/latest/developerguide/cognito-user-identity-pools.html).
type CognitoConfig struct {
	// The client ID for your Amazon Cognito user pool.
	ClientId *string
	// A  user pool
	// (https://docs.aws.amazon.com/cognito/latest/developerguide/cognito-user-identity-pools.html)
	// is a user directory in Amazon Cognito. With a user pool, your users can sign in
	// to your web or mobile app through Amazon Cognito. Your users can also sign in
	// through social identity providers like Google, Facebook, Amazon, or Apple, and
	// through SAML identity providers.
	UserPool *string
}

// Identifies a Amazon Cognito user group. A user group can be used in on or more
// work teams.
type CognitoMemberDefinition struct {
	// An identifier for an application client. You must create the app client ID using
	// Amazon Cognito.
	ClientId *string
	// An identifier for a user pool. The user pool must be in the same region as the
	// service that you are calling.
	UserPool *string
	// An identifier for a user group.
	UserGroup *string
}

// Configuration information for tensor collections.
type CollectionConfiguration struct {
	// Parameter values for the tensor collection. The allowed parameters are "name",
	// "include_regex", "reduction_config", "save_config", "tensor_names", and
	// "save_histogram".
	CollectionParameters map[string]*string
	// The name of the tensor collection. The name must be unique relative to other
	// rule configuration names.
	CollectionName *string
}

// A summary of a model compilation job.
type CompilationJobSummary struct {
	// The type of OS that the model will run on after the compilation job has
	// completed.
	CompilationTargetPlatformOs TargetPlatformOs
	// The type of device that the model will run on after the compilation job has
	// completed.
	CompilationTargetDevice TargetDevice
	// The type of architecture that the model will run on after the compilation job
	// has completed.
	CompilationTargetPlatformArch TargetPlatformArch
	// The time when the model compilation job completed.
	CompilationEndTime *time.Time
	// The type of accelerator that the model will run on after the compilation job has
	// completed.
	CompilationTargetPlatformAccelerator TargetPlatformAccelerator
	// The time when the model compilation job was created.
	CreationTime *time.Time
	// The time when the model compilation job was last modified.
	LastModifiedTime *time.Time
	// The time when the model compilation job started.
	CompilationStartTime *time.Time
	// The Amazon Resource Name (ARN) of the model compilation job.
	CompilationJobArn *string
	// The name of the model compilation job that you want a summary for.
	CompilationJobName *string
	// The status of the model compilation job.
	CompilationJobStatus CompilationJobStatus
}

// Describes the container, as part of model definition.
type ContainerDefinition struct {
	// The environment variables to set in the Docker container. Each key and value in
	// the Environment string to string map can have length of up to 1024. We support
	// up to 16 entries in the map.
	Environment map[string]*string
	// The name or Amazon Resource Name (ARN) of the model package to use to create the
	// model.
	ModelPackageName *string
	// Whether the container hosts a single model or multiple models.
	Mode ContainerMode
	// This parameter is ignored for models that contain only a PrimaryContainer. When
	// a ContainerDefinition is part of an inference pipeline, the value of the
	// parameter uniquely identifies the container for the purposes of logging and
	// metrics. For information, see Use Logs and Metrics to Monitor an Inference
	// Pipeline
	// (https://docs.aws.amazon.com/sagemaker/latest/dg/inference-pipeline-logs-metrics.html).
	// If you don't specify a value for this parameter for a ContainerDefinition that
	// is part of an inference pipeline, a unique name is automatically assigned based
	// on the position of the ContainerDefinition in the pipeline. If you specify a
	// value for the ContainerHostName for any ContainerDefinition that is part of an
	// inference pipeline, you must specify a value for the ContainerHostName parameter
	// of every ContainerDefinition in that pipeline.
	ContainerHostname *string
	// The Amazon EC2 Container Registry (Amazon ECR) path where inference code is
	// stored. If you are using your own custom algorithm instead of an algorithm
	// provided by Amazon SageMaker, the inference code must meet Amazon SageMaker
	// requirements. Amazon SageMaker supports both registry/repository[:tag] and
	// registry/repository[@digest] image path formats. For more information, see Using
	// Your Own Algorithms with Amazon SageMaker
	// (https://docs.aws.amazon.com/sagemaker/latest/dg/your-algorithms.html)
	Image *string
	// The S3 path where the model artifacts, which result from model training, are
	// stored. This path must point to a single gzip compressed tar archive (.tar.gz
	// suffix). The S3 path is required for Amazon SageMaker built-in algorithms, but
	// not if you use your own algorithms. For more information on built-in algorithms,
	// see Common Parameters
	// (https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-algo-docker-registry-paths.html).
	// If you provide a value for this parameter, Amazon SageMaker uses AWS Security
	// Token Service to download model artifacts from the S3 path you provide. AWS STS
	// is activated in your IAM user account by default. If you previously deactivated
	// AWS STS for a region, you need to reactivate AWS STS for that region. For more
	// information, see Activating and Deactivating AWS STS in an AWS Region
	// (https://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_temp_enable-regions.html)
	// in the AWS Identity and Access Management User Guide. If you use a built-in
	// algorithm to create a model, Amazon SageMaker requires that you provide a S3
	// path to the model artifacts in ModelDataUrl.
	ModelDataUrl *string
}

// A list of continuous hyperparameters to tune.
type ContinuousParameterRange struct {
	// The maximum value for the hyperparameter. The tuning job uses floating-point
	// values between MinValue value and this value for tuning.
	MaxValue *string
	// The scale that hyperparameter tuning uses to search the hyperparameter range.
	// For information about choosing a hyperparameter scale, see Hyperparameter
	// Scaling
	// (https://docs.aws.amazon.com/sagemaker/latest/dg/automatic-model-tuning-define-ranges.html#scaling-type).
	// One of the following values: Auto Amazon SageMaker hyperparameter tuning chooses
	// the best scale for the hyperparameter. Linear Hyperparameter tuning searches the
	// values in the hyperparameter range by using a linear scale. Logarithmic
	// Hyperparameter tuning searches the values in the hyperparameter range by using a
	// logarithmic scale. Logarithmic scaling works only for ranges that have only
	// values greater than 0. ReverseLogarithmic Hyperparameter tuning searches the
	// values in the hyperparameter range by using a reverse logarithmic scale. Reverse
	// logarithmic scaling works only for ranges that are entirely within the range
	// 0<=x<1.0.
	ScalingType HyperParameterScalingType
	// The name of the continuous hyperparameter to tune.
	Name *string
	// The minimum value for the hyperparameter. The tuning job uses floating-point
	// values between this value and MaxValuefor tuning.
	MinValue *string
}

// Defines the possible values for a continuous hyperparameter.
type ContinuousParameterRangeSpecification struct {
	// The minimum floating-point value allowed.
	MinValue *string
	// The maximum floating-point value allowed.
	MaxValue *string
}

//
type DataCaptureConfig struct {
	//
	EnableCapture *bool
	//
	KmsKeyId *string
	//
	DestinationS3Uri *string
	//
	InitialSamplingPercentage *int32
	//
	CaptureOptions []*CaptureOption
	//
	CaptureContentTypeHeader *CaptureContentTypeHeader
}

//
type DataCaptureConfigSummary struct {
	//
	DestinationS3Uri *string
	//
	CaptureStatus CaptureStatus
	//
	KmsKeyId *string
	//
	EnableCapture *bool
	//
	CurrentSamplingPercentage *int32
}

// The data structure used to specify the data to be used for inference in a batch
// transform job and to associate the data that is relevant to the prediction
// results in the output. The input filter provided allows you to exclude input
// data that is not needed for inference in a batch transform job. The output
// filter provided allows you to include input data relevant to interpreting the
// predictions in the output from the job. For more information, see Associate
// Prediction Results with their Corresponding Input Records
// (https://docs.aws.amazon.com/sagemaker/latest/dg/batch-transform-data-processing.html).
type DataProcessing struct {
	// A JSONPath
	// (https://docs.aws.amazon.com/sagemaker/latest/dg/batch-transform-data-processing.html#data-processing-operators)
	// expression used to select a portion of the input data to pass to the algorithm.
	// Use the InputFilter parameter to exclude fields, such as an ID column, from the
	// input. If you want Amazon SageMaker to pass the entire input dataset to the
	// algorithm, accept the default value $. Examples: "$", "$[1:]", "$.features"
	InputFilter *string
	// Specifies the source of the data to join with the transformed data. The valid
	// values are None and Input. The default value is None, which specifies not to
	// join the input with the transformed data. If you want the batch transform job to
	// join the original input data with the transformed data, set JoinSource to Input.
	// <p>For JSON or JSONLines objects, such as a JSON array, Amazon SageMaker adds
	// the transformed data to the input JSON object in an attribute called
	// <code>SageMakerOutput</code>. The joined result for JSON must be a key-value
	// pair object. If the input is not a key-value pair object, Amazon SageMaker
	// creates a new JSON file. In the new JSON file, and the input data is stored
	// under the <code>SageMakerInput</code> key and the results are stored in
	// <code>SageMakerOutput</code>.</p> <p>For CSV files, Amazon SageMaker combines
	// the transformed data with the input data at the end of the input data and stores
	// it in the output file. The joined data has the joined input data followed by the
	// transformed data and the output is a CSV file. </p>
	JoinSource JoinSource
	// A JSONPath
	// (https://docs.aws.amazon.com/sagemaker/latest/dg/batch-transform-data-processing.html#data-processing-operators)
	// expression used to select a portion of the joined dataset to save in the output
	// file for a batch transform job. If you want Amazon SageMaker to store the entire
	// input dataset in the output file, leave the default value, $. If you specify
	// indexes that aren't within the dimension size of the joined dataset, you get an
	// error. Examples: "$", "$[0,5:]", "$['id','SageMakerOutput']"
	OutputFilter *string
}

// Describes the location of the channel data.
type DataSource struct {
	// The S3 location of the data source that is associated with a channel.
	S3DataSource *S3DataSource
	// The file system that is associated with a channel.
	FileSystemDataSource *FileSystemDataSource
}

// Configuration information for the debug hook parameters, collection
// configuration, and storage paths.
type DebugHookConfig struct {
	// Configuration information for tensor collections.
	CollectionConfigurations []*CollectionConfiguration
	// Path to local storage location for tensors. Defaults to /opt/ml/output/tensors/.
	LocalPath *string
	// Configuration information for the debug hook parameters.
	HookParameters map[string]*string
	// Path to Amazon S3 storage location for tensors.
	S3OutputPath *string
}

// Configuration information for debugging rules.
type DebugRuleConfiguration struct {
	// Path to Amazon S3 storage location for rules.
	S3OutputPath *string
	// The instance type to deploy for a training job.
	InstanceType ProcessingInstanceType
	// The Amazon Elastic Container (ECR) Image for the managed rule evaluation.
	RuleEvaluatorImage *string
	// The name of the rule configuration. It must be unique relative to other rule
	// configuration names.
	RuleConfigurationName *string
	// Runtime configuration for rule container.
	RuleParameters map[string]*string
	// The size, in GB, of the ML storage volume attached to the processing instance.
	VolumeSizeInGB *int32
	// Path to local storage location for output of rules. Defaults to
	// /opt/ml/processing/output/rule/.
	LocalPath *string
}

// Information about the status of the rule evaluation.
type DebugRuleEvaluationStatus struct {
	// Timestamp when the rule evaluation status was last modified.
	LastModifiedTime *time.Time
	// Details from the rule evaluation.
	StatusDetails *string
	// The Amazon Resource Name (ARN) of the rule evaluation job.
	RuleEvaluationJobArn *string
	// Status of the rule evaluation.
	RuleEvaluationStatus RuleEvaluationStatus
	// The name of the rule configuration
	RuleConfigurationName *string
}

// Gets the Amazon EC2 Container Registry path of the docker image of the model
// that is hosted in this ProductionVariant (). If you used the
// registry/repository[:tag] form to specify the image path of the primary
// container when you created the model hosted in this ProductionVariant, the path
// resolves to a path of the form registry/repository[@digest]. A digest is a hash
// value that identifies a specific version of an image. For information about
// Amazon ECR paths, see Pulling an Image
// (https://docs.aws.amazon.com/AmazonECR/latest/userguide/docker-pull-ecr-image.html)
// in the Amazon ECR User Guide.
type DeployedImage struct {
	// The date and time when the image path for the model resolved to the
	// ResolvedImage
	ResolutionTime *time.Time
	// The specific digest path of the image hosted in this ProductionVariant.
	ResolvedImage *string
	// The image path you specified when you created the model.
	SpecifiedImage *string
}

// Specifies weight and capacity values for a production variant.
type DesiredWeightAndCapacity struct {
	// The name of the variant to update.
	VariantName *string
	// The variant's capacity.
	DesiredInstanceCount *int32
	// The variant's weight.
	DesiredWeight *float32
}

// The domain's details.
type DomainDetails struct {
	// The domain name.
	DomainName *string
	// The domain ID.
	DomainId *string
	// The status.
	Status DomainStatus
	// The creation time.
	CreationTime *time.Time
	// The last modified time.
	LastModifiedTime *time.Time
	// The domain's URL.
	Url *string
	// The domain's Amazon Resource Name (ARN).
	DomainArn *string
}

// Provides summary information for an endpoint configuration.
type EndpointConfigSummary struct {
	// The name of the endpoint configuration.
	EndpointConfigName *string
	// A timestamp that shows when the endpoint configuration was created.
	CreationTime *time.Time
	// The Amazon Resource Name (ARN) of the endpoint configuration.
	EndpointConfigArn *string
}

// Input object for the endpoint
type EndpointInput struct {
	// An endpoint in customer's account which has enabled DataCaptureConfig enabled.
	EndpointName *string
	// Whether the Pipe or File is used as the input mode for transfering data for the
	// monitoring job. Pipe mode is recommended for large datasets. File mode is useful
	// for small files that fit in memory. Defaults to File.
	S3InputMode ProcessingS3InputMode
	// Whether input data distributed in Amazon S3 is fully replicated or sharded by an
	// S3 key. Defauts to FullyReplicated
	S3DataDistributionType ProcessingS3DataDistributionType
	// Path to the filesystem where the endpoint data is available to the container.
	LocalPath *string
}

// Provides summary information for an endpoint.
type EndpointSummary struct {
	// The name of the endpoint.
	EndpointName *string
	// The status of the endpoint.
	//
	//     * OutOfService: Endpoint is not available to
	// take incoming requests.
	//
	//     * Creating: CreateEndpoint () is executing.
	//
	//     *
	// Updating: UpdateEndpoint () or UpdateEndpointWeightsAndCapacities () is
	// executing.
	//
	//     * SystemUpdating: Endpoint is undergoing maintenance and cannot
	// be updated or deleted or re-scaled until it has completed. This maintenance
	// operation does not change any customer-specified values such as VPC config, KMS
	// encryption, model, instance type, or instance count.
	//
	//     * RollingBack:
	// Endpoint fails to scale up or down or change its variant weight and is in the
	// process of rolling back to its previous configuration. Once the rollback
	// completes, endpoint returns to an InService status. This transitional status
	// only applies to an endpoint that has autoscaling enabled and is undergoing
	// variant weight or capacity changes as part of an
	// UpdateEndpointWeightsAndCapacities () call or when the
	// UpdateEndpointWeightsAndCapacities () operation is called explicitly.
	//
	//     *
	// InService: Endpoint is available to process incoming requests.
	//
	//     * Deleting:
	// DeleteEndpoint () is executing.
	//
	//     * Failed: Endpoint could not be created,
	// updated, or re-scaled. Use DescribeEndpointOutput$FailureReason () for
	// information about the failure. DeleteEndpoint () is the only operation that can
	// be performed on a failed endpoint.
	//
	// To get a list of endpoints with a specified
	// status, use the ListEndpointsInput$StatusEquals () filter.
	EndpointStatus EndpointStatus
	// The Amazon Resource Name (ARN) of the endpoint.
	EndpointArn *string
	// A timestamp that shows when the endpoint was created.
	CreationTime *time.Time
	// A timestamp that shows when the endpoint was last modified.
	LastModifiedTime *time.Time
}

// The properties of an experiment as returned by the Search () API.
type Experiment struct {
	// The list of tags that are associated with the experiment. You can use Search ()
	// API to search on the tags.
	Tags []*Tag
	// The source of the experiment.
	Source *ExperimentSource
	// Information about the user who created or modified an experiment, trial, or
	// trial component.
	LastModifiedBy *UserContext
	// The description of the experiment.
	Description *string
	// Information about the user who created or modified an experiment, trial, or
	// trial component.
	CreatedBy *UserContext
	// The name of the experiment.
	ExperimentName *string
	// The Amazon Resource Name (ARN) of the experiment.
	ExperimentArn *string
	// The name of the experiment as displayed. If DisplayName isn't specified,
	// ExperimentName is displayed.
	DisplayName *string
	// When the experiment was last modified.
	LastModifiedTime *time.Time
	// When the experiment was created.
	CreationTime *time.Time
}

// Associates a SageMaker job as a trial component with an experiment and trial.
// Specified when you call the following APIs:
//
//     * CreateProcessingJob ()
//
//     *
// CreateTrainingJob ()
//
//     * CreateTransformJob ()
type ExperimentConfig struct {
	// The name of an existing trial to associate the trial component with. If not
	// specified, a new trial is created.
	TrialName *string
	// The name of an existing experiment to associate the trial component with.
	ExperimentName *string
	// The display name for the trial component. If this key isn't specified, the
	// display name is the trial component name.
	TrialComponentDisplayName *string
}

// The source of the experiment.
type ExperimentSource struct {
	// The Amazon Resource Name (ARN) of the source.
	SourceArn *string
	// The source type.
	SourceType *string
}

// A summary of the properties of an experiment. To get the complete set of
// properties, call the DescribeExperiment () API and provide the ExperimentName.
type ExperimentSummary struct {
	// The source of the experiment.
	ExperimentSource *ExperimentSource
	// The name of the experiment.
	ExperimentName *string
	// The Amazon Resource Name (ARN) of the experiment.
	ExperimentArn *string
	// When the experiment was created.
	CreationTime *time.Time
	// When the experiment was last modified.
	LastModifiedTime *time.Time
	// The name of the experiment as displayed. If DisplayName isn't specified,
	// ExperimentName is displayed.
	DisplayName *string
}

// Specifies a file system data source for a channel.
type FileSystemDataSource struct {
	// The full path to the directory to associate with the channel.
	DirectoryPath *string
	// The access mode of the mount of the directory associated with the channel. A
	// directory can be mounted either in ro (read-only) or rw (read-write) mode.
	FileSystemAccessMode FileSystemAccessMode
	// The file system type.
	FileSystemType FileSystemType
	// The file system id.
	FileSystemId *string
}

// A conditional statement for a search expression that includes a resource
// property, a Boolean operator, and a value. Resources that match the statement
// are returned in the results from the Search () API.  <p>If you specify a
// <code>Value</code>, but not an <code>Operator</code>, Amazon SageMaker uses the
// equals operator.</p> <p>In search, there are several property types:</p> <dl>
// <dt>Metrics</dt> <dd> <p>To define a metric filter, enter a value using the form
// <code>"Metrics.<name>"</code>, where <code><name></code> is a metric name. For
// example, the following filter searches for training jobs with an
// <code>"accuracy"</code> metric greater than <code>"0.9"</code>:</p> <p>
// <code>{</code> </p> <p> <code>"Name": "Metrics.accuracy",</code> </p> <p>
// <code>"Operator": "GreaterThan",</code> </p> <p> <code>"Value": "0.9"</code>
// </p> <p> <code>}</code> </p> </dd> <dt>HyperParameters</dt> <dd> <p>To define a
// hyperparameter filter, enter a value with the form
// <code>"HyperParameters.<name>"</code>. Decimal hyperparameter values are treated
// as a decimal in a comparison if the specified <code>Value</code> is also a
// decimal value. If the specified <code>Value</code> is an integer, the decimal
// hyperparameter values are treated as integers. For example, the following filter
// is satisfied by training jobs with a <code>"learning_rate"</code> hyperparameter
// that is less than <code>"0.5"</code>:</p> <p> <code> {</code> </p> <p> <code>
// "Name": "HyperParameters.learning_rate",</code> </p> <p> <code> "Operator":
// "LessThan",</code> </p> <p> <code> "Value": "0.5"</code> </p> <p> <code>
// }</code> </p> </dd> <dt>Tags</dt> <dd> <p>To define a tag filter, enter a value
// with the form <code>Tags.<key></code>.</p> </dd> </dl>
type Filter struct {
	// A value used with Name and Operator to determine which resources satisfy the
	// filter's condition. For numerical properties, Value must be an integer or
	// floating-point decimal. For timestamp properties, Value must be an ISO 8601
	// date-time string of the following format: YYYY-mm-dd'T'HH:MM:SS.
	Value *string
	// A resource property name. For example, TrainingJobName. For valid property
	// names, see SearchRecord (). You must specify a valid property for the resource.
	Name *string
	// A Boolean binary operator that is used to evaluate the filter. The operator
	// field contains one of the following values: Equals The value of Name equals
	// Value. NotEquals The value of Name doesn't equal Value. Exists The Name property
	// exists. NotExists The Name property does not exist. GreaterThan The value of
	// Name is greater than Value. Not supported for text properties.
	// GreaterThanOrEqualTo The value of Name is greater than or equal to Value. Not
	// supported for text properties. LessThan The value of Name is less than Value.
	// Not supported for text properties. LessThanOrEqualTo The value of Name is less
	// than or equal to Value. Not supported for text properties. In The value of Name
	// is one of the comma delimited strings in Value. Only supported for text
	// properties. Contains The value of Name contains the string Value. Only supported
	// for text properties. A SearchExpression can include the Contains operator
	// multiple times when the value of Name is one of the following:
	//
	//     *
	// Experiment.DisplayName
	//
	//     * Experiment.ExperimentName
	//
	//     * Experiment.Tags
	//
	//
	// * Trial.DisplayName
	//
	//     * Trial.TrialName
	//
	//     * Trial.Tags
	//
	//     *
	// TrialComponent.DisplayName
	//
	//     * TrialComponent.TrialComponentName
	//
	//     *
	// TrialComponent.Tags
	//
	//     * TrialComponent.InputArtifacts
	//
	//     *
	// TrialComponent.OutputArtifacts
	//
	// A SearchExpression can include only one Contains
	// operator for all other values of Name. In these cases, if you include multiple
	// Contains operators in the SearchExpression, the result is the following error
	// message: "'CONTAINS' operator usage limit of 1 exceeded."
	Operator Operator
}

// The candidate result from a job.
type FinalAutoMLJobObjectiveMetric struct {
	// The value of the metric.
	Value *float32
	// The metric type used.
	Type AutoMLJobObjectiveType
	// The name of the metric.
	MetricName AutoMLMetricEnum
}

// Shows the final value for the objective metric for a training job that was
// launched by a hyperparameter tuning job. You define the objective metric in the
// HyperParameterTuningJobObjective parameter of HyperParameterTuningJobConfig ().
type FinalHyperParameterTuningJobObjectiveMetric struct {
	// Whether to minimize or maximize the objective metric. Valid values are Minimize
	// and Maximize.
	Type HyperParameterTuningJobObjectiveType
	// The value of the objective metric.
	Value *float32
	// The name of the objective metric.
	MetricName *string
}

// Contains information about where human output will be stored.
type FlowDefinitionOutputConfig struct {
	// The Amazon Key Management Service (KMS) key ID for server-side encryption.
	KmsKeyId *string
	// The Amazon S3 path where the object containing human output will be made
	// available.
	S3OutputPath *string
}

// Contains summary information about the flow definition.
type FlowDefinitionSummary struct {
	// The timestamp when SageMaker created the flow definition.
	CreationTime *time.Time
	// The reason why the flow definition creation failed. A failure reason is returned
	// only when the flow definition status is Failed.
	FailureReason *string
	// The status of the flow definition. Valid values:
	FlowDefinitionStatus FlowDefinitionStatus
	// The Amazon Resource Name (ARN) of the flow definition.
	FlowDefinitionArn *string
	// The name of the flow definition.
	FlowDefinitionName *string
}

// Specifies configuration details for a Git repository in your AWS account.
type GitConfig struct {
	// The default branch for the Git repository.
	Branch *string
	// The Amazon Resource Name (ARN) of the AWS Secrets Manager secret that contains
	// the credentials used to access the git repository. The secret must have a
	// staging label of AWSCURRENT and must be in the following format: {"username":
	// UserName, "password": Password}
	SecretArn *string
	// The URL where the Git repository is located.
	RepositoryUrl *string
}

// Specifies configuration details for a Git repository when the repository is
// updated.
type GitConfigForUpdate struct {
	// The Amazon Resource Name (ARN) of the AWS Secrets Manager secret that contains
	// the credentials used to access the git repository. The secret must have a
	// staging label of AWSCURRENT and must be in the following format: {"username":
	// UserName, "password": Password}
	SecretArn *string
}

// Defines under what conditions SageMaker creates a human loop. Used within . See
// for the required format of activation conditions.
type HumanLoopActivationConditionsConfig struct {
	// JSON expressing use-case specific conditions declaratively. If any condition is
	// matched, atomic tasks are created against the configured work team. The set of
	// conditions is different for Rekognition and Textract. For more information about
	// how to structure the JSON, see JSON Schema for Human Loop Activation Conditions
	// in Amazon Augmented AI
	// (https://docs.aws.amazon.com/sagemaker/latest/dg/a2i-human-fallback-conditions-json-schema.html)
	// in the Amazon SageMaker Developer Guide.
	// This value conforms to the media type: application/json
	HumanLoopActivationConditions *string
}

// Provides information about how and under what conditions SageMaker creates a
// human loop. If HumanLoopActivationConfig is not given, then all requests go to
// humans.
type HumanLoopActivationConfig struct {
	// Container structure for defining under what conditions SageMaker creates a human
	// loop.
	HumanLoopActivationConditionsConfig *HumanLoopActivationConditionsConfig
}

// Describes the work to be performed by human workers.
type HumanLoopConfig struct {
	// Defines the amount of money paid to an Amazon Mechanical Turk worker for each
	// task performed. Use one of the following prices for bounding box tasks. Prices
	// are in US dollars and should be based on the complexity of the task; the longer
	// it takes in your initial testing, the more you should offer.
	//
	//     * 0.036
	//
	//     *
	// 0.048
	//
	//     * 0.060
	//
	//     * 0.072
	//
	//     * 0.120
	//
	//     * 0.240
	//
	//     * 0.360
	//
	//     *
	// 0.480
	//
	//     * 0.600
	//
	//     * 0.720
	//
	//     * 0.840
	//
	//     * 0.960
	//
	//     * 1.080
	//
	//     *
	// 1.200
	//
	// Use one of the following prices for image classification, text
	// classification, and custom tasks. Prices are in US dollars.
	//
	//     * 0.012
	//
	//     *
	// 0.024
	//
	//     * 0.036
	//
	//     * 0.048
	//
	//     * 0.060
	//
	//     * 0.072
	//
	//     * 0.120
	//
	//     *
	// 0.240
	//
	//     * 0.360
	//
	//     * 0.480
	//
	//     * 0.600
	//
	//     * 0.720
	//
	//     * 0.840
	//
	//     *
	// 0.960
	//
	//     * 1.080
	//
	//     * 1.200
	//
	// Use one of the following prices for semantic
	// segmentation tasks. Prices are in US dollars.
	//
	//     * 0.840
	//
	//     * 0.960
	//
	//     *
	// 1.080
	//
	//     * 1.200
	//
	// Use one of the following prices for Textract AnalyzeDocument
	// Important Form Key Amazon Augmented AI review tasks. Prices are in US dollars.
	//
	//
	// * 2.400
	//
	//     * 2.280
	//
	//     * 2.160
	//
	//     * 2.040
	//
	//     * 1.920
	//
	//     * 1.800
	//
	//     *
	// 1.680
	//
	//     * 1.560
	//
	//     * 1.440
	//
	//     * 1.320
	//
	//     * 1.200
	//
	//     * 1.080
	//
	//     *
	// 0.960
	//
	//     * 0.840
	//
	//     * 0.720
	//
	//     * 0.600
	//
	//     * 0.480
	//
	//     * 0.360
	//
	//     *
	// 0.240
	//
	//     * 0.120
	//
	//     * 0.072
	//
	//     * 0.060
	//
	//     * 0.048
	//
	//     * 0.036
	//
	//     *
	// 0.024
	//
	//     * 0.012
	//
	// Use one of the following prices for Rekognition
	// DetectModerationLabels Amazon Augmented AI review tasks. Prices are in US
	// dollars.
	//
	//     * 1.200
	//
	//     * 1.080
	//
	//     * 0.960
	//
	//     * 0.840
	//
	//     * 0.720
	//
	//     *
	// 0.600
	//
	//     * 0.480
	//
	//     * 0.360
	//
	//     * 0.240
	//
	//     * 0.120
	//
	//     * 0.072
	//
	//     *
	// 0.060
	//
	//     * 0.048
	//
	//     * 0.036
	//
	//     * 0.024
	//
	//     * 0.012
	//
	// Use one of the
	// following prices for Amazon Augmented AI custom human review tasks. Prices are
	// in US dollars.
	//
	//     * 1.200
	//
	//     * 1.080
	//
	//     * 0.960
	//
	//     * 0.840
	//
	//     *
	// 0.720
	//
	//     * 0.600
	//
	//     * 0.480
	//
	//     * 0.360
	//
	//     * 0.240
	//
	//     * 0.120
	//
	//     *
	// 0.072
	//
	//     * 0.060
	//
	//     * 0.048
	//
	//     * 0.036
	//
	//     * 0.024
	//
	//     * 0.012
	PublicWorkforceTaskPrice *PublicWorkforceTaskPrice
	// The amount of time that a worker has to complete a task.
	TaskTimeLimitInSeconds *int32
	// The number of distinct workers who will perform the same task on each object.
	// For example, if TaskCount is set to 3 for an image classification labeling job,
	// three workers will classify each input image. Increasing TaskCount can improve
	// label accuracy.
	TaskCount *int32
	// Keywords used to describe the task so that workers can discover the task.
	TaskKeywords []*string
	// The length of time that a task remains available for labeling by human workers.
	TaskAvailabilityLifetimeInSeconds *int32
	// A title for the human worker task.
	TaskTitle *string
	// The Amazon Resource Name (ARN) of the human task user interface.
	HumanTaskUiArn *string
	// A description for the human worker task.
	TaskDescription *string
	// Amazon Resource Name (ARN) of a team of workers.
	WorkteamArn *string
}

// Container for configuring the source of human task requests.
type HumanLoopRequestSource struct {
	// Specifies whether Amazon Rekognition or Amazon Textract are used as the
	// integration source. The default field settings and JSON parsing rules are
	// different based on the integration source. Valid values:
	AwsManagedHumanLoopRequestSource AwsManagedHumanLoopRequestSource
}

// Information required for human workers to complete a labeling task.
type HumanTaskConfig struct {
	// The Amazon Resource Name (ARN) of the work team assigned to complete the tasks.
	WorkteamArn *string
	// Defines the maximum number of data objects that can be labeled by human workers
	// at the same time. Also referred to as batch size. Each object may have more than
	// one worker at one time. The default value is 1000 objects.
	MaxConcurrentTaskCount *int32
	// Configures how labels are consolidated across human workers.
	AnnotationConsolidationConfig *AnnotationConsolidationConfig
	// Information about the user interface that workers use to complete the labeling
	// task.
	UiConfig *UiConfig
	// Keywords used to describe the task so that workers on Amazon Mechanical Turk can
	// discover the task.
	TaskKeywords []*string
	// The amount of time that a worker has to complete a task.
	TaskTimeLimitInSeconds *int32
	// A title for the task for your human workers.
	TaskTitle *string
	// The Amazon Resource Name (ARN) of a Lambda function that is run before a data
	// object is sent to a human worker. Use this function to provide input to a custom
	// labeling job. For built-in task types
	// (https://docs.aws.amazon.com/sagemaker/latest/dg/sms-task-types.html), use one
	// of the following Amazon SageMaker Ground Truth Lambda function ARNs for
	// PreHumanTaskLambdaArn. For custom labeling workflows, see Pre-annotation Lambda
	// (https://docs.aws.amazon.com/sagemaker/latest/dg/sms-custom-templates-step3.html#sms-custom-templates-step3-prelambda).
	// <p> <b>Bounding box</b> - Finds the most similar boxes from different workers
	// based on the Jaccard index of the boxes.</p> <ul> <li> <p>
	// <code>arn:aws:lambda:us-east-1:432418664414:function:PRE-BoundingBox</code> </p>
	// </li> <li> <p>
	// <code>arn:aws:lambda:us-east-2:266458841044:function:PRE-BoundingBox</code> </p>
	// </li> <li> <p>
	// <code>arn:aws:lambda:us-west-2:081040173940:function:PRE-BoundingBox</code> </p>
	// </li> <li> <p>
	// <code>arn:aws:lambda:ca-central-1:918755190332:function:PRE-BoundingBox</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:eu-west-1:568282634449:function:PRE-BoundingBox</code> </p>
	// </li> <li> <p>
	// <code>arn:aws:lambda:eu-west-2:487402164563:function:PRE-BoundingBox</code> </p>
	// </li> <li> <p>
	// <code>arn:aws:lambda:eu-central-1:203001061592:function:PRE-BoundingBox</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:ap-northeast-1:477331159723:function:PRE-BoundingBox</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:ap-northeast-2:845288260483:function:PRE-BoundingBox</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:ap-south-1:565803892007:function:PRE-BoundingBox</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:ap-southeast-1:377565633583:function:PRE-BoundingBox</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:ap-southeast-2:454466003867:function:PRE-BoundingBox</code>
	// </p> </li> </ul> <p> <b>Image classification</b> - Uses a variant of the
	// Expectation Maximization approach to estimate the true class of an image based
	// on annotations from individual workers.</p> <ul> <li> <p>
	// <code>arn:aws:lambda:us-east-1:432418664414:function:PRE-ImageMultiClass</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:us-east-2:266458841044:function:PRE-ImageMultiClass</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:us-west-2:081040173940:function:PRE-ImageMultiClass</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:ca-central-1:918755190332:function:PRE-ImageMultiClass</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:eu-west-1:568282634449:function:PRE-ImageMultiClass</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:eu-west-2:487402164563:function:PRE-ImageMultiClass</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:eu-central-1:203001061592:function:PRE-ImageMultiClass</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:ap-northeast-1:477331159723:function:PRE-ImageMultiClass</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:ap-northeast-2:845288260483:function:PRE-ImageMultiClass</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:ap-south-1:565803892007:function:PRE-ImageMultiClass</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:ap-southeast-1:377565633583:function:PRE-ImageMultiClass</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:ap-southeast-2:454466003867:function:PRE-ImageMultiClass</code>
	// </p> </li> </ul> <p> <b>Multi-label image classification</b> - Uses a variant of
	// the Expectation Maximization approach to estimate the true classes of an image
	// based on annotations from individual workers.</p> <ul> <li> <p>
	// <code>arn:aws:lambda:us-east-1:432418664414:function:PRE-ImageMultiClassMultiLabel</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:us-east-2:266458841044:function:PRE-ImageMultiClassMultiLabel</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:us-west-2:081040173940:function:PRE-ImageMultiClassMultiLabel</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:ca-central-1:918755190332:function:PRE-ImageMultiClassMultiLabel</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:eu-west-1:568282634449:function:PRE-ImageMultiClassMultiLabel</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:eu-west-2:487402164563:function:PRE-ImageMultiClassMultiLabel</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:eu-central-1:203001061592:function:PRE-ImageMultiClassMultiLabel</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:ap-northeast-1:477331159723:function:PRE-ImageMultiClassMultiLabel</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:ap-northeast-2:845288260483:function:PRE-ImageMultiClassMultiLabel</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:ap-south-1:565803892007:function:PRE-ImageMultiClassMultiLabel</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:ap-southeast-1:377565633583:function:PRE-ImageMultiClassMultiLabel</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:ap-southeast-2:454466003867:function:PRE-ImageMultiClassMultiLabel</code>
	// </p> </li> </ul> <p> <b>Semantic segmentation</b> - Treats each pixel in an
	// image as a multi-class classification and treats pixel annotations from workers
	// as "votes" for the correct label.</p> <ul> <li> <p>
	// <code>arn:aws:lambda:us-east-1:432418664414:function:PRE-SemanticSegmentation</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:us-east-2:266458841044:function:PRE-SemanticSegmentation</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:us-west-2:081040173940:function:PRE-SemanticSegmentation</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:ca-central-1:918755190332:function:PRE-SemanticSegmentation</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:eu-west-1:568282634449:function:PRE-SemanticSegmentation</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:eu-west-2:487402164563:function:PRE-SemanticSegmentation</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:eu-central-1:203001061592:function:PRE-SemanticSegmentation</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:ap-northeast-1:477331159723:function:PRE-SemanticSegmentation</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:ap-northeast-2:845288260483:function:PRE-SemanticSegmentation</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:ap-south-1:565803892007:function:PRE-SemanticSegmentation</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:ap-southeast-1:377565633583:function:PRE-SemanticSegmentation</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:ap-southeast-2:454466003867:function:PRE-SemanticSegmentation</code>
	// </p> </li> </ul> <p> <b>Text classification</b> - Uses a variant of the
	// Expectation Maximization approach to estimate the true class of text based on
	// annotations from individual workers.</p> <ul> <li> <p>
	// <code>arn:aws:lambda:us-east-1:432418664414:function:PRE-TextMultiClass</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:us-east-2:266458841044:function:PRE-TextMultiClass</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:us-west-2:081040173940:function:PRE-TextMultiClass</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:ca-central-1:918755190332:function:PRE-TextMultiClass</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:eu-west-1:568282634449:function:PRE-TextMultiClass</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:eu-west-2:487402164563:function:PRE-TextMultiClass</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:eu-central-1:203001061592:function:PRE-TextMultiClass</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:ap-northeast-1:477331159723:function:PRE-TextMultiClass</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:ap-northeast-2:845288260483:function:PRE-TextMultiClass</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:ap-south-1:565803892007:function:PRE-TextMultiClass</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:ap-southeast-1:377565633583:function:PRE-TextMultiClass</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:ap-southeast-2:454466003867:function:PRE-TextMultiClass</code>
	// </p> </li> </ul> <p> <b>Multi-label text classification</b> - Uses a variant of
	// the Expectation Maximization approach to estimate the true classes of text based
	// on annotations from individual workers.</p> <ul> <li> <p>
	// <code>arn:aws:lambda:us-east-1:432418664414:function:PRE-TextMultiClassMultiLabel</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:us-east-2:266458841044:function:PRE-TextMultiClassMultiLabel</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:us-west-2:081040173940:function:PRE-TextMultiClassMultiLabel</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:ca-central-1:918755190332:function:PRE-TextMultiClassMultiLabel</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:eu-west-1:568282634449:function:PRE-TextMultiClassMultiLabel</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:eu-west-2:487402164563:function:PRE-TextMultiClassMultiLabel</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:eu-central-1:203001061592:function:PRE-TextMultiClassMultiLabel</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:ap-northeast-1:477331159723:function:PRE-TextMultiClassMultiLabel</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:ap-northeast-2:845288260483:function:PRE-TextMultiClassMultiLabel</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:ap-south-1:565803892007:function:PRE-TextMultiClassMultiLabel</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:ap-southeast-1:377565633583:function:PRE-TextMultiClassMultiLabel</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:ap-southeast-2:454466003867:function:PRE-TextMultiClassMultiLabel</code>
	// </p> </li> </ul> <p> <b>Named entity recognition</b> - Groups similar selections
	// and calculates aggregate boundaries, resolving to most-assigned label.</p> <ul>
	// <li> <p>
	// <code>arn:aws:lambda:us-east-1:432418664414:function:PRE-NamedEntityRecognition</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:us-east-2:266458841044:function:PRE-NamedEntityRecognition</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:us-west-2:081040173940:function:PRE-NamedEntityRecognition</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:ca-central-1:918755190332:function:PRE-NamedEntityRecognition</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:eu-west-1:568282634449:function:PRE-NamedEntityRecognition</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:eu-west-2:487402164563:function:PRE-NamedEntityRecognition</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:eu-central-1:203001061592:function:PRE-NamedEntityRecognition</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:ap-northeast-1:477331159723:function:PRE-NamedEntityRecognition</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:ap-northeast-2:845288260483:function:PRE-NamedEntityRecognition</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:ap-south-1:565803892007:function:PRE-NamedEntityRecognition</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:ap-southeast-1:377565633583:function:PRE-NamedEntityRecognition</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:ap-southeast-2:454466003867:function:PRE-NamedEntityRecognition</code>
	// </p> </li> </ul> <p> <b>Video Classification</b> - Use this task type when you
	// need workers to classify videos using predefined labels that you specify.
	// Workers are shown videos and are asked to choose one label for each video.</p>
	// <ul> <li> <p>
	// <code>arn:aws:lambda:us-east-1:432418664414:function:PRE-VideoMultiClass</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:us-east-2:266458841044:function:PRE-VideoMultiClass</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:us-west-2:081040173940:function:PRE-VideoMultiClass</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:eu-west-1:568282634449:function:PRE-VideoMultiClass</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:ap-northeast-1:477331159723:function:PRE-VideoMultiClass</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:ap-southeast-2:454466003867:function:PRE-VideoMultiClass</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:ap-south-1:565803892007:function:PRE-VideoMultiClass</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:eu-central-1:203001061592:function:PRE-VideoMultiClass</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:ap-northeast-2:845288260483:function:PRE-VideoMultiClass</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:eu-west-2:487402164563:function:PRE-VideoMultiClass</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:ap-southeast-1:377565633583:function:PRE-VideoMultiClass</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:ca-central-1:918755190332:function:PRE-VideoMultiClass</code>
	// </p> </li> </ul> <p> <b>Video Frame Object Detection</b> - Use this task type to
	// have workers identify and locate objects in a sequence of video frames (images
	// extracted from a video) using bounding boxes. For example, you can use this task
	// to ask workers to identify and localize various objects in a series of video
	// frames, such as cars, bikes, and pedestrians.</p> <ul> <li> <p>
	// <code>arn:aws:lambda:us-east-1:432418664414:function:PRE-VideoObjectDetection</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:us-east-2:266458841044:function:PRE-VideoObjectDetection</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:us-west-2:081040173940:function:PRE-VideoObjectDetection</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:eu-west-1:568282634449:function:PRE-VideoObjectDetection</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:ap-northeast-1:477331159723:function:PRE-VideoObjectDetection</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:ap-southeast-2:454466003867:function:PRE-VideoObjectDetection</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:ap-south-1:565803892007:function:PRE-VideoObjectDetection</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:eu-central-1:203001061592:function:PRE-VideoObjectDetection</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:ap-northeast-2:845288260483:function:PRE-VideoObjectDetection</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:eu-west-2:487402164563:function:PRE-VideoObjectDetection</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:ap-southeast-1:377565633583:function:PRE-VideoObjectDetection</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:ca-central-1:918755190332:function:PRE-VideoObjectDetection</code>
	// </p> </li> </ul> <p> <b>Video Frame Object Tracking</b> - Use this task type to
	// have workers track the movement of objects in a sequence of video frames (images
	// extracted from a video) using bounding boxes. For example, you can use this task
	// to ask workers to track the movement of objects, such as cars, bikes, and
	// pedestrians. </p> <ul> <li> <p>
	// <code>arn:aws:lambda:us-east-1:432418664414:function:PRE-VideoObjectTracking</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:us-east-2:266458841044:function:PRE-VideoObjectTracking</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:us-west-2:081040173940:function:PRE-VideoObjectTracking</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:eu-west-1:568282634449:function:PRE-VideoObjectTracking</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:ap-northeast-1:477331159723:function:PRE-VideoObjectTracking</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:ap-southeast-2:454466003867:function:PRE-VideoObjectTracking</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:ap-south-1:565803892007:function:PRE-VideoObjectTracking</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:eu-central-1:203001061592:function:PRE-VideoObjectTracking</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:ap-northeast-2:845288260483:function:PRE-VideoObjectTracking</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:eu-west-2:487402164563:function:PRE-VideoObjectTracking</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:ap-southeast-1:377565633583:function:PRE-VideoObjectTracking</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:ca-central-1:918755190332:function:PRE-VideoObjectTracking</code>
	// </p> </li> </ul> <p> <b>3D Point Cloud Modalities</b> </p> <p>Use the following
	// pre-annotation lambdas for 3D point cloud labeling modality tasks. See <a
	// href="https://docs.aws.amazon.com/sagemaker/latest/dg/sms-point-cloud-task-types.html">3D
	// Point Cloud Task types </a> to learn more. </p> <p> <b>3D Point Cloud Object
	// Detection</b> - Use this task type when you want workers to classify objects in
	// a 3D point cloud by drawing 3D cuboids around objects. For example, you can use
	// this task type to ask workers to identify different types of objects in a point
	// cloud, such as cars, bikes, and pedestrians.</p> <ul> <li> <p>
	// <code>arn:aws:lambda:us-east-1:432418664414:function:PRE-3DPointCloudObjectDetection</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:us-east-2:266458841044:function:PRE-3DPointCloudObjectDetection</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:us-west-2:081040173940:function:PRE-3DPointCloudObjectDetection</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:eu-west-1:568282634449:function:PRE-3DPointCloudObjectDetection</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:ap-northeast-1:477331159723:function:PRE-3DPointCloudObjectDetection</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:ap-southeast-2:454466003867:function:PRE-3DPointCloudObjectDetection</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:ap-south-1:565803892007:function:PRE-3DPointCloudObjectDetection</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:eu-central-1:203001061592:function:PRE-3DPointCloudObjectDetection</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:ap-northeast-2:845288260483:function:PRE-3DPointCloudObjectDetection</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:eu-west-2:487402164563:function:PRE-3DPointCloudObjectDetection</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:ap-southeast-1:377565633583:function:PRE-3DPointCloudObjectDetection</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:ca-central-1:918755190332:function:PRE-3DPointCloudObjectDetection</code>
	// </p> </li> </ul> <p> <b>3D Point Cloud Object Tracking</b> - Use this task type
	// when you want workers to draw 3D cuboids around objects that appear in a
	// sequence of 3D point cloud frames. For example, you can use this task type to
	// ask workers to track the movement of vehicles across multiple point cloud
	// frames. </p> <ul> <li> <p>
	// <code>arn:aws:lambda:us-east-1:432418664414:function:PRE-3DPointCloudObjectTracking</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:us-east-2:266458841044:function:PRE-3DPointCloudObjectTracking</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:us-west-2:081040173940:function:PRE-3DPointCloudObjectTracking</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:eu-west-1:568282634449:function:PRE-3DPointCloudObjectTracking</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:ap-northeast-1:477331159723:function:PRE-3DPointCloudObjectTracking</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:ap-southeast-2:454466003867:function:PRE-3DPointCloudObjectTracking</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:ap-south-1:565803892007:function:PRE-3DPointCloudObjectTracking</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:eu-central-1:203001061592:function:PRE-3DPointCloudObjectTracking</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:ap-northeast-2:845288260483:function:PRE-3DPointCloudObjectTracking</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:eu-west-2:487402164563:function:PRE-3DPointCloudObjectTracking</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:ap-southeast-1:377565633583:function:PRE-3DPointCloudObjectTracking</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:ca-central-1:918755190332:function:PRE-3DPointCloudObjectTracking</code>
	// </p> </li> </ul> <p> <b>3D Point Cloud Semantic Segmentation</b> - Use this task
	// type when you want workers to create a point-level semantic segmentation masks
	// by painting objects in a 3D point cloud using different colors where each color
	// is assigned to one of the classes you specify.</p> <ul> <li> <p>
	// <code>arn:aws:lambda:us-east-1:432418664414:function:PRE-3DPointCloudSemanticSegmentation</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:us-east-2:266458841044:function:PRE-3DPointCloudSemanticSegmentation</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:us-west-2:081040173940:function:PRE-3DPointCloudSemanticSegmentation</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:eu-west-1:568282634449:function:PRE-3DPointCloudSemanticSegmentation</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:ap-northeast-1:477331159723:function:PRE-3DPointCloudSemanticSegmentation</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:ap-southeast-2:454466003867:function:PRE-3DPointCloudSemanticSegmentation</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:ap-south-1:565803892007:function:PRE-3DPointCloudSemanticSegmentation</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:eu-central-1:203001061592:function:PRE-3DPointCloudSemanticSegmentation</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:ap-northeast-2:845288260483:function:PRE-3DPointCloudSemanticSegmentation</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:eu-west-2:487402164563:function:PRE-3DPointCloudSemanticSegmentation</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:ap-southeast-1:377565633583:function:PRE-3DPointCloudSemanticSegmentation</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:ca-central-1:918755190332:function:PRE-3DPointCloudSemanticSegmentation</code>
	// </p> </li> </ul> <p> <b>Use the following ARNs for Label Verification and
	// Adjustment Jobs</b> </p> <p>Use label verification and adjustment jobs to review
	// and adjust labels. To learn more, see <a
	// href="https://docs.aws.amazon.com/sagemaker/latest/dg/sms-verification-data.html">Verify
	// and Adjust Labels </a>.</p> <p> <b>Bounding box verification</b> - Uses a
	// variant of the Expectation Maximization approach to estimate the true class of
	// verification judgement for bounding box labels based on annotations from
	// individual workers.</p> <ul> <li> <p>
	// <code>arn:aws:lambda:us-east-1:432418664414:function:PRE-Adjustment3DPointCloudObjectTracking</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:us-east-2:266458841044:function:PRE-Adjustment3DPointCloudObjectTracking</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:us-west-2:081040173940:function:PRE-Adjustment3DPointCloudObjectTracking</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:eu-west-1:568282634449:function:PRE-Adjustment3DPointCloudObjectTracking</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:ap-northeast-1:477331159723:function:PRE-Adjustment3DPointCloudObjectTracking</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:ap-southeast-2:454466003867:function:PRE-Adjustment3DPointCloudObjectTracking</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:ap-south-1:565803892007:function:PRE-Adjustment3DPointCloudObjectTracking</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:eu-central-1:203001061592:function:PRE-Adjustment3DPointCloudObjectTracking</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:ap-northeast-2:845288260483:function:PRE-Adjustment3DPointCloudObjectTracking</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:eu-west-2:487402164563:function:PRE-Adjustment3DPointCloudObjectTracking</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:ap-southeast-1:377565633583:function:PRE-Adjustment3DPointCloudObjectTracking</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:ca-central-1:918755190332:function:PRE-Adjustment3DPointCloudObjectTracking</code>
	// </p> </li> </ul> <p> <b>Bounding box adjustment</b> - Finds the most similar
	// boxes from different workers based on the Jaccard index of the adjusted
	// annotations.</p> <ul> <li> <p>
	// <code>arn:aws:lambda:us-east-1:432418664414:function:PRE-AdjustmentBoundingBox</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:us-east-2:266458841044:function:PRE-AdjustmentBoundingBox</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:us-west-2:081040173940:function:PRE-AdjustmentBoundingBox</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:ca-central-1:918755190332:function:PRE-AdjustmentBoundingBox</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:eu-west-1:568282634449:function:PRE-AdjustmentBoundingBox</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:eu-west-2:487402164563:function:PRE-AdjustmentBoundingBox</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:eu-central-1:203001061592:function:PRE-AdjustmentBoundingBox</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:ap-northeast-1:477331159723:function:PRE-AdjustmentBoundingBox</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:ap-northeast-2:845288260483:function:PRE-AdjustmentBoundingBox</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:ap-south-1:565803892007:function:PRE-AdjustmentBoundingBox</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:ap-southeast-1:377565633583:function:PRE-AdjustmentBoundingBox</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:ap-southeast-2:454466003867:function:PRE-AdjustmentBoundingBox</code>
	// </p> </li> </ul> <p> <b>Semantic segmentation verification</b> - Uses a variant
	// of the Expectation Maximization approach to estimate the true class of
	// verification judgment for semantic segmentation labels based on annotations from
	// individual workers.</p> <ul> <li> <p>
	// <code>arn:aws:lambda:us-east-1:432418664414:function:PRE-VerificationSemanticSegmentation</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:us-east-2:266458841044:function:PRE-VerificationSemanticSegmentation</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:us-west-2:081040173940:function:PRE-VerificationSemanticSegmentation</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:ca-central-1:918755190332:function:PRE-VerificationSemanticSegmentation</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:eu-west-1:568282634449:function:PRE-VerificationSemanticSegmentation</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:eu-west-2:487402164563:function:PRE-VerificationSemanticSegmentation</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:eu-central-1:203001061592:function:PRE-VerificationSemanticSegmentation</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:ap-northeast-1:477331159723:function:PRE-VerificationSemanticSegmentation</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:ap-northeast-2:845288260483:function:PRE-VerificationSemanticSegmentation</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:ap-south-1:565803892007:function:PRE-VerificationSemanticSegmentation</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:ap-southeast-1:377565633583:function:PRE-VerificationSemanticSegmentation</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:ap-southeast-2:454466003867:function:PRE-VerificationSemanticSegmentation</code>
	// </p> </li> </ul> <p> <b>Semantic segmentation adjustment</b> - Treats each pixel
	// in an image as a multi-class classification and treats pixel adjusted
	// annotations from workers as "votes" for the correct label.</p> <ul> <li> <p>
	// <code>arn:aws:lambda:us-east-1:432418664414:function:PRE-AdjustmentSemanticSegmentation</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:us-east-2:266458841044:function:PRE-AdjustmentSemanticSegmentation</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:us-west-2:081040173940:function:PRE-AdjustmentSemanticSegmentation</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:ca-central-1:918755190332:function:PRE-AdjustmentSemanticSegmentation</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:eu-west-1:568282634449:function:PRE-AdjustmentSemanticSegmentation</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:eu-west-2:487402164563:function:PRE-AdjustmentSemanticSegmentation</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:eu-central-1:203001061592:function:PRE-AdjustmentSemanticSegmentation</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:ap-northeast-1:477331159723:function:PRE-AdjustmentSemanticSegmentation</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:ap-northeast-2:845288260483:function:PRE-AdjustmentSemanticSegmentation</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:ap-south-1:565803892007:function:PRE-AdjustmentSemanticSegmentation</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:ap-southeast-1:377565633583:function:PRE-AdjustmentSemanticSegmentation</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:ap-southeast-2:454466003867:function:PRE-AdjustmentSemanticSegmentation</code>
	// </p> </li> </ul> <p> <b>Video Frame Object Detection Adjustment</b> - Use this
	// task type when you want workers to adjust bounding boxes that workers have added
	// to video frames to classify and localize objects in a sequence of video
	// frames.</p> <ul> <li> <p>
	// <code>arn:aws:lambda:us-east-1:432418664414:function:PRE-AdjustmentVideoObjectDetection</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:us-east-2:266458841044:function:PRE-AdjustmentVideoObjectDetection</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:us-west-2:081040173940:function:PRE-AdjustmentVideoObjectDetection</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:eu-west-1:568282634449:function:PRE-AdjustmentVideoObjectDetection</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:ap-northeast-1:477331159723:function:PRE-AdjustmentVideoObjectDetection</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:ap-southeast-2:454466003867:function:PRE-AdjustmentVideoObjectDetection</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:ap-south-1:565803892007:function:PRE-AdjustmentVideoObjectDetection</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:eu-central-1:203001061592:function:PRE-AdjustmentVideoObjectDetection</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:ap-northeast-2:845288260483:function:PRE-AdjustmentVideoObjectDetection</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:eu-west-2:487402164563:function:PRE-AdjustmentVideoObjectDetection</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:ap-southeast-1:377565633583:function:PRE-AdjustmentVideoObjectDetection</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:ca-central-1:918755190332:function:PRE-AdjustmentVideoObjectDetection</code>
	// </p> </li> </ul> <p> <b>Video Frame Object Tracking Adjustment</b> - Use this
	// task type when you want workers to adjust bounding boxes that workers have added
	// to video frames to track object movement across a sequence of video frames.</p>
	// <ul> <li> <p>
	// <code>arn:aws:lambda:us-east-1:432418664414:function:PRE-AdjustmentVideoObjectTracking</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:us-east-2:266458841044:function:PRE-AdjustmentVideoObjectTracking</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:us-west-2:081040173940:function:PRE-AdjustmentVideoObjectTracking</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:eu-west-1:568282634449:function:PRE-AdjustmentVideoObjectTracking</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:ap-northeast-1:477331159723:function:PRE-AdjustmentVideoObjectTracking</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:ap-southeast-2:454466003867:function:PRE-AdjustmentVideoObjectTracking</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:ap-south-1:565803892007:function:PRE-AdjustmentVideoObjectTracking</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:eu-central-1:203001061592:function:PRE-AdjustmentVideoObjectTracking</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:ap-northeast-2:845288260483:function:PRE-AdjustmentVideoObjectTracking</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:eu-west-2:487402164563:function:PRE-AdjustmentVideoObjectTracking</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:ap-southeast-1:377565633583:function:PRE-AdjustmentVideoObjectTracking</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:ca-central-1:918755190332:function:PRE-AdjustmentVideoObjectTracking</code>
	// </p> </li> </ul> <p> <b>3D point cloud object detection adjustment</b> - Adjust
	// 3D cuboids in a point cloud frame. </p> <ul> <li> <p>
	// <code>arn:aws:lambda:us-east-1:432418664414:function:PRE-Adjustment3DPointCloudObjectDetection</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:us-east-2:266458841044:function:PRE-Adjustment3DPointCloudObjectDetection</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:us-west-2:081040173940:function:PRE-Adjustment3DPointCloudObjectDetection</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:eu-west-1:568282634449:function:PRE-Adjustment3DPointCloudObjectDetection</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:ap-northeast-1:477331159723:function:PRE-Adjustment3DPointCloudObjectDetection</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:ap-southeast-2:454466003867:function:PRE-Adjustment3DPointCloudObjectDetection</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:ap-south-1:565803892007:function:PRE-Adjustment3DPointCloudObjectDetection</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:eu-central-1:203001061592:function:PRE-Adjustment3DPointCloudObjectDetection</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:ap-northeast-2:845288260483:function:PRE-Adjustment3DPointCloudObjectDetection</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:eu-west-2:487402164563:function:PRE-Adjustment3DPointCloudObjectDetection</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:ap-southeast-1:377565633583:function:PRE-Adjustment3DPointCloudObjectDetection</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:ca-central-1:918755190332:function:PRE-Adjustment3DPointCloudObjectDetection</code>
	// </p> </li> </ul> <p> <b>3D point cloud object tracking adjustment</b> - Adjust
	// 3D cuboids across a sequence of point cloud frames. </p> <ul> <li> <p>
	// <code>arn:aws:lambda:us-east-1:432418664414:function:PRE-Adjustment3DPointCloudObjectTracking</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:us-east-2:266458841044:function:PRE-Adjustment3DPointCloudObjectTracking</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:us-west-2:081040173940:function:PRE-Adjustment3DPointCloudObjectTracking</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:eu-west-1:568282634449:function:PRE-Adjustment3DPointCloudObjectTracking</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:ap-northeast-1:477331159723:function:PRE-Adjustment3DPointCloudObjectTracking</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:ap-southeast-2:454466003867:function:PRE-Adjustment3DPointCloudObjectTracking</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:ap-south-1:565803892007:function:PRE-Adjustment3DPointCloudObjectTracking</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:eu-central-1:203001061592:function:PRE-Adjustment3DPointCloudObjectTracking</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:ap-northeast-2:845288260483:function:PRE-Adjustment3DPointCloudObjectTracking</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:eu-west-2:487402164563:function:PRE-Adjustment3DPointCloudObjectTracking</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:ap-southeast-1:377565633583:function:PRE-Adjustment3DPointCloudObjectTracking</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:ca-central-1:918755190332:function:PRE-Adjustment3DPointCloudObjectTracking</code>
	// </p> </li> </ul> <p> <b>3D point cloud semantic segmentation adjustment</b> -
	// Adjust semantic segmentation masks in a 3D point cloud. </p> <ul> <li> <p>
	// <code>arn:aws:lambda:us-east-1:432418664414:function:PRE-Adjustment3DPointCloudSemanticSegmentation</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:us-east-2:266458841044:function:PRE-Adjustment3DPointCloudSemanticSegmentation</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:us-west-2:081040173940:function:PRE-Adjustment3DPointCloudSemanticSegmentation</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:eu-west-1:568282634449:function:PRE-Adjustment3DPointCloudSemanticSegmentation</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:ap-northeast-1:477331159723:function:PRE-Adjustment3DPointCloudSemanticSegmentation</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:ap-southeast-2:454466003867:function:PRE-Adjustment3DPointCloudSemanticSegmentation</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:ap-south-1:565803892007:function:PRE-Adjustment3DPointCloudSemanticSegmentation</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:eu-central-1:203001061592:function:PRE-Adjustment3DPointCloudSemanticSegmentation</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:ap-northeast-2:845288260483:function:PRE-Adjustment3DPointCloudSemanticSegmentation</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:eu-west-2:487402164563:function:PRE-Adjustment3DPointCloudSemanticSegmentation</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:ap-southeast-1:377565633583:function:PRE-Adjustment3DPointCloudSemanticSegmentation</code>
	// </p> </li> <li> <p>
	// <code>arn:aws:lambda:ca-central-1:918755190332:function:PRE-Adjustment3DPointCloudSemanticSegmentation</code>
	// </p> </li> </ul>
	PreHumanTaskLambdaArn *string
	// The length of time that a task remains available for labeling by human workers.
	// If you choose the Amazon Mechanical Turk workforce, the maximum is 12 hours
	// (43200). The default value is 864000 seconds (10 days). For private and vendor
	// workforces, the maximum is as listed.
	TaskAvailabilityLifetimeInSeconds *int32
	// The price that you pay for each task performed by an Amazon Mechanical Turk
	// worker.
	PublicWorkforceTaskPrice *PublicWorkforceTaskPrice
	// The number of human workers that will label an object.
	NumberOfHumanWorkersPerDataObject *int32
	// A description of the task for your human workers.
	TaskDescription *string
}

// Container for human task user interface information.
type HumanTaskUiSummary struct {
	// The Amazon Resource Name (ARN) of the human task user interface.
	HumanTaskUiArn *string
	// The name of the human task user interface.
	HumanTaskUiName *string
	// A timestamp when SageMaker created the human task user interface.
	CreationTime *time.Time
}

// Specifies which training algorithm to use for training jobs that a
// hyperparameter tuning job launches and the metrics to monitor.
type HyperParameterAlgorithmSpecification struct {
	// The input mode that the algorithm supports: File or Pipe. In File input mode,
	// Amazon SageMaker downloads the training data from Amazon S3 to the storage
	// volume that is attached to the training instance and mounts the directory to the
	// Docker volume for the training container. In Pipe input mode, Amazon SageMaker
	// streams data directly from Amazon S3 to the container. If you specify File mode,
	// make sure that you provision the storage volume that is attached to the training
	// instance with enough capacity to accommodate the training data downloaded from
	// Amazon S3, the model artifacts, and intermediate information. For more
	// information about input modes, see Algorithms
	// (https://docs.aws.amazon.com/sagemaker/latest/dg/algos.html).
	TrainingInputMode TrainingInputMode
	// An array of MetricDefinition () objects that specify the metrics that the
	// algorithm emits.
	MetricDefinitions []*MetricDefinition
	// The name of the resource algorithm to use for the hyperparameter tuning job. If
	// you specify a value for this parameter, do not specify a value for
	// TrainingImage.
	AlgorithmName *string
	// The registry path of the Docker image that contains the training algorithm. For
	// information about Docker registry paths for built-in algorithms, see Algorithms
	// Provided by Amazon SageMaker: Common Parameters
	// (https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-algo-docker-registry-paths.html).
	// Amazon SageMaker supports both registry/repository[:tag] and
	// registry/repository[@digest] image path formats. For more information, see Using
	// Your Own Algorithms with Amazon SageMaker
	// (https://docs.aws.amazon.com/sagemaker/latest/dg/your-algorithms.html).
	TrainingImage *string
}

// Defines a hyperparameter to be used by an algorithm.
type HyperParameterSpecification struct {
	// The type of this hyperparameter. The valid types are Integer, Continuous,
	// Categorical, and FreeText.
	Type ParameterType
	// A brief description of the hyperparameter.
	Description *string
	// The allowed range for this hyperparameter.
	Range *ParameterRange
	// The name of this hyperparameter. The name must be unique.
	Name *string
	// The default value for this hyperparameter. If a default value is specified, a
	// hyperparameter cannot be required.
	DefaultValue *string
	// Indicates whether this hyperparameter is tunable in a hyperparameter tuning job.
	IsTunable *bool
	// Indicates whether this hyperparameter is required.
	IsRequired *bool
}

// Defines the training jobs launched by a hyperparameter tuning job.
type HyperParameterTrainingJobDefinition struct {
	// To encrypt all communications between ML compute instances in distributed
	// training, choose True. Encryption provides greater security for distributed
	// training, but training might take longer. How long it takes depends on the
	// amount of communication between compute instances, especially if you use a deep
	// learning algorithm in distributed training.
	EnableInterContainerTrafficEncryption *bool
	// Isolates the training container. No inbound or outbound network calls can be
	// made, except for calls between peers within a training cluster for distributed
	// training. If network isolation is used for training jobs that are configured to
	// use a VPC, Amazon SageMaker downloads and uploads customer data and model
	// artifacts through the specified VPC, but the training container does not have
	// network access.
	EnableNetworkIsolation *bool
	// Specifies a limit to how long a model hyperparameter training job can run. It
	// also specifies how long you are willing to wait for a managed spot training job
	// to complete. When the job reaches the a limit, Amazon SageMaker ends the
	// training job. Use this API to cap model training costs.
	StoppingCondition *StoppingCondition
	// Specifies the values of hyperparameters that do not change for the tuning job.
	StaticHyperParameters map[string]*string
	// Specifies ranges of integer, continuous, and categorical hyperparameters that a
	// hyperparameter tuning job searches. The hyperparameter tuning job launches
	// training jobs with hyperparameter values within these ranges to find the
	// combination of values that result in the training job with the best performance
	// as measured by the objective metric of the hyperparameter tuning job. You can
	// specify a maximum of 20 hyperparameters that a hyperparameter tuning job can
	// search over. Every possible value of a categorical parameter range counts
	// against this limit.
	HyperParameterRanges *ParameterRanges
	// The resources, including the compute instances and storage volumes, to use for
	// the training jobs that the tuning job launches. Storage volumes store model
	// artifacts and incremental states. Training algorithms might also use storage
	// volumes for scratch space. If you want Amazon SageMaker to use the storage
	// volume to store the training data, choose File as the TrainingInputMode in the
	// algorithm specification. For distributed training algorithms, specify an
	// instance count greater than 1.
	ResourceConfig *ResourceConfig
	// Defines the objective metric for a hyperparameter tuning job. Hyperparameter
	// tuning uses the value of this metric to evaluate the training jobs it launches,
	// and returns the training job that results in either the highest or lowest value
	// for this metric, depending on the value you specify for the Type parameter.
	TuningObjective *HyperParameterTuningJobObjective
	// The HyperParameterAlgorithmSpecification () object that specifies the resource
	// algorithm to use for the training jobs that the tuning job launches.
	AlgorithmSpecification *HyperParameterAlgorithmSpecification
	// The job definition name.
	DefinitionName *string
	// Contains information about the output location for managed spot training
	// checkpoint data.
	CheckpointConfig *CheckpointConfig
	// The VpcConfig () object that specifies the VPC that you want the training jobs
	// that this hyperparameter tuning job launches to connect to. Control access to
	// and from your training container by configuring the VPC. For more information,
	// see Protect Training Jobs by Using an Amazon Virtual Private Cloud
	// (https://docs.aws.amazon.com/sagemaker/latest/dg/train-vpc.html).
	VpcConfig *VpcConfig
	// Specifies the path to the Amazon S3 bucket where you store model artifacts from
	// the training jobs that the tuning job launches.
	OutputDataConfig *OutputDataConfig
	// An array of Channel () objects that specify the input for the training jobs that
	// the tuning job launches.
	InputDataConfig []*Channel
	// The Amazon Resource Name (ARN) of the IAM role associated with the training jobs
	// that the tuning job launches.
	RoleArn *string
	// A Boolean indicating whether managed spot training is enabled (True) or not
	// (False).
	EnableManagedSpotTraining *bool
}

// Specifies summary information about a training job.
type HyperParameterTrainingJobSummary struct {
	// The date and time that the training job started.
	TrainingStartTime *time.Time
	// The date and time that the training job was created.
	CreationTime *time.Time
	// Specifies the time when the training job ends on training instances. You are
	// billed for the time interval between the value of TrainingStartTime and this
	// time. For successful jobs and stopped jobs, this is the time after model
	// artifacts are uploaded. For failed jobs, this is the time when Amazon SageMaker
	// detects a job failure.
	TrainingEndTime *time.Time
	// The reason that the training job failed.
	FailureReason *string
	// The training job definition name.
	TrainingJobDefinitionName *string
	// The HyperParameter tuning job that launched the training job.
	TuningJobName *string
	// The status of the training job.
	TrainingJobStatus TrainingJobStatus
	// A list of the hyperparameters for which you specified ranges to search.
	TunedHyperParameters map[string]*string
	// The name of the training job.
	TrainingJobName *string
	// The status of the objective metric for the training job:
	//
	//     * Succeeded: The
	// final objective metric for the training job was evaluated by the hyperparameter
	// tuning job and used in the hyperparameter tuning process.
	//
	//     * Pending: The
	// training job is in progress and evaluation of its final objective metric is
	// pending.
	//
	//     * Failed: The final objective metric for the training job was not
	// evaluated, and was not used in the hyperparameter tuning process. This typically
	// occurs when the training job failed or did not emit an objective metric.
	ObjectiveStatus ObjectiveStatus
	// The FinalHyperParameterTuningJobObjectiveMetric () object that specifies the
	// value of the objective metric of the tuning job that launched this training job.
	FinalHyperParameterTuningJobObjectiveMetric *FinalHyperParameterTuningJobObjectiveMetric
	// The Amazon Resource Name (ARN) of the training job.
	TrainingJobArn *string
}

// Configures a hyperparameter tuning job.
type HyperParameterTuningJobConfig struct {
	// The HyperParameterTuningJobObjective () object that specifies the objective
	// metric for this tuning job.
	HyperParameterTuningJobObjective *HyperParameterTuningJobObjective
	// The tuning job's completion criteria.
	TuningJobCompletionCriteria *TuningJobCompletionCriteria
	// The ResourceLimits () object that specifies the maximum number of training jobs
	// and parallel training jobs for this tuning job.
	ResourceLimits *ResourceLimits
	// Specifies how hyperparameter tuning chooses the combinations of hyperparameter
	// values to use for the training job it launches. To use the Bayesian search
	// strategy, set this to Bayesian. To randomly search, set it to Random. For
	// information about search strategies, see How Hyperparameter Tuning Works
	// (https://docs.aws.amazon.com/sagemaker/latest/dg/automatic-model-tuning-how-it-works.html).
	Strategy HyperParameterTuningJobStrategyType
	// Specifies whether to use early stopping for training jobs launched by the
	// hyperparameter tuning job. This can be one of the following values (the default
	// value is OFF): OFF Training jobs launched by the hyperparameter tuning job do
	// not use early stopping. AUTO Amazon SageMaker stops training jobs launched by
	// the hyperparameter tuning job when they are unlikely to perform better than
	// previously completed training jobs. For more information, see Stop Training Jobs
	// Early
	// (https://docs.aws.amazon.com/sagemaker/latest/dg/automatic-model-tuning-early-stopping.html).
	TrainingJobEarlyStoppingType TrainingJobEarlyStoppingType
	// The ParameterRanges () object that specifies the ranges of hyperparameters that
	// this tuning job searches.
	ParameterRanges *ParameterRanges
}

// Defines the objective metric for a hyperparameter tuning job. Hyperparameter
// tuning uses the value of this metric to evaluate the training jobs it launches,
// and returns the training job that results in either the highest or lowest value
// for this metric, depending on the value you specify for the Type parameter.
type HyperParameterTuningJobObjective struct {
	// The name of the metric to use for the objective metric.
	MetricName *string
	// Whether to minimize or maximize the objective metric.
	Type HyperParameterTuningJobObjectiveType
}

// Provides summary information about a hyperparameter tuning job.
type HyperParameterTuningJobSummary struct {
	// The ResourceLimits () object that specifies the maximum number of training jobs
	// and parallel training jobs allowed for this tuning job.
	ResourceLimits *ResourceLimits
	// The date and time that the tuning job was modified.
	LastModifiedTime *time.Time
	// The Amazon Resource Name (ARN) of the tuning job.
	HyperParameterTuningJobArn *string
	// Specifies the search strategy hyperparameter tuning uses to choose which
	// hyperparameters to use for each iteration. Currently, the only valid value is
	// Bayesian.
	Strategy HyperParameterTuningJobStrategyType
	// The date and time that the tuning job was created.
	CreationTime *time.Time
	// The status of the tuning job.
	HyperParameterTuningJobStatus HyperParameterTuningJobStatus
	// The ObjectiveStatusCounters () object that specifies the numbers of training
	// jobs, categorized by objective metric status, that this tuning job launched.
	ObjectiveStatusCounters *ObjectiveStatusCounters
	// The TrainingJobStatusCounters () object that specifies the numbers of training
	// jobs, categorized by status, that this tuning job launched.
	TrainingJobStatusCounters *TrainingJobStatusCounters
	// The date and time that the tuning job ended.
	HyperParameterTuningEndTime *time.Time
	// The name of the tuning job.
	HyperParameterTuningJobName *string
}

// Specifies the configuration for a hyperparameter tuning job that uses one or
// more previous hyperparameter tuning jobs as a starting point. The results of
// previous tuning jobs are used to inform which combinations of hyperparameters to
// search over in the new tuning job. All training jobs launched by the new
// hyperparameter tuning job are evaluated by using the objective metric, and the
// training job that performs the best is compared to the best training jobs from
// the parent tuning jobs. From these, the training job that performs the best as
// measured by the objective metric is returned as the overall best training job.
// All training jobs launched by parent hyperparameter tuning jobs and the new
// hyperparameter tuning jobs count against the limit of training jobs for the
// tuning job.
type HyperParameterTuningJobWarmStartConfig struct {
	// An array of hyperparameter tuning jobs that are used as the starting point for
	// the new hyperparameter tuning job. For more information about warm starting a
	// hyperparameter tuning job, see Using a Previous Hyperparameter Tuning Job as a
	// Starting Point
	// (https://docs.aws.amazon.com/sagemaker/latest/dg/automatic-model-tuning-warm-start.html).
	// Hyperparameter tuning jobs created before October 1, 2018 cannot be used as
	// parent jobs for warm start tuning jobs.
	ParentHyperParameterTuningJobs []*ParentHyperParameterTuningJob
	// Specifies one of the following: IDENTICAL_DATA_AND_ALGORITHM The new
	// hyperparameter tuning job uses the same input data and training image as the
	// parent tuning jobs. You can change the hyperparameter ranges to search and the
	// maximum number of training jobs that the hyperparameter tuning job launches. You
	// cannot use a new version of the training algorithm, unless the changes in the
	// new version do not affect the algorithm itself. For example, changes that
	// improve logging or adding support for a different data format are allowed. You
	// can also change hyperparameters from tunable to static, and from static to
	// tunable, but the total number of static plus tunable hyperparameters must remain
	// the same as it is in all parent jobs. The objective metric for the new tuning
	// job must be the same as for all parent jobs. TRANSFER_LEARNING The new
	// hyperparameter tuning job can include input data, hyperparameter ranges, maximum
	// number of concurrent training jobs, and maximum number of training jobs that are
	// different than those of its parent hyperparameter tuning jobs. The training
	// image can also be a different version from the version used in the parent
	// hyperparameter tuning job. You can also change hyperparameters from tunable to
	// static, and from static to tunable, but the total number of static plus tunable
	// hyperparameters must remain the same as it is in all parent jobs. The objective
	// metric for the new tuning job must be the same as for all parent jobs.
	WarmStartType HyperParameterTuningJobWarmStartType
}

// Defines how to perform inference generation after a training job is run.
type InferenceSpecification struct {
	// A list of the instance types that are used to generate inferences in real-time.
	SupportedRealtimeInferenceInstanceTypes []ProductionVariantInstanceType
	// The supported MIME types for the input data.
	SupportedContentTypes []*string
	// A list of the instance types on which a transformation job can be run or on
	// which an endpoint can be deployed.
	SupportedTransformInstanceTypes []TransformInstanceType
	// The supported MIME types for the output data.
	SupportedResponseMIMETypes []*string
	// The Amazon ECR registry path of the Docker image that contains the inference
	// code.
	Containers []*ModelPackageContainerDefinition
}

// Contains information about the location of input model artifacts, the name and
// shape of the expected data inputs, and the framework in which the model was
// trained.
type InputConfig struct {
	// Identifies the framework in which the model was trained. For example:
	// TENSORFLOW.
	Framework Framework
	// Specifies the name and shape of the expected data inputs for your trained model
	// with a JSON dictionary form. The data inputs are InputConfig$Framework ()
	// specific.
	//
	//     * TensorFlow: You must specify the name and shape (NHWC format)
	// of the expected data inputs using a dictionary format for your trained model.
	// The dictionary formats required for the console and CLI are different.
	//
	//
	// * Examples for one input:
	//
	//             * If using the console,
	// {"input":[1,1024,1024,3]}
	//
	//             * If using the CLI,
	// {\"input\":[1,1024,1024,3]}
	//
	//         * Examples for two inputs:
	//
	//             *
	// If using the console, {"data1": [1,28,28,1], "data2":[1,28,28,1]}
	//
	//             *
	// If using the CLI, {\"data1\": [1,28,28,1], \"data2\":[1,28,28,1]}
	//
	//     * KERAS:
	// You must specify the name and shape (NCHW format) of expected data inputs using
	// a dictionary format for your trained model. Note that while Keras model
	// artifacts should be uploaded in NHWC (channel-last) format, DataInputConfig
	// should be specified in NCHW (channel-first) format. The dictionary formats
	// required for the console and CLI are different.
	//
	//         * Examples for one
	// input:
	//
	//             * If using the console, {"input_1":[1,3,224,224]}
	//
	//
	// * If using the CLI, {\"input_1\":[1,3,224,224]}
	//
	//         * Examples for two
	// inputs:
	//
	//             * If using the console, {"input_1": [1,3,224,224],
	// "input_2":[1,3,224,224]}
	//
	//             * If using the CLI, {\"input_1\":
	// [1,3,224,224], \"input_2\":[1,3,224,224]}
	//
	//     * MXNET/ONNX: You must specify
	// the name and shape (NCHW format) of the expected data inputs in order using a
	// dictionary format for your trained model. The dictionary formats required for
	// the console and CLI are different.
	//
	//         * Examples for one input:
	//
	//
	// * If using the console, {"data":[1,3,1024,1024]}
	//
	//             * If using the
	// CLI, {\"data\":[1,3,1024,1024]}
	//
	//         * Examples for two inputs:
	//
	//
	// * If using the console, {"var1": [1,1,28,28], "var2":[1,1,28,28]}
	//
	//             *
	// If using the CLI, {\"var1\": [1,1,28,28], \"var2\":[1,1,28,28]}
	//
	//     * PyTorch:
	// You can either specify the name and shape (NCHW format) of expected data inputs
	// in order using a dictionary format for your trained model or you can specify the
	// shape only using a list format. The dictionary formats required for the console
	// and CLI are different. The list formats for the console and CLI are the same.
	//
	//
	// * Examples for one input in dictionary format:
	//
	//             * If using the
	// console, {"input0":[1,3,224,224]}
	//
	//             * If using the CLI,
	// {\"input0\":[1,3,224,224]}
	//
	//         * Example for one input in list format:
	// [[1,3,224,224]]
	//
	//         * Examples for two inputs in dictionary format:
	//
	//
	// * If using the console, {"input0":[1,3,224,224], "input1":[1,3,224,224]}
	//
	//
	// * If using the CLI, {\"input0\":[1,3,224,224], \"input1\":[1,3,224,224]}
	//
	//
	// * Example for two inputs in list format: [[1,3,224,224], [1,3,224,224]]
	//
	//     *
	// XGBOOST: input data name and shape are not needed.
	DataInputConfig *string
	// The S3 path where the model artifacts, which result from model training, are
	// stored. This path must point to a single gzip compressed tar archive (.tar.gz
	// suffix).
	S3Uri *string
}

// For a hyperparameter of the integer type, specifies the range that a
// hyperparameter tuning job searches.
type IntegerParameterRange struct {
	// The scale that hyperparameter tuning uses to search the hyperparameter range.
	// For information about choosing a hyperparameter scale, see Hyperparameter
	// Scaling
	// (https://docs.aws.amazon.com/sagemaker/latest/dg/automatic-model-tuning-define-ranges.html#scaling-type).
	// One of the following values: Auto Amazon SageMaker hyperparameter tuning chooses
	// the best scale for the hyperparameter. Linear Hyperparameter tuning searches the
	// values in the hyperparameter range by using a linear scale. Logarithmic
	// Hyperparameter tuning searches the values in the hyperparameter range by using a
	// logarithmic scale. Logarithmic scaling works only for ranges that have only
	// values greater than 0.
	ScalingType HyperParameterScalingType
	// The maximum value of the hyperparameter to search.
	MaxValue *string
	// The minimum value of the hyperparameter to search.
	MinValue *string
	// The name of the hyperparameter to search.
	Name *string
}

// Defines the possible values for an integer hyperparameter.
type IntegerParameterRangeSpecification struct {
	// The maximum integer value allowed.
	MaxValue *string
	// The minimum integer value allowed.
	MinValue *string
}

// Jupyter server's app settings.
type JupyterServerAppSettings struct {
	// The default instance type and the Amazon Resource Name (ARN) of the SageMaker
	// image created on the instance.
	DefaultResourceSpec *ResourceSpec
}

// The kernel gateway app settings.
type KernelGatewayAppSettings struct {
	// The default instance type and the Amazon Resource Name (ARN) of the SageMaker
	// image created on the instance.
	DefaultResourceSpec *ResourceSpec
}

// Provides a breakdown of the number of objects labeled.
type LabelCounters struct {
	// The total number of objects labeled by automated data labeling.
	MachineLabeled *int32
	// The total number of objects that could not be labeled due to an error.
	FailedNonRetryableError *int32
	// The total number of objects labeled.
	TotalLabeled *int32
	// The total number of objects labeled by a human worker.
	HumanLabeled *int32
	// The total number of objects not yet labeled.
	Unlabeled *int32
}

// Provides counts for human-labeled tasks in the labeling job.
type LabelCountersForWorkteam struct {
	// The total number of data objects that need to be labeled by a human worker.
	PendingHuman *int32
	// The total number of tasks in the labeling job.
	Total *int32
	// The total number of data objects labeled by a human worker.
	HumanLabeled *int32
}

// Provides configuration information for auto-labeling of your data objects. A
// LabelingJobAlgorithmsConfig object must be supplied in order to use
// auto-labeling.
type LabelingJobAlgorithmsConfig struct {
	// At the end of an auto-label job Amazon SageMaker Ground Truth sends the Amazon
	// Resource Nam (ARN) of the final model used for auto-labeling. You can use this
	// model as the starting point for subsequent similar jobs by providing the ARN of
	// the model here.
	InitialActiveLearningModelArn *string
	// Provides configuration information for a labeling job.
	LabelingJobResourceConfig *LabelingJobResourceConfig
	// Specifies the Amazon Resource Name (ARN) of the algorithm used for
	// auto-labeling. You must select one of the following ARNs:
	//
	//     * Image
	// classification
	// arn:aws:sagemaker:region:027400017018:labeling-job-algorithm-specification/image-classification
	//
	//
	// * Text classification
	// arn:aws:sagemaker:region:027400017018:labeling-job-algorithm-specification/text-classification
	//
	//
	// * Object detection
	// arn:aws:sagemaker:region:027400017018:labeling-job-algorithm-specification/object-detection
	//
	//
	// * Semantic Segmentation
	// arn:aws:sagemaker:region:027400017018:labeling-job-algorithm-specification/semantic-segmentation
	LabelingJobAlgorithmSpecificationArn *string
}

// Attributes of the data specified by the customer. Use these to describe the data
// to be labeled.
type LabelingJobDataAttributes struct {
	// Declares that your content is free of personally identifiable information or
	// adult content. Amazon SageMaker may restrict the Amazon Mechanical Turk workers
	// that can view your task based on this information.
	ContentClassifiers []ContentClassifier
}

// Provides information about the location of input data.
type LabelingJobDataSource struct {
	// The Amazon S3 location of the input data objects.
	S3DataSource *LabelingJobS3DataSource
}

// Provides summary information for a work team.
type LabelingJobForWorkteamSummary struct {
	// Provides information about the progress of a labeling job.
	LabelCounters *LabelCountersForWorkteam
	// A unique identifier for a labeling job. You can use this to refer to a specific
	// labeling job.
	JobReferenceCode *string
	// The configured number of workers per data object.
	NumberOfHumanWorkersPerDataObject *int32
	//
	WorkRequesterAccountId *string
	// The date and time that the labeling job was created.
	CreationTime *time.Time
	// The name of the labeling job that the work team is assigned to.
	LabelingJobName *string
}

// Input configuration information for a labeling job.
type LabelingJobInputConfig struct {
	// The location of the input data.
	DataSource *LabelingJobDataSource
	// Attributes of the data specified by the customer.
	DataAttributes *LabelingJobDataAttributes
}

// Specifies the location of the output produced by the labeling job.
type LabelingJobOutput struct {
	// The Amazon Resource Name (ARN) for the most recent Amazon SageMaker model
	// trained as part of automated data labeling.
	FinalActiveLearningModelArn *string
	// The Amazon S3 bucket location of the manifest file for labeled data.
	OutputDatasetS3Uri *string
}

// Output configuration information for a labeling job.
type LabelingJobOutputConfig struct {
	// The AWS Key Management Service ID of the key used to encrypt the output data, if
	// any. If you use a KMS key ID or an alias of your master key, the Amazon
	// SageMaker execution role must include permissions to call kms:Encrypt. If you
	// don't provide a KMS key ID, Amazon SageMaker uses the default KMS key for Amazon
	// S3 for your role's account. Amazon SageMaker uses server-side encryption with
	// KMS-managed keys for LabelingJobOutputConfig. If you use a bucket policy with an
	// s3:PutObject permission that only allows objects with server-side encryption,
	// set the condition key of s3:x-amz-server-side-encryption to "aws:kms". For more
	// information, see KMS-Managed Encryption Keys
	// (https://docs.aws.amazon.com/AmazonS3/latest/dev/UsingKMSEncryption.html) in the
	// Amazon Simple Storage Service Developer Guide. The KMS key policy must grant
	// permission to the IAM role that you specify in your CreateLabelingJob request.
	// For more information, see Using Key Policies in AWS KMS
	// (http://docs.aws.amazon.com/kms/latest/developerguide/key-policies.html) in the
	// AWS Key Management Service Developer Guide.
	KmsKeyId *string
	// The Amazon S3 location to write output data.
	S3OutputPath *string
}

// Provides configuration information for labeling jobs.
type LabelingJobResourceConfig struct {
	// The AWS Key Management Service (AWS KMS) key that Amazon SageMaker uses to
	// encrypt data on the storage volume attached to the ML compute instance(s) that
	// run the training job. The VolumeKmsKeyId can be any of the following formats:
	//
	//
	// * // KMS Key ID "1234abcd-12ab-34cd-56ef-1234567890ab"
	//
	//     * // Amazon Resource
	// Name (ARN) of a KMS Key
	// "arn:aws:kms:us-west-2:111122223333:key/1234abcd-12ab-34cd-56ef-1234567890ab"
	VolumeKmsKeyId *string
}

// The Amazon S3 location of the input data objects.
type LabelingJobS3DataSource struct {
	// The Amazon S3 location of the manifest file that describes the input data
	// objects.
	ManifestS3Uri *string
}

// A set of conditions for stopping a labeling job. If any of the conditions are
// met, the job is automatically stopped. You can use these conditions to control
// the cost of data labeling. Labeling jobs fail after 30 days with an appropriate
// client error message.
type LabelingJobStoppingConditions struct {
	// The maximum number of input data objects that should be labeled.
	MaxPercentageOfInputDatasetLabeled *int32
	// The maximum number of objects that can be labeled by human workers.
	MaxHumanLabeledObjectCount *int32
}

// Provides summary information about a labeling job.
type LabelingJobSummary struct {
	// The date and time that the job was created (timestamp).
	CreationTime *time.Time
	// The date and time that the job was last modified (timestamp).
	LastModifiedTime *time.Time
	// The current status of the labeling job.
	LabelingJobStatus LabelingJobStatus
	// If the LabelingJobStatus field is Failed, this field contains a description of
	// the error.
	FailureReason *string
	// The Amazon Resource Name (ARN) of the Lambda function used to consolidate the
	// annotations from individual workers into a label for a data object. For more
	// information, see Annotation Consolidation
	// (https://docs.aws.amazon.com/sagemaker/latest/dg/sms-annotation-consolidation.html).
	AnnotationConsolidationLambdaArn *string
	// Counts showing the progress of the labeling job.
	LabelCounters *LabelCounters
	// Input configuration for the labeling job.
	InputConfig *LabelingJobInputConfig
	// The name of the labeling job.
	LabelingJobName *string
	// The Amazon Resource Name (ARN) of a Lambda function. The function is run before
	// each data object is sent to a worker.
	PreHumanTaskLambdaArn *string
	// The Amazon Resource Name (ARN) of the work team assigned to the job.
	WorkteamArn *string
	// The Amazon Resource Name (ARN) assigned to the labeling job when it was created.
	LabelingJobArn *string
	// The location of the output produced by the labeling job.
	LabelingJobOutput *LabelingJobOutput
}

// Defines the Amazon Cognito user group that is part of a work team.
type MemberDefinition struct {
	// The Amazon Cognito user group that is part of the work team.
	CognitoMemberDefinition *CognitoMemberDefinition
	// A list user groups that exist in your OIDC Identity Provider (IdP). One to ten
	// groups can be used to create a single private work team. When you add a user
	// group to the list of Groups, you can add that user group to one or more private
	// work teams. If you add a user group to a private work team, all workers in that
	// user group are added to the work team.
	OidcMemberDefinition *OidcMemberDefinition
}

// The name, value, and date and time of a metric that was emitted to Amazon
// CloudWatch.
type MetricData struct {
	// The name of the metric.
	MetricName *string
	// The date and time that the algorithm emitted the metric.
	Timestamp *time.Time
	// The value of the metric.
	Value *float32
}

// Specifies a metric that the training algorithm writes to stderr or stdout .
// Amazon SageMakerhyperparameter tuning captures all defined metrics. You specify
// one metric that a hyperparameter tuning job uses as its objective metric to
// choose the best training job.
type MetricDefinition struct {
	// The name of the metric.
	Name *string
	// A regular expression that searches the output of a training job and gets the
	// value of the metric. For more information about using regular expressions to
	// define metrics, see Defining Objective Metrics
	// (https://docs.aws.amazon.com/sagemaker/latest/dg/automatic-model-tuning-define-metrics.html).
	Regex *string
}

// Provides information about the location that is configured for storing model
// artifacts. Model artifacts are the output that results from training a model,
// and typically consist of trained parameters, a model defintion that desribes how
// to compute inferences, and other metadata.
type ModelArtifacts struct {
	// The path of the S3 object that contains the model artifacts. For example,
	// s3://bucket-name/keynameprefix/model.tar.gz.
	S3ModelArtifacts *string
}

// Configures the timeout and maximum number of retries for processing a transform
// job invocation.
type ModelClientConfig struct {
	// The timeout value in seconds for an invocation request.
	InvocationsTimeoutInSeconds *int32
	// The maximum number of retries when invocation requests are failing.
	InvocationsMaxRetries *int32
}

// Describes the Docker container for the model package.
type ModelPackageContainerDefinition struct {
	// The AWS Marketplace product ID of the model package.
	ProductId *string
	// The Amazon S3 path where the model artifacts, which result from model training,
	// are stored. This path must point to a single gzip compressed tar archive
	// (.tar.gz suffix).
	ModelDataUrl *string
	// The DNS host name for the Docker container.
	ContainerHostname *string
	// The Amazon EC2 Container Registry (Amazon ECR) path where inference code is
	// stored. If you are using your own custom algorithm instead of an algorithm
	// provided by Amazon SageMaker, the inference code must meet Amazon SageMaker
	// requirements. Amazon SageMaker supports both registry/repository[:tag] and
	// registry/repository[@digest] image path formats. For more information, see Using
	// Your Own Algorithms with Amazon SageMaker
	// (https://docs.aws.amazon.com/sagemaker/latest/dg/your-algorithms.html).
	Image *string
	// An MD5 hash of the training algorithm that identifies the Docker image used for
	// training.
	ImageDigest *string
}

// Specifies the validation and image scan statuses of the model package.
type ModelPackageStatusDetails struct {
	// The validation status of the model package.
	ValidationStatuses []*ModelPackageStatusItem
	// The status of the scan of the Docker image container for the model package.
	ImageScanStatuses []*ModelPackageStatusItem
}

// Represents the overall status of a model package.
type ModelPackageStatusItem struct {
	// if the overall status is Failed, the reason for the failure.
	FailureReason *string
	// The name of the model package for which the overall status is being reported.
	Name *string
	// The current status.
	Status DetailedModelPackageStatus
}

// Provides summary information about a model package.
type ModelPackageSummary struct {
	// The name of the model package.
	ModelPackageName *string
	// The Amazon Resource Name (ARN) of the model package.
	ModelPackageArn *string
	// A brief description of the model package.
	ModelPackageDescription *string
	// The overall status of the model package.
	ModelPackageStatus ModelPackageStatus
	// A timestamp that shows when the model package was created.
	CreationTime *time.Time
}

// Contains data, such as the inputs and targeted instance types that are used in
// the process of validating the model package. The data provided in the validation
// profile is made available to your buyers on AWS Marketplace.
type ModelPackageValidationProfile struct {
	// The TransformJobDefinition object that describes the transform job used for the
	// validation of the model package.
	TransformJobDefinition *TransformJobDefinition
	// The name of the profile for the model package.
	ProfileName *string
}

// Specifies batch transform jobs that Amazon SageMaker runs to validate your model
// package.
type ModelPackageValidationSpecification struct {
	// An array of ModelPackageValidationProfile objects, each of which specifies a
	// batch transform job that Amazon SageMaker runs to validate your model package.
	ValidationProfiles []*ModelPackageValidationProfile
	// The IAM roles to be used for the validation of the model package.
	ValidationRole *string
}

// Provides summary information about a model.
type ModelSummary struct {
	// A timestamp that indicates when the model was created.
	CreationTime *time.Time
	// The Amazon Resource Name (ARN) of the model.
	ModelArn *string
	// The name of the model that you want a summary for.
	ModelName *string
}

// Container image configuration object for the monitoring job.
type MonitoringAppSpecification struct {
	// The container image to be run by the monitoring job.
	ImageUri *string
	// Specifies the entrypoint for a container used to run the monitoring job.
	ContainerEntrypoint []*string
	// An Amazon S3 URI to a script that is called after analysis has been performed.
	// Applicable only for the built-in (first party) containers.
	PostAnalyticsProcessorSourceUri *string
	// An array of arguments for the container used to run the monitoring job.
	ContainerArguments []*string
	// An Amazon S3 URI to a script that is called per row prior to running analysis.
	// It can base64 decode the payload and convert it into a flatted json so that the
	// built-in container can use the converted data. Applicable only for the built-in
	// (first party) containers.
	RecordPreprocessorSourceUri *string
}

// Configuration for monitoring constraints and monitoring statistics. These
// baseline resources are compared against the results of the current job from the
// series of jobs scheduled to collect data periodically.
type MonitoringBaselineConfig struct {
	// The baseline statistics file in Amazon S3 that the current monitoring job should
	// be validated against.
	StatisticsResource *MonitoringStatisticsResource
	// The baseline constraint file in Amazon S3 that the current monitoring job should
	// validated against.
	ConstraintsResource *MonitoringConstraintsResource
}

// Configuration for the cluster used to run model monitoring jobs.
type MonitoringClusterConfig struct {
	// The number of ML compute instances to use in the model monitoring job. For
	// distributed processing jobs, specify a value greater than 1. The default value
	// is 1.
	InstanceCount *int32
	// The ML compute instance type for the processing job.
	InstanceType ProcessingInstanceType
	// The AWS Key Management Service (AWS KMS) key that Amazon SageMaker uses to
	// encrypt data on the storage volume attached to the ML compute instance(s) that
	// run the model monitoring job.
	VolumeKmsKeyId *string
	// The size of the ML storage volume, in gigabytes, that you want to provision. You
	// must specify sufficient ML storage for your scenario.
	VolumeSizeInGB *int32
}

// The constraints resource for a monitoring job.
type MonitoringConstraintsResource struct {
	// The Amazon S3 URI for the constraints resource.
	S3Uri *string
}

// Summary of information about the last monitoring job to run.
type MonitoringExecutionSummary struct {
	// The time the monitoring job was scheduled.
	ScheduledTime *time.Time
	// The Amazon Resource Name (ARN) of the monitoring job.
	ProcessingJobArn *string
	// The status of the monitoring job.
	MonitoringExecutionStatus ExecutionStatus
	// A timestamp that indicates the last time the monitoring job was modified.
	LastModifiedTime *time.Time
	// The time at which the monitoring job was created.
	CreationTime *time.Time
	// The name of the monitoring schedule.
	MonitoringScheduleName *string
	// Contains the reason a monitoring job failed, if it failed.
	FailureReason *string
	// The name of teh endpoint used to run the monitoring job.
	EndpointName *string
}

// The inputs for a monitoring job.
type MonitoringInput struct {
	// The endpoint for a monitoring job.
	EndpointInput *EndpointInput
}

// Defines the monitoring job.
type MonitoringJobDefinition struct {
	// The array of outputs from the monitoring job to be uploaded to Amazon Simple
	// Storage Service (Amazon S3).
	MonitoringOutputConfig *MonitoringOutputConfig
	// Identifies the resources, ML compute instances, and ML storage volumes to deploy
	// for a monitoring job. In distributed processing, you specify more than one
	// instance.
	MonitoringResources *MonitoringResources
	// Configures the monitoring job to run a specified Docker container image.
	MonitoringAppSpecification *MonitoringAppSpecification
	// The Amazon Resource Name (ARN) of an IAM role that Amazon SageMaker can assume
	// to perform tasks on your behalf.
	RoleArn *string
	// Sets the environment variables in the Docker container.
	Environment map[string]*string
	// Baseline configuration used to validate that the data conforms to the specified
	// constraints and statistics
	BaselineConfig *MonitoringBaselineConfig
	// Specifies a time limit for how long the monitoring job is allowed to run.
	StoppingCondition *MonitoringStoppingCondition
	// The array of inputs for the monitoring job. Currently we support monitoring an
	// Amazon SageMaker Endpoint.
	MonitoringInputs []*MonitoringInput
	// Specifies networking options for an monitoring job.
	NetworkConfig *NetworkConfig
}

// The output object for a monitoring job.
type MonitoringOutput struct {
	// The Amazon S3 storage location where the results of a monitoring job are saved.
	S3Output *MonitoringS3Output
}

// The output configuration for monitoring jobs.
type MonitoringOutputConfig struct {
	// Monitoring outputs for monitoring jobs. This is where the output of the periodic
	// monitoring jobs is uploaded.
	MonitoringOutputs []*MonitoringOutput
	// The AWS Key Management Service (AWS KMS) key that Amazon SageMaker uses to
	// encrypt the model artifacts at rest using Amazon S3 server-side encryption.
	KmsKeyId *string
}

// Identifies the resources to deploy for a monitoring job.
type MonitoringResources struct {
	// The configuration for the cluster resources used to run the processing job.
	ClusterConfig *MonitoringClusterConfig
}

// Information about where and how you want to store the results of a monitoring
// job.
type MonitoringS3Output struct {
	// The local path to the Amazon S3 storage location where Amazon SageMaker saves
	// the results of a monitoring job. LocalPath is an absolute path for the output
	// data.
	LocalPath *string
	// Whether to upload the results of the monitoring job continuously or after the
	// job completes.
	S3UploadMode ProcessingS3UploadMode
	// A URI that identifies the Amazon S3 storage location where Amazon SageMaker
	// saves the results of a monitoring job.
	S3Uri *string
}

// Configures the monitoring schedule and defines the monitoring job.
type MonitoringScheduleConfig struct {
	// Defines the monitoring job.
	MonitoringJobDefinition *MonitoringJobDefinition
	// Configures the monitoring schedule.
	ScheduleConfig *ScheduleConfig
}

// Summarizes the monitoring schedule.
type MonitoringScheduleSummary struct {
	// The last time the monitoring schedule was modified.
	LastModifiedTime *time.Time
	// The creation time of the monitoring schedule.
	CreationTime *time.Time
	// The name of the endpoint using the monitoring schedule.
	EndpointName *string
	// The status of the monitoring schedule.
	MonitoringScheduleStatus ScheduleStatus
	// The name of the monitoring schedule.
	MonitoringScheduleName *string
	// The Amazon Resource Name (ARN) of the monitoring schedule.
	MonitoringScheduleArn *string
}

// The statistics resource for a monitoring job.
type MonitoringStatisticsResource struct {
	// The Amazon S3 URI for the statistics resource.
	S3Uri *string
}

// A time limit for how long the monitoring job is allowed to run before stopping.
type MonitoringStoppingCondition struct {
	// The maximum runtime allowed in seconds.
	MaxRuntimeInSeconds *int32
}

// A list of nested Filter () objects. A resource must satisfy the conditions of
// all filters to be included in the results returned from the Search () API. For
// example, to filter on a training job's InputDataConfig property with a specific
// channel name and S3Uri prefix, define the following filters:
//
//     *
// '{Name:"InputDataConfig.ChannelName", "Operator":"Equals", "Value":"train"}',
//
//
// * '{Name:"InputDataConfig.DataSource.S3DataSource.S3Uri", "Operator":"Contains",
// "Value":"mybucket/catdata"}'
type NestedFilters struct {
	// A list of filters. Each filter acts on a property. Filters must contain at least
	// one Filters value. For example, a NestedFilters call might include a filter on
	// the PropertyName parameter of the InputDataConfig property:
	// InputDataConfig.DataSource.S3DataSource.S3Uri.
	Filters []*Filter
	// The name of the property to use in the nested filters. The value must match a
	// listed property name, such as InputDataConfig.
	NestedPropertyName *string
}

// Networking options for a job, such as network traffic encryption between
// containers, whether to allow inbound and outbound network calls to and from
// containers, and the VPC subnets and security groups to use for VPC-enabled jobs.
type NetworkConfig struct {
	// Whether to allow inbound and outbound network calls to and from the containers
	// used for the processing job.
	EnableNetworkIsolation *bool
	// Whether to encrypt all communications between distributed processing jobs.
	// Choose True to encrypt communications. Encryption provides greater security for
	// distributed processing jobs, but the processing might take longer.
	EnableInterContainerTrafficEncryption *bool
	// Specifies a VPC that your training jobs and hosted models have access to.
	// Control access to and from your training and model containers by configuring the
	// VPC. For more information, see Protect Endpoints by Using an Amazon Virtual
	// Private Cloud (https://docs.aws.amazon.com/sagemaker/latest/dg/host-vpc.html)
	// and Protect Training Jobs by Using an Amazon Virtual Private Cloud
	// (https://docs.aws.amazon.com/sagemaker/latest/dg/train-vpc.html).
	VpcConfig *VpcConfig
}

// Provides a summary of a notebook instance lifecycle configuration.
type NotebookInstanceLifecycleConfigSummary struct {
	// The name of the lifecycle configuration.
	NotebookInstanceLifecycleConfigName *string
	// The Amazon Resource Name (ARN) of the lifecycle configuration.
	NotebookInstanceLifecycleConfigArn *string
	// A timestamp that tells when the lifecycle configuration was last modified.
	LastModifiedTime *time.Time
	// A timestamp that tells when the lifecycle configuration was created.
	CreationTime *time.Time
}

// Contains the notebook instance lifecycle configuration script. Each lifecycle
// configuration script has a limit of 16384 characters. The value of the $PATH
// environment variable that is available to both scripts is
// /sbin:bin:/usr/sbin:/usr/bin. View CloudWatch Logs for notebook instance
// lifecycle configurations in log group /aws/sagemaker/NotebookInstances in log
// stream [notebook-instance-name]/[LifecycleConfigHook]. Lifecycle configuration
// scripts cannot run for longer than 5 minutes. If a script runs for longer than 5
// minutes, it fails and the notebook instance is not created or started. For
// information about notebook instance lifestyle configurations, see Step 2.1:
// (Optional) Customize a Notebook Instance
// (https://docs.aws.amazon.com/sagemaker/latest/dg/notebook-lifecycle-config.html).
type NotebookInstanceLifecycleHook struct {
	// A base64-encoded string that contains a shell script for a notebook instance
	// lifecycle configuration.
	Content *string
}

// Provides summary information for an Amazon SageMaker notebook instance.
type NotebookInstanceSummary struct {
	// A timestamp that shows when the notebook instance was created.
	CreationTime *time.Time
	// The Git repository associated with the notebook instance as its default code
	// repository. This can be either the name of a Git repository stored as a resource
	// in your account, or the URL of a Git repository in AWS CodeCommit
	// (https://docs.aws.amazon.com/codecommit/latest/userguide/welcome.html) or in any
	// other Git repository. When you open a notebook instance, it opens in the
	// directory that contains this repository. For more information, see Associating
	// Git Repositories with Amazon SageMaker Notebook Instances
	// (https://docs.aws.amazon.com/sagemaker/latest/dg/nbi-git-repo.html).
	DefaultCodeRepository *string
	// An array of up to three Git repositories associated with the notebook instance.
	// These can be either the names of Git repositories stored as resources in your
	// account, or the URL of Git repositories in AWS CodeCommit
	// (https://docs.aws.amazon.com/codecommit/latest/userguide/welcome.html) or in any
	// other Git repository. These repositories are cloned at the same level as the
	// default repository of your notebook instance. For more information, see
	// Associating Git Repositories with Amazon SageMaker Notebook Instances
	// (https://docs.aws.amazon.com/sagemaker/latest/dg/nbi-git-repo.html).
	AdditionalCodeRepositories []*string
	// A timestamp that shows when the notebook instance was last modified.
	LastModifiedTime *time.Time
	// The Amazon Resource Name (ARN) of the notebook instance.
	NotebookInstanceArn *string
	// The status of the notebook instance.
	NotebookInstanceStatus NotebookInstanceStatus
	// The name of a notebook instance lifecycle configuration associated with this
	// notebook instance. For information about notebook instance lifestyle
	// configurations, see Step 2.1: (Optional) Customize a Notebook Instance
	// (https://docs.aws.amazon.com/sagemaker/latest/dg/notebook-lifecycle-config.html).
	NotebookInstanceLifecycleConfigName *string
	// The name of the notebook instance that you want a summary for.
	NotebookInstanceName *string
	// The type of ML compute instance that the notebook instance is running on.
	InstanceType InstanceType
	// The URL that you use to connect to the Jupyter instance running in your notebook
	// instance.
	Url *string
}

// Configures SNS notifications of available or expiring work items for work teams.
type NotificationConfiguration struct {
	// The ARN for the SNS topic to which notifications should be published.
	NotificationTopicArn *string
}

// Specifies the number of training jobs that this hyperparameter tuning job
// launched, categorized by the status of their objective metric. The objective
// metric status shows whether the final objective metric for the training job has
// been evaluated by the tuning job and used in the hyperparameter tuning process.
type ObjectiveStatusCounters struct {
	// The number of training jobs that are in progress and pending evaluation of their
	// final objective metric.
	Pending *int32
	// The number of training jobs whose final objective metric was not evaluated and
	// used in the hyperparameter tuning process. This typically occurs when the
	// training job failed or did not emit an objective metric.
	Failed *int32
	// The number of training jobs whose final objective metric was evaluated by the
	// hyperparameter tuning job and used in the hyperparameter tuning process.
	Succeeded *int32
}

// Use this parameter to configure your OIDC Identity Provider (IdP).
type OidcConfig struct {
	// The OIDC IdP logout endpoint used to configure your private workforce.
	LogoutEndpoint *string
	// The OIDC IdP JSON Web Key Set (Jwks) URI used to configure your private
	// workforce.
	JwksUri *string
	// The OIDC IdP token endpoint used to configure your private workforce.
	TokenEndpoint *string
	// The OIDC IdP authorization endpoint used to configure your private workforce.
	AuthorizationEndpoint *string
	// The OIDC IdP user information endpoint used to configure your private workforce.
	UserInfoEndpoint *string
	// The OIDC IdP client ID used to configure your private workforce.
	ClientId *string
	// The OIDC IdP issuer used to configure your private workforce.
	Issuer *string
	// The OIDC IdP client secret used to configure your private workforce.
	ClientSecret *string
}

// Your Amazon Cognito workforce configuration.
type OidcConfigForResponse struct {
	// The OIDC IdP token endpoint used to configure your private workforce.
	TokenEndpoint *string
	// The OIDC IdP logout endpoint used to configure your private workforce.
	LogoutEndpoint *string
	// The OIDC IdP JSON Web Key Set (Jwks) URI used to configure your private
	// workforce.
	JwksUri *string
	// The OIDC IdP user information endpoint used to configure your private workforce.
	UserInfoEndpoint *string
	// The OIDC IdP client ID used to configure your private workforce.
	ClientId *string
	// The OIDC IdP issuer used to configure your private workforce.
	Issuer *string
	// The OIDC IdP authorization endpoint used to configure your private workforce.
	AuthorizationEndpoint *string
}

// A list user groups that exist in your OIDC Identity Provider (IdP). One to ten
// groups can be used to create a single private work team. When you add a user
// group to the list of Groups, you can add that user group to one or more private
// work teams. If you add a user group to a private work team, all workers in that
// user group are added to the work team.
type OidcMemberDefinition struct {
	// A list of comma seperated strings that identifies user groups in your OIDC IdP.
	// Each user group is made up of a group of private workers.
	Groups []*string
}

// Contains information about the output location for the compiled model and the
// target device that the model runs on. TargetDevice and TargetPlatform are
// mutually exclusive, so you need to choose one between the two to specify your
// target device or platform. If you cannot find your device you want to use from
// the TargetDevice list, use TargetPlatform to describe the platform of your edge
// device and CompilerOptions if there are specific settings that are required or
// recommended to use for particular TargetPlatform.
type OutputConfig struct {
	// Specifies additional parameters for compiler options in JSON format. The
	// compiler options are TargetPlatform specific. It is required for NVIDIA
	// accelerators and highly recommended for CPU compliations. For any other cases,
	// it is optional to specify CompilerOptions.
	//
	//     * CPU: Compilation for CPU
	// supports the following compiler options.
	//
	//         * mcpu: CPU
	// micro-architecture. For example, {'mcpu': 'skylake-avx512'}
	//
	//         * mattr:
	// CPU flags. For example, {'mattr': ['+neon', '+vfpv4']}
	//
	//     * ARM: Details of
	// ARM CPU compilations.
	//
	//         * NEON: NEON is an implementation of the Advanced
	// SIMD extension used in ARMv7 processors. For example, add {'mattr': ['+neon']}
	// to the compiler options if compiling for ARM 32-bit platform with the NEON
	// support.
	//
	//     * NVIDIA: Compilation for NVIDIA GPU supports the following
	// compiler options.
	//
	//         * gpu_code: Specifies the targeted architecture.
	//
	//
	// * trt-ver: Specifies the TensorRT versions in x.y.z. format.
	//
	//         *
	// cuda-ver: Specifies the CUDA version in x.y format.
	//
	//     For example,
	// {'gpu-code': 'sm_72', 'trt-ver': '6.0.1', 'cuda-ver': '10.1'}
	//
	//     * ANDROID:
	// Compilation for the Android OS supports the following compiler options:
	//
	//
	// * ANDROID_PLATFORM: Specifies the Android API levels. Available levels range
	// from 21 to 29. For example, {'ANDROID_PLATFORM': 28}.
	//
	//         * mattr: Add
	// {'mattr': ['+neon']} to compiler options if compiling for ARM 32-bit platform
	// with NEON support.
	CompilerOptions *string
	// Identifies the S3 bucket where you want Amazon SageMaker to store the model
	// artifacts. For example, s3://bucket-name/key-name-prefix.
	S3OutputLocation *string
	// Contains information about a target platform that you want your model to run on,
	// such as OS, architecture, and accelerators. It is an alternative of
	// TargetDevice. The following examples show how to configure the TargetPlatform
	// and CompilerOptions JSON strings for popular target platforms:
	//
	//     * Raspberry
	// Pi 3 Model B+ "TargetPlatform": {"Os": "LINUX", "Arch": "ARM_EABIHF"},
	// "CompilerOptions": {'mattr': ['+neon']}
	//
	//     * Jetson TX2 "TargetPlatform":
	// {"Os": "LINUX", "Arch": "ARM64", "Accelerator": "NVIDIA"}, "CompilerOptions":
	// {'gpu-code': 'sm_62', 'trt-ver': '6.0.1', 'cuda-ver': '10.0'}
	//
	//     * EC2
	// m5.2xlarge instance OS "TargetPlatform": {"Os": "LINUX", "Arch": "X86_64",
	// "Accelerator": "NVIDIA"}, "CompilerOptions": {'mcpu': 'skylake-avx512'}
	//
	//     *
	// RK3399 "TargetPlatform": {"Os": "LINUX", "Arch": "ARM64", "Accelerator":
	// "MALI"}
	//
	//     * ARMv7 phone (CPU) "TargetPlatform": {"Os": "ANDROID", "Arch":
	// "ARM_EABI"}, "CompilerOptions": {'ANDROID_PLATFORM': 25, 'mattr': ['+neon']}
	//
	//
	// * ARMv8 phone (CPU) "TargetPlatform": {"Os": "ANDROID", "Arch": "ARM64"},
	// "CompilerOptions": {'ANDROID_PLATFORM': 29}
	TargetPlatform *TargetPlatform
	// Identifies the target device or the machine learning instance that you want to
	// run your model on after the compilation has completed. Alternatively, you can
	// specify OS, architecture, and accelerator using TargetPlatform () fields. It can
	// be used instead of TargetPlatform.
	TargetDevice TargetDevice
}

// Provides information about how to store model training results (model
// artifacts).
type OutputDataConfig struct {
	// The AWS Key Management Service (AWS KMS) key that Amazon SageMaker uses to
	// encrypt the model artifacts at rest using Amazon S3 server-side encryption. The
	// KmsKeyId can be any of the following formats:
	//
	//     * // KMS Key ID
	// "1234abcd-12ab-34cd-56ef-1234567890ab"
	//
	//     * // Amazon Resource Name (ARN) of a
	// KMS Key
	// "arn:aws:kms:us-west-2:111122223333:key/1234abcd-12ab-34cd-56ef-1234567890ab"
	//
	//
	// * // KMS Key Alias "alias/ExampleAlias"
	//
	//     * // Amazon Resource Name (ARN) of
	// a KMS Key Alias "arn:aws:kms:us-west-2:111122223333:alias/ExampleAlias"
	//
	//
	// <p>If you use a KMS key ID or an alias of your master key, the Amazon SageMaker
	// execution role must include permissions to call <code>kms:Encrypt</code>. If you
	// don't provide a KMS key ID, Amazon SageMaker uses the default KMS key for Amazon
	// S3 for your role's account. Amazon SageMaker uses server-side encryption with
	// KMS-managed keys for <code>OutputDataConfig</code>. If you use a bucket policy
	// with an <code>s3:PutObject</code> permission that only allows objects with
	// server-side encryption, set the condition key of
	// <code>s3:x-amz-server-side-encryption</code> to <code>"aws:kms"</code>. For more
	// information, see <a
	// href="https://docs.aws.amazon.com/AmazonS3/latest/dev/UsingKMSEncryption.html">KMS-Managed
	// Encryption Keys</a> in the <i>Amazon Simple Storage Service Developer Guide.</i>
	// </p> <p>The KMS key policy must grant permission to the IAM role that you
	// specify in your <code>CreateTrainingJob</code>, <code>CreateTransformJob</code>,
	// or <code>CreateHyperParameterTuningJob</code> requests. For more information,
	// see <a
	// href="http://docs.aws.amazon.com/kms/latest/developerguide/key-policies.html">Using
	// Key Policies in AWS KMS</a> in the <i>AWS Key Management Service Developer
	// Guide</i>.</p>
	KmsKeyId *string
	// Identifies the S3 path where you want Amazon SageMaker to store the model
	// artifacts. For example, s3://bucket-name/key-name-prefix.
	S3OutputPath *string
}

// Defines the possible values for categorical, continuous, and integer
// hyperparameters to be used by an algorithm.
type ParameterRange struct {
	// A IntegerParameterRangeSpecification object that defines the possible values for
	// an integer hyperparameter.
	IntegerParameterRangeSpecification *IntegerParameterRangeSpecification
	// A CategoricalParameterRangeSpecification object that defines the possible values
	// for a categorical hyperparameter.
	CategoricalParameterRangeSpecification *CategoricalParameterRangeSpecification
	// A ContinuousParameterRangeSpecification object that defines the possible values
	// for a continuous hyperparameter.
	ContinuousParameterRangeSpecification *ContinuousParameterRangeSpecification
}

// Specifies ranges of integer, continuous, and categorical hyperparameters that a
// hyperparameter tuning job searches. The hyperparameter tuning job launches
// training jobs with hyperparameter values within these ranges to find the
// combination of values that result in the training job with the best performance
// as measured by the objective metric of the hyperparameter tuning job. You can
// specify a maximum of 20 hyperparameters that a hyperparameter tuning job can
// search over. Every possible value of a categorical parameter range counts
// against this limit.
type ParameterRanges struct {
	// The array of CategoricalParameterRange () objects that specify ranges of
	// categorical hyperparameters that a hyperparameter tuning job searches.
	CategoricalParameterRanges []*CategoricalParameterRange
	// The array of ContinuousParameterRange () objects that specify ranges of
	// continuous hyperparameters that a hyperparameter tuning job searches.
	ContinuousParameterRanges []*ContinuousParameterRange
	// The array of IntegerParameterRange () objects that specify ranges of integer
	// hyperparameters that a hyperparameter tuning job searches.
	IntegerParameterRanges []*IntegerParameterRange
}

// The trial that a trial component is associated with and the experiment the trial
// is part of. A component might not be associated with a trial. A component can be
// associated with multiple trials.
type Parent struct {
	// The name of the experiment.
	ExperimentName *string
	// The name of the trial.
	TrialName *string
}

// A previously completed or stopped hyperparameter tuning job to be used as a
// starting point for a new hyperparameter tuning job.
type ParentHyperParameterTuningJob struct {
	// The name of the hyperparameter tuning job to be used as a starting point for a
	// new hyperparameter tuning job.
	HyperParameterTuningJobName *string
}

// Configuration for the cluster used to run a processing job.
type ProcessingClusterConfig struct {
	// The number of ML compute instances to use in the processing job. For distributed
	// processing jobs, specify a value greater than 1. The default value is 1.
	InstanceCount *int32
	// The size of the ML storage volume in gigabytes that you want to provision. You
	// must specify sufficient ML storage for your scenario.
	VolumeSizeInGB *int32
	// The AWS Key Management Service (AWS KMS) key that Amazon SageMaker uses to
	// encrypt data on the storage volume attached to the ML compute instance(s) that
	// run the processing job.
	VolumeKmsKeyId *string
	// The ML compute instance type for the processing job.
	InstanceType ProcessingInstanceType
}

// The inputs for a processing job.
type ProcessingInput struct {
	// The name of the inputs for the processing job.
	InputName *string
	// The S3 inputs for the processing job.
	S3Input *ProcessingS3Input
}

// An Amazon SageMaker processing job that is used to analyze data and evaluate
// models. For more information, see Process Data and Evaluate Models
// (https://docs.aws.amazon.com/sagemaker/latest/dg/processing-job.html).
type ProcessingJob struct {
	// For each input, data is downloaded from S3 into the processing container before
	// the processing job begins running if "S3InputMode" is set to File.
	ProcessingInputs []*ProcessingInput
	// The name of the processing job.
	ProcessingJobName *string
	// The ARN of the role used to create the processing job.
	RoleArn *string
	// The output configuration for the processing job.
	ProcessingOutputConfig *ProcessingOutputConfig
	// The ARN of the training job associated with this processing job.
	TrainingJobArn *string
	// Networking options for a job, such as network traffic encryption between
	// containers, whether to allow inbound and outbound network calls to and from
	// containers, and the VPC subnets and security groups to use for VPC-enabled jobs.
	NetworkConfig *NetworkConfig
	// The time that the processing job ended.
	ProcessingEndTime *time.Time
	// The ARN of the processing job.
	ProcessingJobArn *string
	// Associates a SageMaker job as a trial component with an experiment and trial.
	// Specified when you call the following APIs:
	//
	//     * CreateProcessingJob ()
	//
	//     *
	// CreateTrainingJob ()
	//
	//     * CreateTransformJob ()
	ExperimentConfig *ExperimentConfig
	// The time that the processing job started.
	ProcessingStartTime *time.Time
	// The ARN of a monitoring schedule for an endpoint associated with this processing
	// job.
	MonitoringScheduleArn *string
	// An array of key-value pairs. For more information, see Using Cost Allocation
	// Tags
	// (https://docs.aws.amazon.com/awsaccountbilling/latest/aboutv2/cost-alloc-tags.html#allocation-whatURL)
	// in the AWS Billing and Cost Management User Guide.
	Tags []*Tag
	// A string, up to one KB in size, that contains the reason a processing job
	// failed, if it failed.
	FailureReason *string
	// The Amazon Resource Name (ARN) of the AutoML job associated with this processing
	// job.
	AutoMLJobArn *string
	// Identifies the resources, ML compute instances, and ML storage volumes to deploy
	// for a processing job. In distributed training, you specify more than one
	// instance.
	ProcessingResources *ProcessingResources
	// A string, up to one KB in size, that contains metadata from the processing
	// container when the processing job exits.
	ExitMessage *string
	// The status of the processing job.
	ProcessingJobStatus ProcessingJobStatus
	// The time the processing job was last modified.
	LastModifiedTime *time.Time
	// The time the processing job was created.
	CreationTime *time.Time
	// Sets the environment variables in the Docker container.
	Environment map[string]*string
	// Configuration to run a processing job in a specified container image.
	AppSpecification *AppSpecification
	// Specifies a time limit for how long the processing job is allowed to run.
	StoppingCondition *ProcessingStoppingCondition
}

// Summary of information about a processing job.
type ProcessingJobSummary struct {
	// A timestamp that indicates the last time the processing job was modified.
	LastModifiedTime *time.Time
	// The time at which the processing job was created.
	CreationTime *time.Time
	// The status of the processing job.
	ProcessingJobStatus ProcessingJobStatus
	// The time at which the processing job completed.
	ProcessingEndTime *time.Time
	// An optional string, up to one KB in size, that contains metadata from the
	// processing container when the processing job exits.
	ExitMessage *string
	// The Amazon Resource Name (ARN) of the processing job..
	ProcessingJobArn *string
	// The name of the processing job.
	ProcessingJobName *string
	// A string, up to one KB in size, that contains the reason a processing job
	// failed, if it failed.
	FailureReason *string
}

// Describes the results of a processing job.
type ProcessingOutput struct {
	// The name for the processing job output.
	OutputName *string
	// Configuration for processing job outputs in Amazon S3.
	S3Output *ProcessingS3Output
}

// The output configuration for the processing job.
type ProcessingOutputConfig struct {
	// Output configuration information for a processing job.
	Outputs []*ProcessingOutput
	// The AWS Key Management Service (AWS KMS) key that Amazon SageMaker uses to
	// encrypt the processing job output. KmsKeyId can be an ID of a KMS key, ARN of a
	// KMS key, alias of a KMS key, or alias of a KMS key. The KmsKeyId is applied to
	// all outputs.
	KmsKeyId *string
}

// Identifies the resources, ML compute instances, and ML storage volumes to deploy
// for a processing job. In distributed training, you specify more than one
// instance.
type ProcessingResources struct {
	// The configuration for the resources in a cluster used to run the processing job.
	ClusterConfig *ProcessingClusterConfig
}

// Information about where and how you want to obtain the inputs for an processing
// job.
type ProcessingS3Input struct {
	// Whether you use an S3Prefix or a ManifestFile for the data type. If you choose
	// S3Prefix, S3Uri identifies a key name prefix. Amazon SageMaker uses all objects
	// with the specified key name prefix for the processing job. If you choose
	// ManifestFile, S3Uri identifies an object that is a manifest file containing a
	// list of object keys that you want Amazon SageMaker to use for the processing
	// job.
	S3DataType ProcessingS3DataType
	// Whether the data stored in Amazon S3 is FullyReplicated or ShardedByS3Key.
	S3DataDistributionType ProcessingS3DataDistributionType
	// Whether to use File or Pipe input mode. In File mode, Amazon SageMaker copies
	// the data from the input source onto the local Amazon Elastic Block Store (Amazon
	// EBS) volumes before starting your training algorithm. This is the most commonly
	// used input mode. In Pipe mode, Amazon SageMaker streams input data from the
	// source directly to your algorithm without using the EBS volume.
	S3InputMode ProcessingS3InputMode
	// Whether to use Gzip compression for Amazon S3 storage.
	S3CompressionType ProcessingS3CompressionType
	// The URI for the Amazon S3 storage where you want Amazon SageMaker to download
	// the artifacts needed to run a processing job.
	S3Uri *string
	// The local path to the Amazon S3 bucket where you want Amazon SageMaker to
	// download the inputs to run a processing job. LocalPath is an absolute path to
	// the input data.
	LocalPath *string
}

// Information about where and how you want to store the results of an processing
// job.
type ProcessingS3Output struct {
	// The local path to the Amazon S3 bucket where you want Amazon SageMaker to save
	// the results of an processing job. LocalPath is an absolute path to the input
	// data.
	LocalPath *string
	// Whether to upload the results of the processing job continuously or after the
	// job completes.
	S3UploadMode ProcessingS3UploadMode
	// A URI that identifies the Amazon S3 bucket where you want Amazon SageMaker to
	// save the results of a processing job.
	S3Uri *string
}

// Specifies a time limit for how long the processing job is allowed to run.
type ProcessingStoppingCondition struct {
	// Specifies the maximum runtime in seconds.
	MaxRuntimeInSeconds *int32
}

// Identifies a model that you want to host and the resources to deploy for hosting
// it. If you are deploying multiple models, tell Amazon SageMaker how to
// distribute traffic among the models by specifying variant weights.
type ProductionVariant struct {
	// The name of the model that you want to host. This is the name that you specified
	// when creating the model.
	ModelName *string
	// The ML compute instance type.
	InstanceType ProductionVariantInstanceType
	// Number of instances to launch initially.
	InitialInstanceCount *int32
	// The name of the production variant.
	VariantName *string
	// Determines initial traffic distribution among all of the models that you specify
	// in the endpoint configuration. The traffic to a production variant is determined
	// by the ratio of the VariantWeight to the sum of all VariantWeight values across
	// all ProductionVariants. If unspecified, it defaults to 1.0.
	InitialVariantWeight *float32
	// The size of the Elastic Inference (EI) instance to use for the production
	// variant. EI instances provide on-demand GPU computing for inference. For more
	// information, see Using Elastic Inference in Amazon SageMaker
	// (https://docs.aws.amazon.com/sagemaker/latest/dg/ei.html).
	AcceleratorType ProductionVariantAcceleratorType
}

// Describes weight and capacities for a production variant associated with an
// endpoint. If you sent a request to the UpdateEndpointWeightsAndCapacities API
// and the endpoint status is Updating, you get different desired and current
// values.
type ProductionVariantSummary struct {
	// The requested weight, as specified in the UpdateEndpointWeightsAndCapacities
	// request.
	DesiredWeight *float32
	// The name of the variant.
	VariantName *string
	// The number of instances associated with the variant.
	CurrentInstanceCount *int32
	// The number of instances requested in the UpdateEndpointWeightsAndCapacities
	// request.
	DesiredInstanceCount *int32
	// The weight associated with the variant.
	CurrentWeight *float32
	// An array of DeployedImage objects that specify the Amazon EC2 Container Registry
	// paths of the inference images deployed on instances of this ProductionVariant.
	DeployedImages []*DeployedImage
}

// Part of the SuggestionQuery type. Specifies a hint for retrieving property names
// that begin with the specified text.
type PropertyNameQuery struct {
	// Text that begins a property's name.
	PropertyNameHint *string
}

// A property name returned from a GetSearchSuggestions call that specifies a value
// in the PropertyNameQuery field.
type PropertyNameSuggestion struct {
	// A suggested property name based on what you entered in the search textbox in the
	// Amazon SageMaker console.
	PropertyName *string
}

// Defines the amount of money paid to an Amazon Mechanical Turk worker for each
// task performed. Use one of the following prices for bounding box tasks. Prices
// are in US dollars and should be based on the complexity of the task; the longer
// it takes in your initial testing, the more you should offer.
//
//     * 0.036
//
//     *
// 0.048
//
//     * 0.060
//
//     * 0.072
//
//     * 0.120
//
//     * 0.240
//
//     * 0.360
//
//     *
// 0.480
//
//     * 0.600
//
//     * 0.720
//
//     * 0.840
//
//     * 0.960
//
//     * 1.080
//
//     *
// 1.200
//
// Use one of the following prices for image classification, text
// classification, and custom tasks. Prices are in US dollars.
//
//     * 0.012
//
//     *
// 0.024
//
//     * 0.036
//
//     * 0.048
//
//     * 0.060
//
//     * 0.072
//
//     * 0.120
//
//     *
// 0.240
//
//     * 0.360
//
//     * 0.480
//
//     * 0.600
//
//     * 0.720
//
//     * 0.840
//
//     *
// 0.960
//
//     * 1.080
//
//     * 1.200
//
// Use one of the following prices for semantic
// segmentation tasks. Prices are in US dollars.
//
//     * 0.840
//
//     * 0.960
//
//     *
// 1.080
//
//     * 1.200
//
// Use one of the following prices for Textract AnalyzeDocument
// Important Form Key Amazon Augmented AI review tasks. Prices are in US dollars.
//
//
// * 2.400
//
//     * 2.280
//
//     * 2.160
//
//     * 2.040
//
//     * 1.920
//
//     * 1.800
//
//     *
// 1.680
//
//     * 1.560
//
//     * 1.440
//
//     * 1.320
//
//     * 1.200
//
//     * 1.080
//
//     *
// 0.960
//
//     * 0.840
//
//     * 0.720
//
//     * 0.600
//
//     * 0.480
//
//     * 0.360
//
//     *
// 0.240
//
//     * 0.120
//
//     * 0.072
//
//     * 0.060
//
//     * 0.048
//
//     * 0.036
//
//     *
// 0.024
//
//     * 0.012
//
// Use one of the following prices for Rekognition
// DetectModerationLabels Amazon Augmented AI review tasks. Prices are in US
// dollars.
//
//     * 1.200
//
//     * 1.080
//
//     * 0.960
//
//     * 0.840
//
//     * 0.720
//
//     *
// 0.600
//
//     * 0.480
//
//     * 0.360
//
//     * 0.240
//
//     * 0.120
//
//     * 0.072
//
//     *
// 0.060
//
//     * 0.048
//
//     * 0.036
//
//     * 0.024
//
//     * 0.012
//
// Use one of the
// following prices for Amazon Augmented AI custom human review tasks. Prices are
// in US dollars.
//
//     * 1.200
//
//     * 1.080
//
//     * 0.960
//
//     * 0.840
//
//     *
// 0.720
//
//     * 0.600
//
//     * 0.480
//
//     * 0.360
//
//     * 0.240
//
//     * 0.120
//
//     *
// 0.072
//
//     * 0.060
//
//     * 0.048
//
//     * 0.036
//
//     * 0.024
//
//     * 0.012
type PublicWorkforceTaskPrice struct {
	// Defines the amount of money paid to an Amazon Mechanical Turk worker in United
	// States dollars.
	AmountInUsd *USD
}

// Contains input values for a task.
type RenderableTask struct {
	// A JSON object that contains values for the variables defined in the template. It
	// is made available to the template under the substitution variable task.input.
	// For example, if you define a variable task.input.text in your template, you can
	// supply the variable in the JSON object as "text": "sample text".
	Input *string
}

// A description of an error that occurred while rendering the template.
type RenderingError struct {
	// A human-readable message describing the error.
	Message *string
	// A unique identifier for a specific class of errors.
	Code *string
}

// The resolved attributes.
type ResolvedAttributes struct {
	// The problem type.
	ProblemType ProblemType
	// How long a job is allowed to run, or how many candidates a job is allowed to
	// generate.
	CompletionCriteria *AutoMLJobCompletionCriteria
	// Applies a metric to minimize or maximize for the job's objective.
	AutoMLJobObjective *AutoMLJobObjective
}

// Describes the resources, including ML compute instances and ML storage volumes,
// to use for model training.
type ResourceConfig struct {
	// The AWS KMS key that Amazon SageMaker uses to encrypt data on the storage volume
	// attached to the ML compute instance(s) that run the training job. Certain
	// Nitro-based instances include local storage, dependent on the instance type.
	// Local storage volumes are encrypted using a hardware module on the instance. You
	// can't request a VolumeKmsKeyId when using an instance type with local storage.
	// For a list of instance types that support local instance storage, see Instance
	// Store Volumes
	// (https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/InstanceStorage.html#instance-store-volumes).
	// For more information about local instance storage encryption, see SSD Instance
	// Store Volumes
	// (https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ssd-instance-store.html).
	// The VolumeKmsKeyId can be in any of the following formats:
	//
	//     * // KMS Key ID
	// "1234abcd-12ab-34cd-56ef-1234567890ab"
	//
	//     * // Amazon Resource Name (ARN) of a
	// KMS Key
	// "arn:aws:kms:us-west-2:111122223333:key/1234abcd-12ab-34cd-56ef-1234567890ab"
	VolumeKmsKeyId *string
	// The ML compute instance type.
	InstanceType TrainingInstanceType
	// The number of ML compute instances to use. For distributed training, provide a
	// value greater than 1.
	InstanceCount *int32
	// The size of the ML storage volume that you want to provision. ML storage volumes
	// store model artifacts and incremental states. Training algorithms might also use
	// the ML storage volume for scratch space. If you want to store the training data
	// in the ML storage volume, choose File as the TrainingInputMode in the algorithm
	// specification. You must specify sufficient ML storage for your scenario. Amazon
	// SageMaker supports only the General Purpose SSD (gp2) ML storage volume type.
	// Certain Nitro-based instances include local storage with a fixed total size,
	// dependent on the instance type. When using these instances for training, Amazon
	// SageMaker mounts the local instance storage instead of Amazon EBS gp2 storage.
	// You can't request a VolumeSizeInGB greater than the total size of the local
	// instance storage. For a list of instance types that support local instance
	// storage, including the total size per instance type, see Instance Store Volumes
	// (https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/InstanceStorage.html#instance-store-volumes).
	VolumeSizeInGB *int32
}

// Specifies the maximum number of training jobs and parallel training jobs that a
// hyperparameter tuning job can launch.
type ResourceLimits struct {
	// The maximum number of concurrent training jobs that a hyperparameter tuning job
	// can launch.
	MaxParallelTrainingJobs *int32
	// The maximum number of training jobs that a hyperparameter tuning job can launch.
	MaxNumberOfTrainingJobs *int32
}

// The instance type and the Amazon Resource Name (ARN) of the SageMaker image
// created on the instance. The ARN is stored as metadata in SageMaker Studio
// notebooks.
type ResourceSpec struct {
	// The Amazon Resource Name (ARN) of the SageMaker image created on the instance.
	SageMakerImageArn *string
	// The instance type.
	InstanceType AppInstanceType
}

// The retention policy for data stored on an Amazon Elastic File System (EFS)
// volume.
type RetentionPolicy struct {
	// The default is Retain, which specifies to keep the data stored on the EFS
	// volume. Specify Delete to delete the data stored on the EFS volume.
	HomeEfsFileSystem RetentionType
}

// Describes the S3 data source.
type S3DataSource struct {
	// If you want Amazon SageMaker to replicate the entire dataset on each ML compute
	// instance that is launched for model training, specify FullyReplicated. If you
	// want Amazon SageMaker to replicate a subset of data on each ML compute instance
	// that is launched for model training, specify ShardedByS3Key. If there are n ML
	// compute instances launched for a training job, each instance gets approximately
	// 1/n of the number of S3 objects. In this case, model training on each machine
	// uses only the subset of training data. Don't choose more ML compute instances
	// for training than available S3 objects. If you do, some nodes won't get any data
	// and you will pay for nodes that aren't getting any training data. This applies
	// in both File and Pipe modes. Keep this in mind when developing algorithms. In
	// distributed training, where you use multiple ML compute EC2 instances, you might
	// choose ShardedByS3Key. If the algorithm requires copying training data to the ML
	// storage volume (when TrainingInputMode is set to File), this copies 1/n of the
	// number of objects.
	S3DataDistributionType S3DataDistribution
	// A list of one or more attribute names to use that are found in a specified
	// augmented manifest file.
	AttributeNames []*string
	// If you choose S3Prefix, S3Uri identifies a key name prefix. Amazon SageMaker
	// uses all objects that match the specified key name prefix for model training. If
	// you choose ManifestFile, S3Uri identifies an object that is a manifest file
	// containing a list of object keys that you want Amazon SageMaker to use for model
	// training. If you choose AugmentedManifestFile, S3Uri identifies an object that
	// is an augmented manifest file in JSON lines format. This file contains the data
	// you want to use for model training. AugmentedManifestFile can only be used if
	// the Channel's input mode is Pipe.
	S3DataType S3DataType
	// Depending on the value specified for the S3DataType, identifies either a key
	// name prefix or a manifest. For example:
	//
	//     * A key name prefix might look like
	// this: s3://bucketname/exampleprefix
	//
	//     * A manifest might look like this:
	// s3://bucketname/example.manifest A manifest is an S3 object which is a JSON file
	// consisting of an array of elements. The first element is a prefix which is
	// followed by one or more suffixes. SageMaker appends the suffix elements to the
	// prefix to get a full set of S3Uri. Note that the prefix must be a valid
	// non-empty S3Uri that precludes users from specifying a manifest whose individual
	// S3Uri is sourced from different S3 buckets. The following code example shows a
	// valid manifest format: [ {"prefix": "s3://customer_bucket/some/prefix/"},
	// "relative/path/to/custdata-1", "relative/path/custdata-2", ...
	// "relative/path/custdata-N"] This JSON is equivalent to the following S3Uri list:
	// s3://customer_bucket/some/prefix/relative/path/to/custdata-1s3://customer_bucket/some/prefix/relative/path/custdata-2...s3://customer_bucket/some/prefix/relative/path/custdata-N
	// The complete set of S3Uri in this manifest is the input data for the channel for
	// this data source. The object that each S3Uri points to must be readable by the
	// IAM role that Amazon SageMaker uses to perform tasks on your behalf.
	S3Uri *string
}

// Configuration details about the monitoring schedule.
type ScheduleConfig struct {
	// A cron expression that describes details about the monitoring schedule.
	// <p>Currently the only supported cron expressions are:</p> <ul> <li> <p>If you
	// want to set the job to start every hour, please use the following:</p> <p>
	// <code>Hourly: cron(0 * ? * * *)</code> </p> </li> <li> <p>If you want to start
	// the job daily:</p> <p> <code>cron(0 [00-23] ? * * *)</code> </p> </li> </ul>
	// <p>For example, the following are valid cron expressions:</p> <ul> <li> <p>Daily
	// at noon UTC: <code>cron(0 12 ? * * *)</code> </p> </li> <li> <p>Daily at
	// midnight UTC: <code>cron(0 0 ? * * *)</code> </p> </li> </ul> <p>To support
	// running every 6, 12 hours, the following are also supported:</p> <p>
	// <code>cron(0 [00-23]/[01-24] ? * * *)</code> </p> <p>For example, the following
	// are valid cron expressions:</p> <ul> <li> <p>Every 12 hours, starting at 5pm
	// UTC: <code>cron(0 17/12 ? * * *)</code> </p> </li> <li> <p>Every two hours
	// starting at midnight: <code>cron(0 0/2 ? * * *)</code> </p> </li> </ul> <note>
	// <ul> <li> <p>Even though the cron expression is set to start at 5PM UTC, note
	// that there could be a delay of 0-20 minutes from the actual requested time to
	// run the execution. </p> </li> <li> <p>We recommend that if you would like a
	// daily schedule, you do not provide this parameter. Amazon SageMaker will pick a
	// time for running every day.</p> </li> </ul> </note>
	ScheduleExpression *string
}

// A multi-expression that searches for the specified resource or resources in a
// search. All resource objects that satisfy the expression's condition are
// included in the search results. You must specify at least one subexpression,
// filter, or nested filter. A SearchExpression can contain up to twenty elements.
// A SearchExpression contains the following components:
//
//     * A list of Filter
// objects. Each filter defines a simple Boolean expression comprised of a resource
// property name, Boolean operator, and value.
//
//     * A list of NestedFilter
// objects. Each nested filter defines a list of Boolean expressions using a list
// of resource properties. A nested filter is satisfied if a single object in the
// list satisfies all Boolean expressions.
//
//     * A list of SearchExpression
// objects. A search expression object can be nested in a list of search expression
// objects.
//
//     * A Boolean operator: And or Or.
type SearchExpression struct {
	// A list of filter objects.
	Filters []*Filter
	// A list of search expression objects.
	SubExpressions []*SearchExpression
	// A Boolean operator used to evaluate the search expression. If you want every
	// conditional statement in all lists to be satisfied for the entire search
	// expression to be true, specify And. If only a single conditional statement needs
	// to be true for the entire search expression to be true, specify Or. The default
	// value is And.
	Operator BooleanOperator
	// A list of nested filter objects.
	NestedFilters []*NestedFilters
}

// A single resource returned as part of the Search () API response.
type SearchRecord struct {
	// The properties of a trial.
	Trial *Trial
	// The properties of an experiment.
	Experiment *Experiment
	// The properties of a trial component.
	TrialComponent *TrialComponent
	// The properties of a training job.
	TrainingJob *TrainingJob
}

// An array element of DescribeTrainingJobResponse$SecondaryStatusTransitions ().
// It provides additional details about a status that the training job has
// transitioned through. A training job can be in one of several states, for
// example, starting, downloading, training, or uploading. Within each state, there
// are a number of intermediate states. For example, within the starting state,
// Amazon SageMaker could be starting the training job or launching the ML
// instances. These transitional states are referred to as the job's secondary
// status.
type SecondaryStatusTransition struct {
	// A detailed description of the progress within a secondary status. Amazon
	// SageMaker provides secondary statuses and status messages that apply to each of
	// them: Starting
	//
	//     * Starting the training job.
	//
	//     * Launching requested ML
	// instances.
	//
	//     * Insufficient capacity error from EC2 while launching
	// instances, retrying!
	//
	//     * Launched instance was unhealthy, replacing it!
	//
	//
	// * Preparing the instances for training.
	//
	// Training
	//
	//     * Downloading the
	// training image.
	//
	//     * Training image download completed. Training in
	// progress.
	//
	// Status messages are subject to change. Therefore, we recommend not
	// including them in code that programmatically initiates actions. For examples,
	// don't use status messages in if statements. To have an overview of your training
	// job's progress, view TrainingJobStatus and SecondaryStatus in
	// DescribeTrainingJob (), and StatusMessage together. For example, at the start of
	// a training job, you might see the following:
	//
	//     * TrainingJobStatus -
	// InProgress
	//
	//     * SecondaryStatus - Training
	//
	//     * StatusMessage - Downloading
	// the training image
	StatusMessage *string
	// A timestamp that shows when the training job transitioned to the current
	// secondary status state.
	StartTime *time.Time
	// Contains a secondary status information from a training job. Status might be one
	// of the following secondary statuses: InProgress
	//
	//     * Starting - Starting the
	// training job.
	//
	//     * Downloading - An optional stage for algorithms that support
	// File training input mode. It indicates that data is being downloaded to the ML
	// storage volumes.
	//
	//     * Training - Training is in progress.
	//
	//     * Uploading -
	// Training is complete and the model artifacts are being uploaded to the S3
	// location.
	//
	// Completed
	//
	//     * Completed - The training job has
	// completed.
	//
	// Failed
	//
	//     * Failed - The training job has failed. The reason for
	// the failure is returned in the FailureReason field of
	// DescribeTrainingJobResponse.
	//
	// Stopped
	//
	//     * MaxRuntimeExceeded - The job
	// stopped because it exceeded the maximum allowed runtime.
	//
	//     * Stopped - The
	// training job has stopped.
	//
	// Stopping
	//
	//     * Stopping - Stopping the training
	// job.
	//
	// We no longer support the following secondary statuses:
	//
	//     *
	// LaunchingMLInstances
	//
	//     * PreparingTrainingStack
	//
	//     *
	// DownloadingTrainingImage
	Status SecondaryStatus
	// A timestamp that shows when the training job transitioned out of this secondary
	// status state into another secondary status state or when the training job has
	// ended.
	EndTime *time.Time
}

// Specifies options when sharing an Amazon SageMaker Studio notebook. These
// settings are specified as part of DefaultUserSettings when the CreateDomain ()
// API is called, and as part of UserSettings when the CreateUserProfile () API is
// called.
type SharingSettings struct {
	// Whether to include the notebook cell output when sharing the notebook. The
	// default is Disabled.
	NotebookOutputOption NotebookOutputOption
	// When NotebookOutputOption is Allowed, the Amazon S3 bucket used to save the
	// notebook cell output. If S3OutputPath isn't specified, a default bucket is used.
	S3OutputPath *string
	// When NotebookOutputOption is Allowed, the AWS Key Management Service (KMS)
	// encryption key ID used to encrypt the notebook cell output in the Amazon S3
	// bucket.
	S3KmsKeyId *string
}

// A configuration for a shuffle option for input data in a channel. If you use
// S3Prefix for S3DataType, the results of the S3 key prefix matches are shuffled.
// If you use ManifestFile, the order of the S3 object references in the
// ManifestFile is shuffled. If you use AugmentedManifestFile, the order of the
// JSON lines in the AugmentedManifestFile is shuffled. The shuffling order is
// determined using the Seed value. For Pipe input mode, when ShuffleConfig is
// specified shuffling is done at the start of every epoch. With large datasets,
// this ensures that the order of the training data is different for each epoch,
// and it helps reduce bias and possible overfitting. In a multi-node training job
// when ShuffleConfig is combined with S3DataDistributionType of ShardedByS3Key,
// the data is shuffled across nodes so that the content sent to a particular node
// on the first epoch might be sent to a different node on the second epoch.
type ShuffleConfig struct {
	// Determines the shuffling order in ShuffleConfig value.
	Seed *int64
}

// Specifies an algorithm that was used to create the model package. The algorithm
// must be either an algorithm resource in your Amazon SageMaker account or an
// algorithm in AWS Marketplace that you are subscribed to.
type SourceAlgorithm struct {
	// The name of an algorithm that was used to create the model package. The
	// algorithm must be either an algorithm resource in your Amazon SageMaker account
	// or an algorithm in AWS Marketplace that you are subscribed to.
	AlgorithmName *string
	// The Amazon S3 path where the model artifacts, which result from model training,
	// are stored. This path must point to a single gzip compressed tar archive
	// (.tar.gz suffix).
	ModelDataUrl *string
}

// A list of algorithms that were used to create a model package.
type SourceAlgorithmSpecification struct {
	// A list of the algorithms that were used to create a model package.
	SourceAlgorithms []*SourceAlgorithm
}

// A list of IP address ranges (CIDRs
// (https://docs.aws.amazon.com/vpc/latest/userguide/VPC_Subnets.html)). Used to
// create an allow list of IP addresses for a private workforce. For more
// information, see .
type SourceIpConfig struct {
	// A list of one to ten Classless Inter-Domain Routing
	// (https://docs.aws.amazon.com/vpc/latest/userguide/VPC_Subnets.html) (CIDR)
	// values. Maximum: Ten CIDR values The following Length Constraints apply to
	// individual CIDR values in the CIDR value list.
	Cidrs []*string
}

// Specifies a limit to how long a model training or compilation job can run. It
// also specifies how long you are willing to wait for a managed spot training job
// to complete. When the job reaches the time limit, Amazon SageMaker ends the
// training or compilation job. Use this API to cap model training costs. To stop a
// job, Amazon SageMaker sends the algorithm the SIGTERM signal, which delays job
// termination for 120 seconds. Algorithms can use this 120-second window to save
// the model artifacts, so the results of training are not lost. The training
// algorithms provided by Amazon SageMaker automatically save the intermediate
// results of a model training job when possible. This attempt to save artifacts is
// only a best effort case as model might not be in a state from which it can be
// saved. For example, if training has just started, the model might not be ready
// to save. When saved, this intermediate data is a valid model artifact. You can
// use it to create a model with CreateModel. The Neural Topic Model (NTM)
// currently does not support saving intermediate model artifacts. When training
// NTMs, make sure that the maximum runtime is sufficient for the training job to
// complete.
type StoppingCondition struct {
	// The maximum length of time, in seconds, how long you are willing to wait for a
	// managed spot training job to complete. It is the amount of time spent waiting
	// for Spot capacity plus the amount of time the training job runs. It must be
	// equal to or greater than MaxRuntimeInSeconds.
	MaxWaitTimeInSeconds *int32
	// The maximum length of time, in seconds, that the training or compilation job can
	// run. If job does not complete during this time, Amazon SageMaker ends the job.
	// If value is not specified, default value is 1 day. The maximum value is 28 days.
	MaxRuntimeInSeconds *int32
}

// Describes a work team of a vendor that does the a labelling job.
type SubscribedWorkteam struct {
	// The Amazon Resource Name (ARN) of the vendor that you have subscribed.
	WorkteamArn *string
	// The title of the service provided by the vendor in the Amazon Marketplace.
	MarketplaceTitle *string
	// Marketplace product listing ID.
	ListingId *string
	// The description of the vendor from the Amazon Marketplace.
	MarketplaceDescription *string
	// The name of the vendor in the Amazon Marketplace.
	SellerName *string
}

// Specified in the GetSearchSuggestions () request. Limits the property names that
// are included in the response.
type SuggestionQuery struct {
	// Defines a property name hint. Only property names that begin with the specified
	// hint are included in the response.
	PropertyNameQuery *PropertyNameQuery
}

// Describes a tag.
type Tag struct {
	// The tag value.
	Value *string
	// The tag key.
	Key *string
}

// Contains information about a target platform that you want your model to run on,
// such as OS, architecture, and accelerators. It is an alternative of
// TargetDevice.
type TargetPlatform struct {
	// Specifies a target platform OS.
	//
	//     * LINUX: Linux-based operating systems.
	//
	//
	// * ANDROID: Android operating systems. Android API level can be specified using
	// the ANDROID_PLATFORM compiler option. For example, "CompilerOptions":
	// {'ANDROID_PLATFORM': 28}
	Os TargetPlatformOs
	// Specifies a target platform accelerator (optional).
	//
	//     * NVIDIA: Nvidia
	// graphics processing unit. It also requires gpu-code, trt-ver, cuda-ver compiler
	// options
	//
	//     * MALI: ARM Mali graphics processor
	//
	//     * INTEL_GRAPHICS:
	// Integrated Intel graphics
	Accelerator TargetPlatformAccelerator
	// Specifies a target platform architecture.
	//
	//     * X86_64: 64-bit version of the
	// x86 instruction set.
	//
	//     * X86: 32-bit version of the x86 instruction set.
	//
	//
	// * ARM64: ARMv8 64-bit CPU.
	//
	//     * ARM_EABIHF: ARMv7 32-bit, Hard Float.
	//
	//     *
	// ARM_EABI: ARMv7 32-bit, Soft Float. Used by Android 32-bit ARM platform.
	Arch TargetPlatformArch
}

// The TensorBoard app settings.
type TensorBoardAppSettings struct {
	// The default instance type and the Amazon Resource Name (ARN) of the SageMaker
	// image created on the instance.
	DefaultResourceSpec *ResourceSpec
}

// Configuration of storage locations for TensorBoard output.
type TensorBoardOutputConfig struct {
	// Path to Amazon S3 storage location for TensorBoard output.
	S3OutputPath *string
	// Path to local storage location for tensorBoard output. Defaults to
	// /opt/ml/output/tensorboard.
	LocalPath *string
}

// Contains information about a training job.
type TrainingJob struct {
	// Resources, including ML compute instances and ML storage volumes, that are
	// configured for model training.
	ResourceConfig *ResourceConfig
	// The S3 path where model artifacts that you configured when creating the job are
	// stored. Amazon SageMaker creates subfolders for model artifacts.
	OutputDataConfig *OutputDataConfig
	// Information about the Amazon S3 location that is configured for storing model
	// artifacts.
	ModelArtifacts *ModelArtifacts
	// Information about the evaluation status of the rules for the training job.
	DebugRuleEvaluationStatuses []*DebugRuleEvaluationStatus
	// A VpcConfig () object that specifies the VPC that this training job has access
	// to. For more information, see Protect Training Jobs by Using an Amazon Virtual
	// Private Cloud (https://docs.aws.amazon.com/sagemaker/latest/dg/train-vpc.html).
	VpcConfig *VpcConfig
	// An array of Channel objects that describes each data input channel.
	InputDataConfig []*Channel
	// If the TrainingJob was created with network isolation, the value is set to true.
	// If network isolation is enabled, nodes can't communicate beyond the VPC they run
	// in.
	EnableNetworkIsolation *bool
	// Specifies a limit to how long a model training job can run. When the job reaches
	// the time limit, Amazon SageMaker ends the training job. Use this API to cap
	// model training costs. To stop a job, Amazon SageMaker sends the algorithm the
	// SIGTERM signal, which delays job termination for 120 seconds. Algorithms can use
	// this 120-second window to save the model artifacts, so the results of training
	// are not lost.
	StoppingCondition *StoppingCondition
	// An array of key-value pairs. For more information, see Using Cost Allocation
	// Tags
	// (https://docs.aws.amazon.com/awsaccountbilling/latest/aboutv2/cost-alloc-tags.html#allocation-what)
	// in the AWS Billing and Cost Management User Guide.
	Tags []*Tag
	// Information about the debug rule configuration.
	DebugRuleConfigurations []*DebugRuleConfiguration
	// The Amazon Resource Name (ARN) of the job.
	AutoMLJobArn *string
	// Indicates the time when the training job starts on training instances. You are
	// billed for the time interval between this time and the value of TrainingEndTime.
	// The start time in CloudWatch Logs might be later than this time. The difference
	// is due to the time it takes to download the training data and to the size of the
	// training container.
	TrainingStartTime *time.Time
	// Information about the algorithm used for training, and algorithm metadata.
	AlgorithmSpecification *AlgorithmSpecification
	// The name of the training job.
	TrainingJobName *string
	// Provides detailed information about the state of the training job. For detailed
	// information about the secondary status of the training job, see StatusMessage
	// under SecondaryStatusTransition (). Amazon SageMaker provides primary statuses
	// and secondary statuses that apply to each of them: InProgress
	//
	//     * Starting -
	// Starting the training job.
	//
	//     * Downloading - An optional stage for algorithms
	// that support File training input mode. It indicates that data is being
	// downloaded to the ML storage volumes.
	//
	//     * Training - Training is in
	// progress.
	//
	//     * Uploading - Training is complete and the model artifacts are
	// being uploaded to the S3 location.
	//
	// Completed
	//
	//     * Completed - The training
	// job has completed.
	//
	// Failed
	//
	//     * Failed - The training job has failed. The
	// reason for the failure is returned in the FailureReason field of
	// DescribeTrainingJobResponse.
	//
	// Stopped
	//
	//     * MaxRuntimeExceeded - The job
	// stopped because it exceeded the maximum allowed runtime.
	//
	//     * Stopped - The
	// training job has stopped.
	//
	// Stopping
	//
	//     * Stopping - Stopping the training
	// job.
	//
	// Valid values for SecondaryStatus are subject to change. We no longer
	// support the following secondary statuses:
	//
	//     * LaunchingMLInstances
	//
	//     *
	// PreparingTrainingStack
	//
	//     * DownloadingTrainingImage
	SecondaryStatus SecondaryStatus
	// Algorithm-specific parameters.
	HyperParameters map[string]*string
	// A list of final metric values that are set when the training job completes. Used
	// only if the training job was configured to use metrics.
	FinalMetricDataList []*MetricData
	// A history of all of the secondary statuses that the training job has
	// transitioned through.
	SecondaryStatusTransitions []*SecondaryStatusTransition
	// The billable time in seconds.
	BillableTimeInSeconds *int32
	// Contains information about the output location for managed spot training
	// checkpoint data.
	CheckpointConfig *CheckpointConfig
	// Configuration information for the debug hook parameters, collection
	// configuration, and storage paths.
	DebugHookConfig *DebugHookConfig
	// The AWS Identity and Access Management (IAM) role configured for the training
	// job.
	RoleArn *string
	// The status of the training job. Training job statuses are:
	//
	//     * InProgress -
	// The training is in progress.
	//
	//     * Completed - The training job has
	// completed.
	//
	//     * Failed - The training job has failed. To see the reason for
	// the failure, see the FailureReason field in the response to a
	// DescribeTrainingJobResponse call.
	//
	//     * Stopping - The training job is
	// stopping.
	//
	//     * Stopped - The training job has stopped.
	//
	// For more detailed
	// information, see SecondaryStatus.
	TrainingJobStatus TrainingJobStatus
	// When true, enables managed spot training using Amazon EC2 Spot instances to run
	// training jobs instead of on-demand instances. For more information, see Managed
	// Spot Training
	// (https://docs.aws.amazon.com/sagemaker/latest/dg/model-managed-spot-training.html).
	EnableManagedSpotTraining *bool
	// The Amazon Resource Name (ARN) of the associated hyperparameter tuning job if
	// the training job was launched by a hyperparameter tuning job.
	TuningJobArn *string
	// If the training job failed, the reason it failed.
	FailureReason *string
	// The Amazon Resource Name (ARN) of the labeling job.
	LabelingJobArn *string
	// Associates a SageMaker job as a trial component with an experiment and trial.
	// Specified when you call the following APIs:
	//
	//     * CreateProcessingJob ()
	//
	//     *
	// CreateTrainingJob ()
	//
	//     * CreateTransformJob ()
	ExperimentConfig *ExperimentConfig
	// A timestamp that indicates when the status of the training job was last
	// modified.
	LastModifiedTime *time.Time
	// A timestamp that indicates when the training job was created.
	CreationTime *time.Time
	// Configuration of storage locations for TensorBoard output.
	TensorBoardOutputConfig *TensorBoardOutputConfig
	// The training time in seconds.
	TrainingTimeInSeconds *int32
	// To encrypt all communications between ML compute instances in distributed
	// training, choose True. Encryption provides greater security for distributed
	// training, but training might take longer. How long it takes depends on the
	// amount of communication between compute instances, especially if you use a deep
	// learning algorithm in distributed training.
	EnableInterContainerTrafficEncryption *bool
	// The Amazon Resource Name (ARN) of the training job.
	TrainingJobArn *string
	// Indicates the time when the training job ends on training instances. You are
	// billed for the time interval between the value of TrainingStartTime and this
	// time. For successful jobs and stopped jobs, this is the time after model
	// artifacts are uploaded. For failed jobs, this is the time when Amazon SageMaker
	// detects a job failure.
	TrainingEndTime *time.Time
}

// Defines the input needed to run a training job using the algorithm.
type TrainingJobDefinition struct {
	// The input mode used by the algorithm for the training job. For the input modes
	// that Amazon SageMaker algorithms support, see Algorithms
	// (https://docs.aws.amazon.com/sagemaker/latest/dg/algos.html). If an algorithm
	// supports the File input mode, Amazon SageMaker downloads the training data from
	// S3 to the provisioned ML storage Volume, and mounts the directory to docker
	// volume for training container. If an algorithm supports the Pipe input mode,
	// Amazon SageMaker streams data directly from S3 to the container.
	TrainingInputMode TrainingInputMode
	// The hyperparameters used for the training job.
	HyperParameters map[string]*string
	// An array of Channel objects, each of which specifies an input source.
	InputDataConfig []*Channel
	// the path to the S3 bucket where you want to store model artifacts. Amazon
	// SageMaker creates subfolders for the artifacts.
	OutputDataConfig *OutputDataConfig
	// The resources, including the ML compute instances and ML storage volumes, to use
	// for model training.
	ResourceConfig *ResourceConfig
	// Specifies a limit to how long a model training job can run. When the job reaches
	// the time limit, Amazon SageMaker ends the training job. Use this API to cap
	// model training costs. To stop a job, Amazon SageMaker sends the algorithm the
	// SIGTERM signal, which delays job termination for 120 seconds. Algorithms can use
	// this 120-second window to save the model artifacts.
	StoppingCondition *StoppingCondition
}

// The numbers of training jobs launched by a hyperparameter tuning job,
// categorized by status.
type TrainingJobStatusCounters struct {
	// The number of training jobs that failed, but can be retried. A failed training
	// job can be retried only if it failed because an internal service error occurred.
	RetryableError *int32
	// The number of training jobs that failed and can't be retried. A failed training
	// job can't be retried if it failed because a client error occurred.
	NonRetryableError *int32
	// The number of completed training jobs launched by the hyperparameter tuning job.
	Completed *int32
	// The number of training jobs launched by a hyperparameter tuning job that were
	// manually stopped.
	Stopped *int32
	// The number of in-progress training jobs launched by a hyperparameter tuning job.
	InProgress *int32
}

// Provides summary information about a training job.
type TrainingJobSummary struct {
	// The status of the training job.
	TrainingJobStatus TrainingJobStatus
	// The Amazon Resource Name (ARN) of the training job.
	TrainingJobArn *string
	// A timestamp that shows when the training job ended. This field is set only if
	// the training job has one of the terminal statuses (Completed, Failed, or
	// Stopped).
	TrainingEndTime *time.Time
	// Timestamp when the training job was last modified.
	LastModifiedTime *time.Time
	// The name of the training job that you want a summary for.
	TrainingJobName *string
	// A timestamp that shows when the training job was created.
	CreationTime *time.Time
}

// Defines how the algorithm is used for a training job.
type TrainingSpecification struct {
	// A list of the metrics that the algorithm emits that can be used as the objective
	// metric in a hyperparameter tuning job.
	SupportedTuningJobObjectiveMetrics []*HyperParameterTuningJobObjective
	// A list of ChannelSpecification objects, which specify the input sources to be
	// used by the algorithm.
	TrainingChannels []*ChannelSpecification
	// Indicates whether the algorithm supports distributed training. If set to false,
	// buyers can't request more than one instance during training.
	SupportsDistributedTraining *bool
	// A list of the HyperParameterSpecification objects, that define the supported
	// hyperparameters. This is required if the algorithm supports automatic model
	// tuning.>
	SupportedHyperParameters []*HyperParameterSpecification
	// A list of MetricDefinition objects, which are used for parsing metrics generated
	// by the algorithm.
	MetricDefinitions []*MetricDefinition
	// The Amazon ECR registry path of the Docker image that contains the training
	// algorithm.
	TrainingImage *string
	// An MD5 hash of the training algorithm that identifies the Docker image used for
	// training.
	TrainingImageDigest *string
	// A list of the instance types that this algorithm can use for training.
	SupportedTrainingInstanceTypes []TrainingInstanceType
}

// Describes the location of the channel data.
type TransformDataSource struct {
	// The S3 location of the data source that is associated with a channel.
	S3DataSource *TransformS3DataSource
}

// Describes the input source of a transform job and the way the transform job
// consumes it.
type TransformInput struct {
	// If your transform data is compressed, specify the compression type. Amazon
	// SageMaker automatically decompresses the data for the transform job accordingly.
	// The default value is None.
	CompressionType CompressionType
	// Describes the location of the channel data, which is, the S3 location of the
	// input data that the model can consume.
	DataSource *TransformDataSource
	// The multipurpose internet mail extension (MIME) type of the data. Amazon
	// SageMaker uses the MIME type with each http call to transfer data to the
	// transform job.
	ContentType *string
	// The method to use to split the transform job's data files into smaller batches.
	// Splitting is necessary when the total size of each object is too large to fit in
	// a single request. You can also use data splitting to improve performance by
	// processing multiple concurrent mini-batches. The default value for SplitType is
	// None, which indicates that input data files are not split, and request payloads
	// contain the entire contents of an input object. Set the value of this parameter
	// to Line to split records on a newline character boundary. SplitType also
	// supports a number of record-oriented binary data formats. When splitting is
	// enabled, the size of a mini-batch depends on the values of the BatchStrategy and
	// MaxPayloadInMB parameters. When the value of BatchStrategy is MultiRecord,
	// Amazon SageMaker sends the maximum number of records in each request, up to the
	// MaxPayloadInMB limit. If the value of BatchStrategy is SingleRecord, Amazon
	// SageMaker sends individual records in each request. Some data formats represent
	// a record as a binary payload wrapped with extra padding bytes. When splitting is
	// applied to a binary data format, padding is removed if the value of
	// BatchStrategy is set to SingleRecord. Padding is not removed if the value of
	// BatchStrategy is set to MultiRecord. For more information about RecordIO, see
	// Create a Dataset Using RecordIO (https://mxnet.apache.org/api/faq/recordio) in
	// the MXNet documentation. For more information about TFRecord, see Consuming
	// TFRecord data
	// (https://www.tensorflow.org/guide/datasets#consuming_tfrecord_data) in the
	// TensorFlow documentation.
	SplitType SplitType
}

// A batch transform job. For information about SageMaker batch transform, see Use
// Batch Transform
// (https://docs.aws.amazon.com/sagemaker/latest/dg/batch-transform.html).
type TransformJob struct {
	// Describes the results of a transform job.
	TransformOutput *TransformOutput
	// The name of the model associated with the transform job.
	ModelName *string
	// The maximum allowed size of the payload, in MB. A payload is the data portion of
	// a record (without metadata). The value in MaxPayloadInMB must be greater than,
	// or equal to, the size of a single record. To estimate the size of a record in
	// MB, divide the size of your dataset by the number of records. To ensure that the
	// records fit within the maximum payload size, we recommend using a slightly
	// larger value. The default value is 6 MB. For cases where the payload might be
	// arbitrarily large and is transmitted using HTTP chunked encoding, set the value
	// to 0. This feature works only in supported algorithms. Currently, SageMaker
	// built-in algorithms do not support HTTP chunked encoding.
	MaxPayloadInMB *int32
	// The environment variables to set in the Docker container. We support up to 16
	// key and values entries in the map.
	Environment map[string]*string
	// A timestamp that shows when the transform Job was created.
	CreationTime *time.Time
	// Specifies the number of records to include in a mini-batch for an HTTP inference
	// request. A record is a single unit of input data that inference can be made on.
	// For example, a single line in a CSV file is a record.
	BatchStrategy BatchStrategy
	// The name of the transform job.
	TransformJobName *string
	// A list of tags associated with the transform job.
	Tags []*Tag
	// Describes the resources, including ML instance types and ML instance count, to
	// use for transform job.
	TransformResources *TransformResources
	// Indicates when the transform job starts on ML instances. You are billed for the
	// time interval between this time and the value of TransformEndTime.
	TransformStartTime *time.Time
	// Configures the timeout and maximum number of retries for processing a transform
	// job invocation.
	ModelClientConfig *ModelClientConfig
	// The maximum number of parallel requests that can be sent to each instance in a
	// transform job. If MaxConcurrentTransforms is set to 0 or left unset, SageMaker
	// checks the optional execution-parameters to determine the settings for your
	// chosen algorithm. If the execution-parameters endpoint is not enabled, the
	// default value is 1. For built-in algorithms, you don't need to set a value for
	// MaxConcurrentTransforms.
	MaxConcurrentTransforms *int32
	// The Amazon Resource Name (ARN) of the labeling job that created the transform
	// job.
	LabelingJobArn *string
	// Associates a SageMaker job as a trial component with an experiment and trial.
	// Specified when you call the following APIs:
	//
	//     * CreateProcessingJob ()
	//
	//     *
	// CreateTrainingJob ()
	//
	//     * CreateTransformJob ()
	ExperimentConfig *ExperimentConfig
	// The Amazon Resource Name (ARN) of the AutoML job that created the transform job.
	AutoMLJobArn *string
	// If the transform job failed, the reason it failed.
	FailureReason *string
	// Describes the input source of a transform job and the way the transform job
	// consumes it.
	TransformInput *TransformInput
	// The status of the transform job. Transform job statuses are:
	//
	//     * InProgress -
	// The job is in progress.
	//
	//     * Completed - The job has completed.
	//
	//     * Failed
	// - The transform job has failed. To see the reason for the failure, see the
	// FailureReason field in the response to a DescribeTransformJob call.
	//
	//     *
	// Stopping - The transform job is stopping.
	//
	//     * Stopped - The transform job has
	// stopped.
	TransformJobStatus TransformJobStatus
	// The Amazon Resource Name (ARN) of the transform job.
	TransformJobArn *string
	// Indicates when the transform job has been completed, or has stopped or failed.
	// You are billed for the time interval between this time and the value of
	// TransformStartTime.
	TransformEndTime *time.Time
	// The data structure used to specify the data to be used for inference in a batch
	// transform job and to associate the data that is relevant to the prediction
	// results in the output. The input filter provided allows you to exclude input
	// data that is not needed for inference in a batch transform job. The output
	// filter provided allows you to include input data relevant to interpreting the
	// predictions in the output from the job. For more information, see Associate
	// Prediction Results with their Corresponding Input Records
	// (https://docs.aws.amazon.com/sagemaker/latest/dg/batch-transform-data-processing.html).
	DataProcessing *DataProcessing
}

// Defines the input needed to run a transform job using the inference
// specification specified in the algorithm.
type TransformJobDefinition struct {
	// The environment variables to set in the Docker container. We support up to 16
	// key and values entries in the map.
	Environment map[string]*string
	// A string that determines the number of records included in a single mini-batch.
	// SingleRecord means only one record is used per mini-batch. MultiRecord means a
	// mini-batch is set to contain as many records that can fit within the
	// MaxPayloadInMB limit.
	BatchStrategy BatchStrategy
	// A description of the input source and the way the transform job consumes it.
	TransformInput *TransformInput
	// The maximum number of parallel requests that can be sent to each instance in a
	// transform job. The default value is 1.
	MaxConcurrentTransforms *int32
	// Identifies the Amazon S3 location where you want Amazon SageMaker to save the
	// results from the transform job.
	TransformOutput *TransformOutput
	// Identifies the ML compute instances for the transform job.
	TransformResources *TransformResources
	// The maximum payload size allowed, in MB. A payload is the data portion of a
	// record (without metadata).
	MaxPayloadInMB *int32
}

// Provides a summary of a transform job. Multiple TransformJobSummary objects are
// returned as a list after in response to a ListTransformJobs () call.
type TransformJobSummary struct {
	// If the transform job failed, the reason it failed.
	FailureReason *string
	// The status of the transform job.
	TransformJobStatus TransformJobStatus
	// Indicates when the transform job ends on compute instances. For successful jobs
	// and stopped jobs, this is the exact time recorded after the results are
	// uploaded. For failed jobs, this is when Amazon SageMaker detected that the job
	// failed.
	TransformEndTime *time.Time
	// Indicates when the transform job was last modified.
	LastModifiedTime *time.Time
	// A timestamp that shows when the transform Job was created.
	CreationTime *time.Time
	// The Amazon Resource Name (ARN) of the transform job.
	TransformJobArn *string
	// The name of the transform job.
	TransformJobName *string
}

// Describes the results of a transform job.
type TransformOutput struct {
	// The AWS Key Management Service (AWS KMS) key that Amazon SageMaker uses to
	// encrypt the model artifacts at rest using Amazon S3 server-side encryption. The
	// KmsKeyId can be any of the following formats:
	//
	//     * Key ID:
	// 1234abcd-12ab-34cd-56ef-1234567890ab
	//
	//     * Key ARN:
	// arn:aws:kms:us-west-2:111122223333:key/1234abcd-12ab-34cd-56ef-1234567890ab
	//
	//
	// * Alias name: alias/ExampleAlias
	//
	//     * Alias name ARN:
	// arn:aws:kms:us-west-2:111122223333:alias/ExampleAlias
	//
	//     <p>If you don't
	// provide a KMS key ID, Amazon SageMaker uses the default KMS key for Amazon S3
	// for your role's account. For more information, see <a
	// href="https://docs.aws.amazon.com/AmazonS3/latest/dev/UsingKMSEncryption.html">KMS-Managed
	// Encryption Keys</a> in the <i>Amazon Simple Storage Service Developer Guide.</i>
	// </p> <p>The KMS key policy must grant permission to the IAM role that you
	// specify in your <a>CreateModel</a> request. For more information, see <a
	// href="http://docs.aws.amazon.com/kms/latest/developerguide/key-policies.html">Using
	// Key Policies in AWS KMS</a> in the <i>AWS Key Management Service Developer
	// Guide</i>.</p>
	KmsKeyId *string
	// Defines how to assemble the results of the transform job as a single S3 object.
	// Choose a format that is most convenient to you. To concatenate the results in
	// binary format, specify None. To add a newline character at the end of every
	// transformed record, specify Line.
	AssembleWith AssemblyType
	// The MIME type used to specify the output data. Amazon SageMaker uses the MIME
	// type with each http call to transfer data from the transform job.
	Accept *string
	// The Amazon S3 path where you want Amazon SageMaker to store the results of the
	// transform job. For example, s3://bucket-name/key-name-prefix. For every S3
	// object used as input for the transform job, batch transform stores the
	// transformed data with an .out suffix in a corresponding subfolder in the
	// location in the output prefix. For example, for the input data stored at
	// s3://bucket-name/input-name-prefix/dataset01/data.csv, batch transform stores
	// the transformed data at
	// s3://bucket-name/output-name-prefix/input-name-prefix/data.csv.out. Batch
	// transform doesn't upload partially processed objects. For an input S3 object
	// that contains multiple records, it creates an .out file only if the transform
	// job succeeds on the entire file. When the input contains multiple S3 objects,
	// the batch transform job processes the listed S3 objects and uploads only the
	// output for successfully processed objects. If any object fails in the transform
	// job batch transform marks the job as failed to prompt investigation.
	S3OutputPath *string
}

// Describes the resources, including ML instance types and ML instance count, to
// use for transform job.
type TransformResources struct {
	// The number of ML compute instances to use in the transform job. For distributed
	// transform jobs, specify a value greater than 1. The default value is 1.
	InstanceCount *int32
	// The AWS Key Management Service (AWS KMS) key that Amazon SageMaker uses to
	// encrypt model data on the storage volume attached to the ML compute instance(s)
	// that run the batch transform job. The VolumeKmsKeyId can be any of the following
	// formats:
	//
	//     * Key ID: 1234abcd-12ab-34cd-56ef-1234567890ab
	//
	//     * Key ARN:
	// arn:aws:kms:us-west-2:111122223333:key/1234abcd-12ab-34cd-56ef-1234567890ab
	//
	//
	// * Alias name: alias/ExampleAlias
	//
	//     * Alias name ARN:
	// arn:aws:kms:us-west-2:111122223333:alias/ExampleAlias
	VolumeKmsKeyId *string
	// The ML compute instance type for the transform job. If you are using built-in
	// algorithms to transform moderately sized datasets, we recommend using
	// ml.m4.xlarge or ml.m5.large instance types.
	InstanceType TransformInstanceType
}

// Describes the S3 data source.
type TransformS3DataSource struct {
	// Depending on the value specified for the S3DataType, identifies either a key
	// name prefix or a manifest. For example:
	//
	//     * A key name prefix might look like
	// this: s3://bucketname/exampleprefix.
	//
	//     * A manifest might look like this:
	// s3://bucketname/example.manifest The manifest is an S3 object which is a JSON
	// file with the following format: [ {"prefix":
	// "s3://customer_bucket/some/prefix/"},"relative/path/to/custdata-1","relative/path/custdata-2",..."relative/path/custdata-N"]
	// The preceding JSON matches the following S3Uris:
	// s3://customer_bucket/some/prefix/relative/path/to/custdata-1s3://customer_bucket/some/prefix/relative/path/custdata-2...s3://customer_bucket/some/prefix/relative/path/custdata-N
	// The complete set of S3Uris in this manifest constitutes the input data for the
	// channel for this datasource. The object that each S3Uris points to must be
	// readable by the IAM role that Amazon SageMaker uses to perform tasks on your
	// behalf.
	S3Uri *string
	// If you choose S3Prefix, S3Uri identifies a key name prefix. Amazon SageMaker
	// uses all objects with the specified key name prefix for batch transform. If you
	// choose ManifestFile, S3Uri identifies an object that is a manifest file
	// containing a list of object keys that you want Amazon SageMaker to use for batch
	// transform. The following values are compatible: ManifestFile, S3Prefix The
	// following value is not compatible: AugmentedManifestFile
	S3DataType S3DataType
}

// The properties of a trial as returned by the Search () API.
type Trial struct {
	// The name of the experiment the trial is part of.
	ExperimentName *string
	// When the trial was created.
	CreationTime *time.Time
	// The Amazon Resource Name (ARN) of the trial.
	TrialArn *string
	// The name of the trial.
	TrialName *string
	// The source of the trial.
	Source *TrialSource
	// Who last modified the trial.
	LastModifiedTime *time.Time
	// The name of the trial as displayed. If DisplayName isn't specified, TrialName is
	// displayed.
	DisplayName *string
	// Information about the user who created or modified an experiment, trial, or
	// trial component.
	CreatedBy *UserContext
	// The list of tags that are associated with the trial. You can use Search () API
	// to search on the tags.
	Tags []*Tag
	// A list of the components associated with the trial. For each component, a
	// summary of the component's properties is included.
	TrialComponentSummaries []*TrialComponentSimpleSummary
	// Information about the user who created or modified an experiment, trial, or
	// trial component.
	LastModifiedBy *UserContext
}

// The properties of a trial component as returned by the Search () API.
type TrialComponent struct {
	// When the component ended.
	EndTime *time.Time
	// When the component was created.
	CreationTime *time.Time
	// When the component was last modified.
	LastModifiedTime *time.Time
	// Information about the user who created or modified an experiment, trial, or
	// trial component.
	LastModifiedBy *UserContext
	// The name of the trial component.
	TrialComponentName *string
	// The metrics for the component.
	Metrics []*TrialComponentMetricSummary
	// Information about the user who created or modified an experiment, trial, or
	// trial component.
	CreatedBy *UserContext
	// The hyperparameters of the component.
	Parameters map[string]*TrialComponentParameterValue
	// An array of the parents of the component. A parent is a trial the component is
	// associated with and the experiment the trial is part of. A component might not
	// have any parents.
	Parents []*Parent
	// The input artifacts of the component.
	InputArtifacts map[string]*TrialComponentArtifact
	// When the component started.
	StartTime *time.Time
	// The Amazon Resource Name (ARN) of the trial component.
	TrialComponentArn *string
	// Details of the source of the component.
	SourceDetail *TrialComponentSourceDetail
	// The list of tags that are associated with the component. You can use Search ()
	// API to search on the tags.
	Tags []*Tag
	// The Amazon Resource Name (ARN) and job type of the source of the component.
	Source *TrialComponentSource
	// The name of the component as displayed. If DisplayName isn't specified,
	// TrialComponentName is displayed.
	DisplayName *string
	// The output artifacts of the component.
	OutputArtifacts map[string]*TrialComponentArtifact
	// The status of the trial component.
	Status *TrialComponentStatus
}

// Represents an input or output artifact of a trial component. You specify
// TrialComponentArtifact as part of the InputArtifacts and OutputArtifacts
// parameters in the CreateTrialComponent () request. Examples of input artifacts
// are datasets, algorithms, hyperparameters, source code, and instance types.
// Examples of output artifacts are metrics, snapshots, logs, and images.
type TrialComponentArtifact struct {
	// The location of the artifact.
	Value *string
	// The media type of the artifact, which indicates the type of data in the artifact
	// file. The media type consists of a type and a subtype concatenated with a slash
	// (/) character, for example, text/csv, image/jpeg, and s3/uri. The type specifies
	// the category of the media. The subtype specifies the kind of data.
	MediaType *string
}

// A summary of the metrics of a trial component.
type TrialComponentMetricSummary struct {
	// When the metric was last updated.
	TimeStamp *time.Time
	// The Amazon Resource Name (ARN) of the source.
	SourceArn *string
	// The most recent value of the metric.
	Last *float64
	// The number of samples used to generate the metric.
	Count *int32
	// The minimum value of the metric.
	Min *float64
	// The average value of the metric.
	Avg *float64
	// The standard deviation of the metric.
	StdDev *float64
	// The maximum value of the metric.
	Max *float64
	// The name of the metric.
	MetricName *string
}

// The value of a hyperparameter. Only one of NumberValue or StringValue can be
// specified. This object is specified in the CreateTrialComponent () request.
type TrialComponentParameterValue struct {
	// The string value of a categorical hyperparameter. If you specify a value for
	// this parameter, you can't specify the NumberValue parameter.
	StringValue *string
	// The numeric value of a numeric hyperparameter. If you specify a value for this
	// parameter, you can't specify the StringValue parameter.
	NumberValue *float64
}

// A short summary of a trial component.
type TrialComponentSimpleSummary struct {
	// The Amazon Resource Name (ARN) and job type of the source of a trial component.
	TrialComponentSource *TrialComponentSource
	// When the component was created.
	CreationTime *time.Time
	// The name of the trial component.
	TrialComponentName *string
	// The Amazon Resource Name (ARN) of the trial component.
	TrialComponentArn *string
	// Information about the user who created or modified an experiment, trial, or
	// trial component.
	CreatedBy *UserContext
}

// The Amazon Resource Name (ARN) and job type of the source of a trial component.
type TrialComponentSource struct {
	// The source ARN.
	SourceArn *string
	// The source job type.
	SourceType *string
}

// Detailed information about the source of a trial component. Either ProcessingJob
// or TrainingJob is returned.
type TrialComponentSourceDetail struct {
	// Information about a processing job that's the source of a trial component.
	ProcessingJob *ProcessingJob
	// The Amazon Resource Name (ARN) of the source.
	SourceArn *string
	// Information about a training job that's the source of a trial component.
	TrainingJob *TrainingJob
	// Information about a transform job that's the source of the trial component.
	TransformJob *TransformJob
}

// The status of the trial component.
type TrialComponentStatus struct {
	// The status of the trial component.
	PrimaryStatus TrialComponentPrimaryStatus
	// If the component failed, a message describing why.
	Message *string
}

// A summary of the properties of a trial component. To get all the properties,
// call the DescribeTrialComponent () API and provide the TrialComponentName.
type TrialComponentSummary struct {
	// The status of the component. States include:
	//
	//     * InProgress
	//
	//     *
	// Completed
	//
	//     * Failed
	Status *TrialComponentStatus
	// Who last modified the component.
	LastModifiedBy *UserContext
	// Who created the component.
	CreatedBy *UserContext
	// When the component was created.
	CreationTime *time.Time
	// When the component was last modified.
	LastModifiedTime *time.Time
	// When the component started.
	StartTime *time.Time
	// The name of the trial component.
	TrialComponentName *string
	// When the component ended.
	EndTime *time.Time
	// The ARN of the trial component.
	TrialComponentArn *string
	// The Amazon Resource Name (ARN) and job type of the source of a trial component.
	TrialComponentSource *TrialComponentSource
	// The name of the component as displayed. If DisplayName isn't specified,
	// TrialComponentName is displayed.
	DisplayName *string
}

// The source of the trial.
type TrialSource struct {
	// The source job type.
	SourceType *string
	// The Amazon Resource Name (ARN) of the source.
	SourceArn *string
}

// A summary of the properties of a trial. To get the complete set of properties,
// call the DescribeTrial () API and provide the TrialName.
type TrialSummary struct {
	// The name of the trial.
	TrialName *string
	// The source of the trial.
	TrialSource *TrialSource
	// When the trial was created.
	CreationTime *time.Time
	// When the trial was last modified.
	LastModifiedTime *time.Time
	// The Amazon Resource Name (ARN) of the trial.
	TrialArn *string
	// The name of the trial as displayed. If DisplayName isn't specified, TrialName is
	// displayed.
	DisplayName *string
}

// The job completion criteria.
type TuningJobCompletionCriteria struct {
	// The objective metric's value.
	TargetObjectiveMetricValue *float32
}

// Provided configuration information for the worker UI for a labeling job.
type UiConfig struct {
	// The ARN of the worker task template used to render the worker UI and tools for
	// labeling job tasks. Use this parameter when you are creating a labeling job for
	// 3D point cloud and video fram labeling jobs. Use your labeling job task type to
	// select one of the following ARN's and use it with this parameter when you create
	// a labeling job. Replace aws-region with the AWS region you are creating your
	// labeling job in.  <p> <b>3D Point Cloud HumanTaskUiArns</b> </p> <p>Use this
	// <code>HumanTaskUiArn</code> for 3D point cloud object detection and 3D point
	// cloud object detection adjustment labeling jobs. </p> <ul> <li> <p>
	// <code>arn:aws:sagemaker:aws-region:394669845002:human-task-ui/PointCloudObjectDetection</code>
	// </p> </li> </ul> <p> Use this <code>HumanTaskUiArn</code> for 3D point cloud
	// object tracking and 3D point cloud object tracking adjustment labeling jobs.
	// </p> <ul> <li> <p>
	// <code>arn:aws:sagemaker:aws-region:394669845002:human-task-ui/PointCloudObjectTracking</code>
	// </p> </li> </ul> <p> Use this <code>HumanTaskUiArn</code> for 3D point cloud
	// semantic segmentation and 3D point cloud semantic segmentation adjustment
	// labeling jobs.</p> <ul> <li> <p>
	// <code>arn:aws:sagemaker:aws-region:394669845002:human-task-ui/PointCloudSemanticSegmentation</code>
	// </p> </li> </ul> <p> <b>Video Frame HumanTaskUiArns</b> </p> <p>Use this
	// <code>HumanTaskUiArn</code> for video frame object detection and video frame
	// object detection adjustment labeling jobs. </p> <ul> <li> <p>
	// <code>arn:aws:sagemaker:region:394669845002:human-task-ui/VideoObjectDetection</code>
	// </p> </li> </ul> <p> Use this <code>HumanTaskUiArn</code> for video frame object
	// tracking and video frame object tracking adjustment labeling jobs. </p> <ul>
	// <li> <p>
	// <code>arn:aws:sagemaker:aws-region:394669845002:human-task-ui/VideoObjectTracking</code>
	// </p> </li> </ul>
	HumanTaskUiArn *string
	// The Amazon S3 bucket location of the UI template, or worker task template. This
	// is the template used to render the worker UI and tools for labeling job tasks.
	// For more information about the contents of a UI template, see  Creating Your
	// Custom Labeling Task Template
	// (https://docs.aws.amazon.com/sagemaker/latest/dg/sms-custom-templates-step2.html).
	UiTemplateS3Uri *string
}

// The Liquid template for the worker user interface.
type UiTemplate struct {
	// The content of the Liquid template for the worker user interface.
	Content *string
}

// Container for user interface template information.
type UiTemplateInfo struct {
	// The SHA-256 digest of the contents of the template.
	ContentSha256 *string
	// The URL for the user interface template.
	Url *string
}

// Represents an amount of money in United States dollars/
type USD struct {
	// The whole number of dollars in the amount.
	Dollars *int32
	// Fractions of a cent, in tenths.
	TenthFractionsOfACent *int32
	// The fractional portion, in cents, of the amount.
	Cents *int32
}

// Information about the user who created or modified an experiment, trial, or
// trial component.
type UserContext struct {
	// The domain associated with the user.
	DomainId *string
	// The name of the user's profile.
	UserProfileName *string
	// The Amazon Resource Name (ARN) of the user's profile.
	UserProfileArn *string
}

// The user profile details.
type UserProfileDetails struct {
	// The user profile name.
	UserProfileName *string
	// The status.
	Status UserProfileStatus
	// The domain ID.
	DomainId *string
	// The last modified time.
	LastModifiedTime *time.Time
	// The creation time.
	CreationTime *time.Time
}

// A collection of settings.
type UserSettings struct {
	// The execution role for the user.
	ExecutionRole *string
	// The Jupyter server's app settings.
	JupyterServerAppSettings *JupyterServerAppSettings
	// The TensorBoard app settings.
	TensorBoardAppSettings *TensorBoardAppSettings
	// The kernel gateway app settings.
	KernelGatewayAppSettings *KernelGatewayAppSettings
	// The sharing settings.
	SharingSettings *SharingSettings
	// The security groups.
	SecurityGroups []*string
}

// Specifies a production variant property type for an Endpoint. If you are
// updating an endpoint with the UpdateEndpointInput$RetainAllVariantProperties ()
// option set to true, the VariantProperty objects listed in
// UpdateEndpointInput$ExcludeRetainedVariantProperties () override the existing
// variant properties of the endpoint.
type VariantProperty struct {
	// The type of variant property. The supported values are:
	//
	//     *
	// DesiredInstanceCount: Overrides the existing variant instance counts using the
	// ProductionVariant$InitialInstanceCount () values in the
	// CreateEndpointConfigInput$ProductionVariants ().
	//
	//     * DesiredWeight: Overrides
	// the existing variant weights using the ProductionVariant$InitialVariantWeight ()
	// values in the CreateEndpointConfigInput$ProductionVariants ().
	//
	//     *
	// DataCaptureConfig: (Not currently supported.)
	VariantPropertyType VariantPropertyType
}

// Specifies a VPC that your training jobs and hosted models have access to.
// Control access to and from your training and model containers by configuring the
// VPC. For more information, see Protect Endpoints by Using an Amazon Virtual
// Private Cloud (https://docs.aws.amazon.com/sagemaker/latest/dg/host-vpc.html)
// and Protect Training Jobs by Using an Amazon Virtual Private Cloud
// (https://docs.aws.amazon.com/sagemaker/latest/dg/train-vpc.html).
type VpcConfig struct {
	// The ID of the subnets in the VPC to which you want to connect your training job
	// or model. For information about the availability of specific instance types, see
	// Supported Instance Types and Availability Zones
	// (https://docs.aws.amazon.com/sagemaker/latest/dg/instance-types-az.html).
	Subnets []*string
	// The VPC security group IDs, in the form sg-xxxxxxxx. Specify the security groups
	// for the VPC that is specified in the Subnets field.
	SecurityGroupIds []*string
}

// A single private workforce, which is automatically created when you create your
// first private work team. You can create one private work force in each AWS
// Region. By default, any workforce-related API operation used in a specific
// region will apply to the workforce created in that region. To learn how to
// create a private workforce, see Create a Private Workforce
// (https://docs.aws.amazon.com/sagemaker/latest/dg/sms-workforce-create-private.html).
type Workforce struct {
	// The configuration of an OIDC Identity Provider (IdP) private workforce.
	OidcConfig *OidcConfigForResponse
	// The name of the private workforce.
	WorkforceName *string
	// The most recent date that was used to successfully add one or more IP address
	// ranges (CIDRs
	// (https://docs.aws.amazon.com/vpc/latest/userguide/VPC_Subnets.html)) to a
	// private workforce's allow list.
	LastUpdatedDate *time.Time
	// The subdomain for your OIDC Identity Provider.
	SubDomain *string
	// The configuration of an Amazon Cognito workforce. A single Cognito workforce is
	// created using and corresponds to a single  Amazon Cognito user pool
	// (https://docs.aws.amazon.com/cognito/latest/developerguide/cognito-user-identity-pools.html).
	CognitoConfig *CognitoConfig
	// A list of one to ten IP address ranges (CIDRs
	// (https://docs.aws.amazon.com/vpc/latest/userguide/VPC_Subnets.html)) to be added
	// to the workforce allow list.
	SourceIpConfig *SourceIpConfig
	// The date that the workforce is created.
	CreateDate *time.Time
	// The Amazon Resource Name (ARN) of the private workforce.
	WorkforceArn *string
}

// Provides details about a labeling work team.
type Workteam struct {
	// The date and time that the work team was last updated (timestamp).
	LastUpdatedDate *time.Time
	// The date and time that the work team was created (timestamp).
	CreateDate *time.Time
	// The URI of the labeling job's user interface. Workers open this URI to start
	// labeling your data objects.
	SubDomain *string
	// A description of the work team.
	Description *string
	// The Amazon Resource Name (ARN) that identifies the work team.
	WorkteamArn *string
	// The Amazon Marketplace identifier for a vendor's work team.
	ProductListingIds []*string
	// Configures SNS notifications of available or expiring work items for work teams.
	NotificationConfiguration *NotificationConfiguration
	// The Amazon Resource Name (ARN) of the workforce.
	WorkforceArn *string
	// The Amazon Cognito user groups that make up the work team.
	MemberDefinitions []*MemberDefinition
	// The name of the work team.
	WorkteamName *string
}
