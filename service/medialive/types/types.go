// Code generated by smithy-go-codegen DO NOT EDIT.

package types

// Aac Settings
type AacSettings struct {
	// Use MPEG-2 AAC audio instead of MPEG-4 AAC audio for raw or MPEG-2 Transport
	// Stream containers.
	Spec AacSpec
	// Set to "broadcasterMixedAd" when input contains pre-mixed main audio + AD
	// (narration) as a stereo pair. The Audio Type field (audioType) will be set to 3,
	// which signals to downstream systems that this stream contains "broadcaster mixed
	// AD". Note that the input received by the encoder must contain pre-mixed audio;
	// the encoder does not perform the mixing. The values in audioTypeControl and
	// audioType (in AudioDescription) are ignored when set to broadcasterMixedAd.
	// Leave set to "normal" when input does not contain pre-mixed audio + AD.
	InputType AacInputType
	// Rate Control Mode.
	RateControlMode AacRateControlMode
	// Sample rate in Hz. Valid values depend on rate control mode and profile.
	SampleRate *float64
	// AAC Profile.
	Profile AacProfile
	// VBR Quality Level - Only used if rateControlMode is VBR.
	VbrQuality AacVbrQuality
	// Average bitrate in bits/second. Valid values depend on rate control mode and
	// profile.
	Bitrate *float64
	// Mono, Stereo, or 5.1 channel layout. Valid values depend on rate control mode
	// and profile. The adReceiverMix setting receives a stereo description plus
	// control track and emits a mono AAC encode of the description track, with control
	// data emitted in the PES header as per ETSI TS 101 154 Annex E.
	CodingMode AacCodingMode
	// Sets LATM / LOAS AAC output for raw containers.
	RawFormat AacRawFormat
}

// Ac3 Settings
type Ac3Settings struct {
	// When set to enabled, applies a 120Hz lowpass filter to the LFE channel prior to
	// encoding. Only valid in codingMode32Lfe mode.
	LfeFilter Ac3LfeFilter
	// Sets the dialnorm for the output. If excluded and input audio is Dolby Digital,
	// dialnorm will be passed through.
	Dialnorm *int32
	// If set to filmStandard, adds dynamic range compression signaling to the output
	// bitstream as defined in the Dolby Digital specification.
	DrcProfile Ac3DrcProfile
	// Average bitrate in bits/second. Valid bitrates depend on the coding mode.
	Bitrate *float64
	// When set to "followInput", encoder metadata will be sourced from the DD, DD+, or
	// DolbyE decoder that supplied this audio data. If audio was not supplied from one
	// of these streams, then the static metadata settings will be used.
	MetadataControl Ac3MetadataControl
	// Dolby Digital coding mode. Determines number of channels.
	CodingMode Ac3CodingMode
	// Specifies the bitstream mode (bsmod) for the emitted AC-3 stream. See ATSC
	// A/52-2012 for background on these values.
	BitstreamMode Ac3BitstreamMode
}

// Archive Container Settings
type ArchiveContainerSettings struct {
	// M2ts Settings
	M2tsSettings *M2tsSettings
}

// Archive Group Settings
type ArchiveGroupSettings struct {
	// Number of seconds to write to archive file before closing and starting a new
	// one.
	RolloverInterval *int32
	// A directory and base filename where archive files should be written.
	Destination *OutputLocationRef
}

// Archive Output Settings
type ArchiveOutputSettings struct {
	// Settings specific to the container type of the file.
	ContainerSettings *ArchiveContainerSettings
	// Output file extension. If excluded, this will be auto-selected from the
	// container type.
	Extension *string
	// String concatenated to the end of the destination filename. Required for
	// multiple outputs of the same type.
	NameModifier *string
}

// Arib Destination Settings
type AribDestinationSettings struct {
}

// Arib Source Settings
type AribSourceSettings struct {
}

// Audio Channel Mapping
type AudioChannelMapping struct {
	// Indices and gain values for each input channel that should be remixed into this
	// output channel.
	InputChannelLevels []*InputChannelLevel
	// The index of the output channel being produced.
	OutputChannel *int32
}

// Audio Codec Settings
type AudioCodecSettings struct {
	// Pass Through Settings
	PassThroughSettings *PassThroughSettings
	// Ac3 Settings
	Ac3Settings *Ac3Settings
	// Mp2 Settings
	Mp2Settings *Mp2Settings
	// Aac Settings
	AacSettings *AacSettings
	// Eac3 Settings
	Eac3Settings *Eac3Settings
}

// Audio Description
type AudioDescription struct {
	// Advanced audio normalization settings.
	AudioNormalizationSettings *AudioNormalizationSettings
	// RFC 5646 language code representing the language of the audio output track. Only
	// used if languageControlMode is useConfigured, or there is no ISO 639 language
	// code specified in the input.
	LanguageCode *string
	// The name of the AudioSelector used as the source for this AudioDescription.
	AudioSelectorName *string
	// Used for MS Smooth and Apple HLS outputs. Indicates the name displayed by the
	// player (eg. English, or Director Commentary).
	StreamName *string
	// Choosing followInput will cause the ISO 639 language code of the output to
	// follow the ISO 639 language code of the input. The languageCode will be used
	// when useConfigured is set, or when followInput is selected but there is no ISO
	// 639 language code specified by the input.
	LanguageCodeControl AudioDescriptionLanguageCodeControl
	// Applies only if audioTypeControl is useConfigured. The values for audioType are
	// defined in ISO-IEC 13818-1.
	AudioType AudioType
	// The name of this AudioDescription. Outputs will use this name to uniquely
	// identify this AudioDescription. Description names should be unique within this
	// Live Event.
	Name *string
	// Audio codec settings.
	CodecSettings *AudioCodecSettings
	// Settings that control how input audio channels are remixed into the output audio
	// channels.
	RemixSettings *RemixSettings
	// Determines how audio type is determined. followInput: If the input contains an
	// ISO 639 audioType, then that value is passed through to the output. If the input
	// contains no ISO 639 audioType, the value in Audio Type is included in the
	// output. useConfigured: The value in Audio Type is included in the output. Note
	// that this field and audioType are both ignored if inputType is
	// broadcasterMixedAd.
	AudioTypeControl AudioDescriptionAudioTypeControl
}

// Audio Language Selection
type AudioLanguageSelection struct {
	// When set to "strict", the transport stream demux strictly identifies audio
	// streams by their language descriptor. If a PMT update occurs such that an audio
	// stream matching the initially selected language is no longer present then mute
	// will be encoded until the language returns. If "loose", then on a PMT update the
	// demux will choose another audio stream in the program with the same stream type
	// if it can't find one with the same language.
	LanguageSelectionPolicy AudioLanguageSelectionPolicy
	// Selects a specific three-letter language code from within an audio source.
	LanguageCode *string
}

// Audio Normalization Settings
type AudioNormalizationSettings struct {
	// Target LKFS(loudness) to adjust volume to. If no value is entered, a default
	// value will be used according to the chosen algorithm. The CALM Act (1770-1)
	// recommends a target of -24 LKFS. The EBU R-128 specification (1770-2) recommends
	// a target of -23 LKFS.
	TargetLkfs *float64
	// When set to correctAudio the output audio is corrected using the chosen
	// algorithm. If set to measureOnly, the audio will be measured but not adjusted.
	AlgorithmControl AudioNormalizationAlgorithmControl
	// Audio normalization algorithm to use. itu17701 conforms to the CALM Act
	// specification, itu17702 conforms to the EBU R-128 specification.
	Algorithm AudioNormalizationAlgorithm
}

// Audio Only Hls Settings
type AudioOnlyHlsSettings struct {
	// Specifies the segment type.
	SegmentType AudioOnlyHlsSegmentType
	// Four types of audio-only tracks are supported: Audio-Only Variant Stream The
	// client can play back this audio-only stream instead of video in low-bandwidth
	// scenarios. Represented as an EXT-X-STREAM-INF in the HLS manifest. Alternate
	// Audio, Auto Select, Default Alternate rendition that the client should try to
	// play back by default. Represented as an EXT-X-MEDIA in the HLS manifest with
	// DEFAULT=YES, AUTOSELECT=YES Alternate Audio, Auto Select, Not Default Alternate
	// rendition that the client may try to play back by default. Represented as an
	// EXT-X-MEDIA in the HLS manifest with DEFAULT=NO, AUTOSELECT=YES Alternate Audio,
	// not Auto Select Alternate rendition that the client will not try to play back by
	// default. Represented as an EXT-X-MEDIA in the HLS manifest with DEFAULT=NO,
	// AUTOSELECT=NO
	AudioTrackType AudioOnlyHlsTrackType
	// Specifies the group to which the audio Rendition belongs.
	AudioGroupId *string
	// Optional. Specifies the .jpg or .png image to use as the cover art for an
	// audio-only output. We recommend a low bit-size file because the image increases
	// the output audio bandwidth. The image is attached to the audio as an ID3 tag,
	// frame type APIC, picture type 0x10, as per the "ID3 tag version 2.4.0 - Native
	// Frames" standard.
	AudioOnlyImage *InputLocation
}

// Audio Pid Selection
type AudioPidSelection struct {
	// Selects a specific PID from within a source.
	Pid *int32
}

// Audio Selector
type AudioSelector struct {
	// The name of this AudioSelector. AudioDescriptions will use this name to uniquely
	// identify this Selector. Selector names should be unique per input.
	Name *string
	// The audio selector settings.
	SelectorSettings *AudioSelectorSettings
}

// Audio Selector Settings
type AudioSelectorSettings struct {
	// Audio Language Selection
	AudioLanguageSelection *AudioLanguageSelection
	// Audio Pid Selection
	AudioPidSelection *AudioPidSelection
	// Audio Track Selection
	AudioTrackSelection *AudioTrackSelection
}

// Audio Track
type AudioTrack struct {
	// 1-based integer value that maps to a specific audio track
	Track *int32
}

// Audio Track Selection
type AudioTrackSelection struct {
	// Selects one or more unique audio tracks from within an mp4 source.
	Tracks []*AudioTrack
}

// The settings for Automatic Input Failover.
type AutomaticInputFailoverSettings struct {
	// The input ID of the secondary input in the automatic input failover pair.
	SecondaryInputId *string
	// Input preference when deciding which input to make active when a previously
	// failed input has recovered.
	InputPreference InputPreference
}

// Avail Blanking
type AvailBlanking struct {
	// When set to enabled, causes video, audio and captions to be blanked when
	// insertion metadata is added.
	State AvailBlankingState
	// Blanking image to be used. Leave empty for solid black. Only bmp and png images
	// are supported.
	AvailBlankingImage *InputLocation
}

// Avail Configuration
type AvailConfiguration struct {
	// Ad avail settings.
	AvailSettings *AvailSettings
}

// Avail Settings
type AvailSettings struct {
	// Scte35 Time Signal Apos
	Scte35TimeSignalApos *Scte35TimeSignalApos
	// Scte35 Splice Insert
	Scte35SpliceInsert *Scte35SpliceInsert
}

// A list of schedule actions to create (in a request) or that have been created
// (in a response).
type BatchScheduleActionCreateRequest struct {
	// A list of schedule actions to create.
	ScheduleActions []*ScheduleAction
}

// List of actions that have been created in the schedule.
type BatchScheduleActionCreateResult struct {
	// List of actions that have been created in the schedule.
	ScheduleActions []*ScheduleAction
}

// A list of schedule actions to delete.
type BatchScheduleActionDeleteRequest struct {
	// A list of schedule actions to delete.
	ActionNames []*string
}

// List of actions that have been deleted from the schedule.
type BatchScheduleActionDeleteResult struct {
	// List of actions that have been deleted from the schedule.
	ScheduleActions []*ScheduleAction
}

// Blackout Slate
type BlackoutSlate struct {
	// When set to enabled, causes video, audio and captions to be blanked when
	// indicated by program metadata.
	State BlackoutSlateState
	// Path to local file to use as Network End Blackout image. Image will be scaled to
	// fill the entire output raster.
	NetworkEndBlackoutImage *InputLocation
	// Setting to enabled causes the encoder to blackout the video, audio, and
	// captions, and raise the "Network Blackout Image" slate when an SCTE104/35
	// Network End Segmentation Descriptor is encountered. The blackout will be lifted
	// when the Network Start Segmentation Descriptor is encountered. The Network End
	// and Network Start descriptors must contain a network ID that matches the value
	// entered in "Network ID".
	NetworkEndBlackout BlackoutSlateNetworkEndBlackout
	// Provides Network ID that matches EIDR ID format (e.g.,
	// "10.XXXX/XXXX-XXXX-XXXX-XXXX-XXXX-C").
	NetworkId *string
	// Blackout slate image to be used. Leave empty for solid black. Only bmp and png
	// images are supported.
	BlackoutSlateImage *InputLocation
}

// Burn In Destination Settings
type BurnInDestinationSettings struct {
	// External font file used for caption burn-in. File extension must be 'ttf' or
	// 'tte'. Although the user can select output fonts for many different types of
	// input captions, embedded, STL and teletext sources use a strict grid system.
	// Using external fonts with these caption sources could cause unexpected display
	// of proportional fonts. All burn-in and DVB-Sub font settings must match.
	Font *InputLocation
	// Specifies the horizontal position of the caption relative to the left side of
	// the output in pixels. A value of 10 would result in the captions starting 10
	// pixels from the left of the output. If no explicit xPosition is provided, the
	// horizontal caption position will be determined by the alignment parameter. All
	// burn-in and DVB-Sub font settings must match.
	XPosition *int32
	// When set to 'auto' fontSize will scale depending on the size of the output.
	// Giving a positive integer will specify the exact font size in points. All
	// burn-in and DVB-Sub font settings must match.
	FontSize *string
	// Specifies the vertical offset of the shadow relative to the captions in pixels.
	// A value of -2 would result in a shadow offset 2 pixels above the text. All
	// burn-in and DVB-Sub font settings must match.
	ShadowYOffset *int32
	// Specifies the vertical position of the caption relative to the top of the output
	// in pixels. A value of 10 would result in the captions starting 10 pixels from
	// the top of the output. If no explicit yPosition is provided, the caption will be
	// positioned towards the bottom of the output. All burn-in and DVB-Sub font
	// settings must match.
	YPosition *int32
	// Controls whether a fixed grid size will be used to generate the output subtitles
	// bitmap. Only applicable for Teletext inputs and DVB-Sub/Burn-in outputs.
	TeletextGridControl BurnInTeletextGridControl
	// Specifies the color of the rectangle behind the captions. All burn-in and
	// DVB-Sub font settings must match.
	BackgroundColor BurnInBackgroundColor
	// Specifies font outline size in pixels. This option is not valid for source
	// captions that are either 608/embedded or teletext. These source settings are
	// already pre-defined by the caption stream. All burn-in and DVB-Sub font settings
	// must match.
	OutlineSize *int32
	// Specifies the horizontal offset of the shadow relative to the captions in
	// pixels. A value of -2 would result in a shadow offset 2 pixels to the left. All
	// burn-in and DVB-Sub font settings must match.
	ShadowXOffset *int32
	// Specifies the opacity of the burned-in captions. 255 is opaque; 0 is
	// transparent. All burn-in and DVB-Sub font settings must match.
	FontOpacity *int32
	// Specifies font outline color. This option is not valid for source captions that
	// are either 608/embedded or teletext. These source settings are already
	// pre-defined by the caption stream. All burn-in and DVB-Sub font settings must
	// match.
	OutlineColor BurnInOutlineColor
	// Specifies the color of the shadow cast by the captions. All burn-in and DVB-Sub
	// font settings must match.
	ShadowColor BurnInShadowColor
	// Font resolution in DPI (dots per inch); default is 96 dpi. All burn-in and
	// DVB-Sub font settings must match.
	FontResolution *int32
	// Specifies the opacity of the background rectangle. 255 is opaque; 0 is
	// transparent. Leaving this parameter out is equivalent to setting it to 0
	// (transparent). All burn-in and DVB-Sub font settings must match.
	BackgroundOpacity *int32
	// If no explicit xPosition or yPosition is provided, setting alignment to centered
	// will place the captions at the bottom center of the output. Similarly, setting a
	// left alignment will align captions to the bottom left of the output. If x and y
	// positions are given in conjunction with the alignment parameter, the font will
	// be justified (either left or centered) relative to those coordinates. Selecting
	// "smart" justification will left-justify live subtitles and center-justify
	// pre-recorded subtitles. All burn-in and DVB-Sub font settings must match.
	Alignment BurnInAlignment
	// Specifies the color of the burned-in captions. This option is not valid for
	// source captions that are STL, 608/embedded or teletext. These source settings
	// are already pre-defined by the caption stream. All burn-in and DVB-Sub font
	// settings must match.
	FontColor BurnInFontColor
	// Specifies the opacity of the shadow. 255 is opaque; 0 is transparent. Leaving
	// this parameter out is equivalent to setting it to 0 (transparent). All burn-in
	// and DVB-Sub font settings must match.
	ShadowOpacity *int32
}

// Caption Description
type CaptionDescription struct {
	// Additional settings for captions destination that depend on the destination
	// type.
	DestinationSettings *CaptionDestinationSettings
	// ISO 639-2 three-digit code: http://www.loc.gov/standards/iso639-2/
	LanguageCode *string
	// Human readable information to indicate captions available for players (eg.
	// English, or Spanish).
	LanguageDescription *string
	// Name of the caption description. Used to associate a caption description with an
	// output. Names must be unique within an event.
	Name *string
	// Specifies which input caption selector to use as a caption source when
	// generating output captions. This field should match a captionSelector name.
	CaptionSelectorName *string
}

// Caption Destination Settings
type CaptionDestinationSettings struct {
	// Smpte Tt Destination Settings
	SmpteTtDestinationSettings *SmpteTtDestinationSettings
	// Embedded Plus Scte20 Destination Settings
	EmbeddedPlusScte20DestinationSettings *EmbeddedPlusScte20DestinationSettings
	// Arib Destination Settings
	AribDestinationSettings *AribDestinationSettings
	// Ebu Tt DDestination Settings
	EbuTtDDestinationSettings *EbuTtDDestinationSettings
	// Ttml Destination Settings
	TtmlDestinationSettings *TtmlDestinationSettings
	// Scte20 Plus Embedded Destination Settings
	Scte20PlusEmbeddedDestinationSettings *Scte20PlusEmbeddedDestinationSettings
	// Dvb Sub Destination Settings
	DvbSubDestinationSettings *DvbSubDestinationSettings
	// Webvtt Destination Settings
	WebvttDestinationSettings *WebvttDestinationSettings
	// Teletext Destination Settings
	TeletextDestinationSettings *TeletextDestinationSettings
	// Burn In Destination Settings
	BurnInDestinationSettings *BurnInDestinationSettings
	// Scte27 Destination Settings
	Scte27DestinationSettings *Scte27DestinationSettings
	// Embedded Destination Settings
	EmbeddedDestinationSettings *EmbeddedDestinationSettings
	// Rtmp Caption Info Destination Settings
	RtmpCaptionInfoDestinationSettings *RtmpCaptionInfoDestinationSettings
}

// Maps a caption channel to an ISO 693-2 language code
// (http://www.loc.gov/standards/iso639-2), with an optional description.
type CaptionLanguageMapping struct {
	// Three character ISO 639-2 language code (see
	// http://www.loc.gov/standards/iso639-2)
	LanguageCode *string
	// Textual description of language
	LanguageDescription *string
	// The closed caption channel being described by this CaptionLanguageMapping. Each
	// channel mapping must have a unique channel number (maximum of 4)
	CaptionChannel *int32
}

// Output groups for this Live Event. Output groups contain information about where
// streams should be distributed.
type CaptionSelector struct {
	// Caption selector settings.
	SelectorSettings *CaptionSelectorSettings
	// When specified this field indicates the three letter language code of the
	// caption track to extract from the source.
	LanguageCode *string
	// Name identifier for a caption selector. This name is used to associate this
	// caption selector with one or more caption descriptions. Names must be unique
	// within an event.
	Name *string
}

// Caption Selector Settings
type CaptionSelectorSettings struct {
	// Scte27 Source Settings
	Scte27SourceSettings *Scte27SourceSettings
	// Dvb Sub Source Settings
	DvbSubSourceSettings *DvbSubSourceSettings
	// Arib Source Settings
	AribSourceSettings *AribSourceSettings
	// Scte20 Source Settings
	Scte20SourceSettings *Scte20SourceSettings
	// Embedded Source Settings
	EmbeddedSourceSettings *EmbeddedSourceSettings
	// Teletext Source Settings
	TeletextSourceSettings *TeletextSourceSettings
}

// Placeholder documentation for Channel
type Channel struct {
	// Placeholder documentation for InputSpecification
	InputSpecification *InputSpecification
	// The Amazon Resource Name (ARN) of the role assumed when running the Channel.
	RoleArn *string
	// The unique id of the channel.
	Id *string
	// List of input attachments for channel.
	InputAttachments []*InputAttachment
	// The unique arn of the channel.
	Arn *string
	// The number of currently healthy pipelines.
	PipelinesRunningCount *int32
	// Runtime details for the pipelines of a running channel.
	PipelineDetails []*PipelineDetail
	// Encoder Settings
	EncoderSettings *EncoderSettings
	// The class for this channel. STANDARD for a channel with two pipelines or
	// SINGLE_PIPELINE for a channel with one pipeline.
	ChannelClass ChannelClass
	// The endpoints where outgoing connections initiate from
	EgressEndpoints []*ChannelEgressEndpoint
	// A collection of key-value pairs.
	Tags map[string]*string
	// The log level being written to CloudWatch Logs.
	LogLevel LogLevel
	// The name of the channel. (user-mutable)
	Name *string
	// A list of destinations of the channel. For UDP outputs, there is one destination
	// per output. For other types (HLS, for example), there is one destination per
	// packager.
	Destinations []*OutputDestination
	// Placeholder documentation for ChannelState
	State ChannelState
}

// Placeholder documentation for ChannelEgressEndpoint
type ChannelEgressEndpoint struct {
	// Public IP of where a channel's output comes from
	SourceIp *string
}

// Placeholder documentation for ChannelSummary
type ChannelSummary struct {
	// A list of destinations of the channel. For UDP outputs, there is one destination
	// per output. For other types (HLS, for example), there is one destination per
	// packager.
	Destinations []*OutputDestination
	// List of input attachments for channel.
	InputAttachments []*InputAttachment
	// Placeholder documentation for InputSpecification
	InputSpecification *InputSpecification
	// The Amazon Resource Name (ARN) of the role assumed when running the Channel.
	RoleArn *string
	// The log level being written to CloudWatch Logs.
	LogLevel LogLevel
	// Placeholder documentation for ChannelState
	State ChannelState
	// The name of the channel. (user-mutable)
	Name *string
	// A collection of key-value pairs.
	Tags map[string]*string
	// The endpoints where outgoing connections initiate from
	EgressEndpoints []*ChannelEgressEndpoint
	// The unique id of the channel.
	Id *string
	// The unique arn of the channel.
	Arn *string
	// The class for this channel. STANDARD for a channel with two pipelines or
	// SINGLE_PIPELINE for a channel with one pipeline.
	ChannelClass ChannelClass
	// The number of currently healthy pipelines.
	PipelinesRunningCount *int32
}

// Passthrough applies no color space conversion to the output
type ColorSpacePassthroughSettings struct {
}

// DVB Network Information Table (NIT)
type DvbNitSettings struct {
	// The network name text placed in the networkNameDescriptor inside the Network
	// Information Table. Maximum length is 256 characters.
	NetworkName *string
	// The number of milliseconds between instances of this table in the output
	// transport stream.
	RepInterval *int32
	// The numeric value placed in the Network Information Table (NIT).
	NetworkId *int32
}

// DVB Service Description Table (SDT)
type DvbSdtSettings struct {
	// Selects method of inserting SDT information into output stream. The sdtFollow
	// setting copies SDT information from input stream to output stream. The
	// sdtFollowIfPresent setting copies SDT information from input stream to output
	// stream if SDT information is present in the input, otherwise it will fall back
	// on the user-defined values. The sdtManual setting means user will enter the SDT
	// information. The sdtNone setting means output stream will not contain SDT
	// information.
	OutputSdt DvbSdtOutputSdt
	// The service provider name placed in the serviceDescriptor in the Service
	// Description Table. Maximum length is 256 characters.
	ServiceProviderName *string
	// The service name placed in the serviceDescriptor in the Service Description
	// Table. Maximum length is 256 characters.
	ServiceName *string
	// The number of milliseconds between instances of this table in the output
	// transport stream.
	RepInterval *int32
}

// Dvb Sub Destination Settings
type DvbSubDestinationSettings struct {
	// Specifies the horizontal position of the caption relative to the left side of
	// the output in pixels. A value of 10 would result in the captions starting 10
	// pixels from the left of the output. If no explicit xPosition is provided, the
	// horizontal caption position will be determined by the alignment parameter. This
	// option is not valid for source captions that are STL, 608/embedded or teletext.
	// These source settings are already pre-defined by the caption stream. All burn-in
	// and DVB-Sub font settings must match.
	XPosition *int32
	// When set to auto fontSize will scale depending on the size of the output. Giving
	// a positive integer will specify the exact font size in points. All burn-in and
	// DVB-Sub font settings must match.
	FontSize *string
	// External font file used for caption burn-in. File extension must be 'ttf' or
	// 'tte'. Although the user can select output fonts for many different types of
	// input captions, embedded, STL and teletext sources use a strict grid system.
	// Using external fonts with these caption sources could cause unexpected display
	// of proportional fonts. All burn-in and DVB-Sub font settings must match.
	Font *InputLocation
	// Specifies the color of the rectangle behind the captions. All burn-in and
	// DVB-Sub font settings must match.
	BackgroundColor DvbSubDestinationBackgroundColor
	// If no explicit xPosition or yPosition is provided, setting alignment to centered
	// will place the captions at the bottom center of the output. Similarly, setting a
	// left alignment will align captions to the bottom left of the output. If x and y
	// positions are given in conjunction with the alignment parameter, the font will
	// be justified (either left or centered) relative to those coordinates. Selecting
	// "smart" justification will left-justify live subtitles and center-justify
	// pre-recorded subtitles. This option is not valid for source captions that are
	// STL or 608/embedded. These source settings are already pre-defined by the
	// caption stream. All burn-in and DVB-Sub font settings must match.
	Alignment DvbSubDestinationAlignment
	// Specifies the horizontal offset of the shadow relative to the captions in
	// pixels. A value of -2 would result in a shadow offset 2 pixels to the left. All
	// burn-in and DVB-Sub font settings must match.
	ShadowXOffset *int32
	// Specifies font outline size in pixels. This option is not valid for source
	// captions that are either 608/embedded or teletext. These source settings are
	// already pre-defined by the caption stream. All burn-in and DVB-Sub font settings
	// must match.
	OutlineSize *int32
	// Specifies the opacity of the background rectangle. 255 is opaque; 0 is
	// transparent. Leaving this parameter blank is equivalent to setting it to 0
	// (transparent). All burn-in and DVB-Sub font settings must match.
	BackgroundOpacity *int32
	// Controls whether a fixed grid size will be used to generate the output subtitles
	// bitmap. Only applicable for Teletext inputs and DVB-Sub/Burn-in outputs.
	TeletextGridControl DvbSubDestinationTeletextGridControl
	// Specifies the vertical position of the caption relative to the top of the output
	// in pixels. A value of 10 would result in the captions starting 10 pixels from
	// the top of the output. If no explicit yPosition is provided, the caption will be
	// positioned towards the bottom of the output. This option is not valid for source
	// captions that are STL, 608/embedded or teletext. These source settings are
	// already pre-defined by the caption stream. All burn-in and DVB-Sub font settings
	// must match.
	YPosition *int32
	// Font resolution in DPI (dots per inch); default is 96 dpi. All burn-in and
	// DVB-Sub font settings must match.
	FontResolution *int32
	// Specifies font outline color. This option is not valid for source captions that
	// are either 608/embedded or teletext. These source settings are already
	// pre-defined by the caption stream. All burn-in and DVB-Sub font settings must
	// match.
	OutlineColor DvbSubDestinationOutlineColor
	// Specifies the opacity of the burned-in captions. 255 is opaque; 0 is
	// transparent. All burn-in and DVB-Sub font settings must match.
	FontOpacity *int32
	// Specifies the color of the burned-in captions. This option is not valid for
	// source captions that are STL, 608/embedded or teletext. These source settings
	// are already pre-defined by the caption stream. All burn-in and DVB-Sub font
	// settings must match.
	FontColor DvbSubDestinationFontColor
	// Specifies the opacity of the shadow. 255 is opaque; 0 is transparent. Leaving
	// this parameter blank is equivalent to setting it to 0 (transparent). All burn-in
	// and DVB-Sub font settings must match.
	ShadowOpacity *int32
	// Specifies the vertical offset of the shadow relative to the captions in pixels.
	// A value of -2 would result in a shadow offset 2 pixels above the text. All
	// burn-in and DVB-Sub font settings must match.
	ShadowYOffset *int32
	// Specifies the color of the shadow cast by the captions. All burn-in and DVB-Sub
	// font settings must match.
	ShadowColor DvbSubDestinationShadowColor
}

// Dvb Sub Source Settings
type DvbSubSourceSettings struct {
	// When using DVB-Sub with Burn-In or SMPTE-TT, use this PID for the source
	// content. Unused for DVB-Sub passthrough. All DVB-Sub content is passed through,
	// regardless of selectors.
	Pid *int32
}

// DVB Time and Date Table (SDT)
type DvbTdtSettings struct {
	// The number of milliseconds between instances of this table in the output
	// transport stream.
	RepInterval *int32
}

// Eac3 Settings
type Eac3Settings struct {
	// When set to enabled, activates a DC highpass filter for all input channels.
	DcFilter Eac3DcFilter
	// Left only/Right only center mix level. Only used for 3/2 coding mode.
	LoRoCenterMixLevel *float64
	// Left total/Right total surround mix level. Only used for 3/2 coding mode.
	LtRtSurroundMixLevel *float64
	// When encoding 3/2 audio, sets whether an extra center back surround channel is
	// matrix encoded into the left and right surround channels.
	SurroundExMode Eac3SurroundExMode
	// When set to whenPossible, input DD+ audio will be passed through if it is
	// present on the input. This detection is dynamic over the life of the transcode.
	// Inputs that alternate between DD+ and non-DD+ content will have a consistent DD+
	// output as the system alternates between passthrough and encoding.
	PassthroughControl Eac3PassthroughControl
	// Specifies the bitstream mode (bsmod) for the emitted E-AC-3 stream. See ATSC
	// A/52-2012 (Annex E) for background on these values.
	BitstreamMode Eac3BitstreamMode
	// Sets the profile for heavy Dolby dynamic range compression, ensures that the
	// instantaneous signal peaks do not exceed specified levels.
	DrcRf Eac3DrcRf
	// When set to attenuate3Db, applies a 3 dB attenuation to the surround channels.
	// Only used for 3/2 coding mode.
	AttenuationControl Eac3AttenuationControl
	// Dolby Digital Plus coding mode. Determines number of channels.
	CodingMode Eac3CodingMode
	// Sets the Dolby dynamic range compression profile.
	DrcLine Eac3DrcLine
	// Sets the dialnorm for the output. If blank and input audio is Dolby Digital
	// Plus, dialnorm will be passed through.
	Dialnorm *int32
	// When set to shift90Degrees, applies a 90-degree phase shift to the surround
	// channels. Only used for 3/2 coding mode.
	PhaseControl Eac3PhaseControl
	// Stereo downmix preference. Only used for 3/2 coding mode.
	StereoDownmix Eac3StereoDownmix
	// When encoding 2/0 audio, sets whether Dolby Surround is matrix encoded into the
	// two channels.
	SurroundMode Eac3SurroundMode
	// Left total/Right total center mix level. Only used for 3/2 coding mode.
	LtRtCenterMixLevel *float64
	// When set to enabled, applies a 120Hz lowpass filter to the LFE channel prior to
	// encoding. Only valid with codingMode32 coding mode.
	LfeFilter Eac3LfeFilter
	// Left only/Right only surround mix level. Only used for 3/2 coding mode.
	LoRoSurroundMixLevel *float64
	// Average bitrate in bits/second. Valid bitrates depend on the coding mode.
	Bitrate *float64
	// When set to followInput, encoder metadata will be sourced from the DD, DD+, or
	// DolbyE decoder that supplied this audio data. If audio was not supplied from one
	// of these streams, then the static metadata settings will be used.
	MetadataControl Eac3MetadataControl
	// When encoding 3/2 audio, setting to lfe enables the LFE channel
	LfeControl Eac3LfeControl
}

// Ebu Tt DDestination Settings
type EbuTtDDestinationSettings struct {
	// Specifies the font family to include in the font data attached to the EBU-TT
	// captions. Valid only if styleControl is set to include. If you leave this field
	// empty, the font family is set to "monospaced". (If styleControl is set to
	// exclude, the font family is always set to "monospaced".) You specify only the
	// font family. All other style information (color, bold, position and so on) is
	// copied from the input captions. The size is always set to 100% to allow the
	// downstream player to choose the size.
	//
	//     * Enter a list of font families, as a
	// comma-separated list of font names, in order of preference. The name can be a
	// font family (such as “Arial”), or a generic font family (such as “serif”), or
	// “default” (to let the downstream player choose the font).
	//
	//     * Leave blank to
	// set the family to “monospace”.
	FontFamily *string
	// Specifies how to handle the gap between the lines (in multi-line captions).
	//
	//
	// * enabled: Fill with the captions background color (as specified in the input
	// captions).
	//
	//     * disabled: Leave the gap unfilled.
	FillLineGap EbuTtDFillLineGapControl
	// Specifies the style information (font color, font position, and so on) to
	// include in the font data that is attached to the EBU-TT captions.
	//
	//     *
	// include: Take the style information (font color, font position, and so on) from
	// the source captions and include that information in the font data attached to
	// the EBU-TT captions. This option is valid only if the source captions are
	// Embedded or Teletext.
	//
	//     * exclude: In the font data attached to the EBU-TT
	// captions, set the font family to "monospaced". Do not include any other style
	// information.
	StyleControl EbuTtDDestinationStyleControl
}

// Embedded Destination Settings
type EmbeddedDestinationSettings struct {
}

// Embedded Plus Scte20 Destination Settings
type EmbeddedPlusScte20DestinationSettings struct {
}

// Embedded Source Settings
type EmbeddedSourceSettings struct {
	// Specifies the 608/708 channel number within the video track from which to
	// extract captions. Unused for passthrough.
	Source608ChannelNumber *int32
	// Set to "auto" to handle streams with intermittent and/or non-aligned SCTE-20 and
	// Embedded captions.
	Scte20Detection EmbeddedScte20Detection
	// If upconvert, 608 data is both passed through via the "608 compatibility bytes"
	// fields of the 708 wrapper as well as translated into 708. 708 data present in
	// the source content will be discarded.
	Convert608To708 EmbeddedConvert608To708
	// This field is unused and deprecated.
	Source608TrackNumber *int32
}

// Encoder Settings
type EncoderSettings struct {
	// Placeholder documentation for __listOfAudioDescription
	AudioDescriptions []*AudioDescription
	// Nielsen configuration settings.
	NielsenConfiguration *NielsenConfiguration
	// Configuration settings that apply to the event as a whole.
	GlobalConfiguration *GlobalConfiguration
	// Placeholder documentation for __listOfVideoDescription
	VideoDescriptions []*VideoDescription
	// Event-wide configuration settings for ad avail insertion.
	AvailConfiguration *AvailConfiguration
	// Placeholder documentation for __listOfOutputGroup
	OutputGroups []*OutputGroup
	// Settings for caption decriptions
	CaptionDescriptions []*CaptionDescription
	// Feature Activations
	FeatureActivations *FeatureActivations
	// Contains settings used to acquire and adjust timecode information from inputs.
	TimecodeConfig *TimecodeConfig
	// Settings for ad avail blanking.
	AvailBlanking *AvailBlanking
	// Settings for blackout slate.
	BlackoutSlate *BlackoutSlate
}

// Feature Activations
type FeatureActivations struct {
	// Enables the Input Prepare feature. You can create Input Prepare actions in the
	// schedule only if this feature is enabled. If you disable the feature on an
	// existing schedule, make sure that you first delete all input prepare actions
	// from the schedule.
	InputPrepareScheduleActions FeatureActivationsInputPrepareScheduleActions
}

// Fec Output Settings
type FecOutputSettings struct {
	// Parameter D from SMPTE 2022-1. The height of the FEC protection matrix. The
	// number of transport stream packets per column error correction packet. Must be
	// between 4 and 20, inclusive.
	ColumnDepth *int32
	// Parameter L from SMPTE 2022-1. The width of the FEC protection matrix. Must be
	// between 1 and 20, inclusive. If only Column FEC is used, then larger values
	// increase robustness. If Row FEC is used, then this is the number of transport
	// stream packets per row error correction packet, and the value must be between 4
	// and 20, inclusive, if includeFec is columnAndRow. If includeFec is column, this
	// value must be 1 to 20, inclusive.
	RowLength *int32
	// Enables column only or column and row based FEC
	IncludeFec FecOutputIncludeFec
}

// Start time for the action.
type FixedModeScheduleActionStartSettings struct {
	// Start time for the action to start in the channel. (Not the time for the action
	// to be added to the schedule: actions are always added to the schedule
	// immediately.) UTC format: yyyy-mm-ddThh:mm:ss.nnnZ. All the letters are digits
	// (for example, mm might be 01) except for the two constants "T" for time and "Z"
	// for "UTC format".
	Time *string
}

// Fmp4 Hls Settings
type Fmp4HlsSettings struct {
	// If set to passthrough, Nielsen inaudible tones for media tracking will be
	// detected in the input audio and an equivalent ID3 tag will be inserted in the
	// output.
	NielsenId3Behavior Fmp4NielsenId3Behavior
	// List all the audio groups that are used with the video output stream. Input all
	// the audio GROUP-IDs that are associated to the video, separate by ','.
	AudioRenditionSets *string
	// When set to passthrough, timed metadata is passed through from input to output.
	TimedMetadataBehavior Fmp4TimedMetadataBehavior
}

// Settings to specify if an action follows another.
type FollowModeScheduleActionStartSettings struct {
	// The action name of another action that this one refers to.
	ReferenceActionName *string
	// Identifies whether this action starts relative to the start or relative to the
	// end of the reference action.
	FollowPoint FollowPoint
}

// Frame Capture Group Settings
type FrameCaptureGroupSettings struct {
	// The destination for the frame capture files. Either the URI for an Amazon S3
	// bucket and object, plus a file name prefix (for example,
	// s3ssl://sportsDelivery/highlights/20180820/curling_) or the URI for a MediaStore
	// container, plus a file name prefix (for example,
	// mediastoressl://sportsDelivery/20180820/curling_). The final file names consist
	// of the prefix from the destination field (for example, "curling_") + name
	// modifier + the counter (5 digits, starting from 00001) + extension (which is
	// always .jpg). For example, curlingLow.00001.jpg
	Destination *OutputLocationRef
}

// Frame Capture Output Settings
type FrameCaptureOutputSettings struct {
	// Required if the output group contains more than one output. This modifier forms
	// part of the output file name.
	NameModifier *string
}

// Frame Capture Settings
type FrameCaptureSettings struct {
	// Unit for the frame capture interval.
	CaptureIntervalUnits FrameCaptureIntervalUnit
	// The frequency at which to capture frames for inclusion in the output. May be
	// specified in either seconds or milliseconds, as specified by
	// captureIntervalUnits.
	CaptureInterval *int32
}

// Global Configuration
type GlobalConfiguration struct {
	// Indicates whether the rate of frames emitted by the Live encoder should be paced
	// by its system clock (which optionally may be locked to another source via NTP)
	// or should be locked to the clock of the source that is providing the input
	// stream.
	OutputTimingSource GlobalConfigurationOutputTimingSource
	// Adjusts video input buffer for streams with very low video framerates. This is
	// commonly set to enabled for music channels with less than one video frame per
	// second.
	SupportLowFramerateInputs GlobalConfigurationLowFramerateInputs
	// Value to set the initial audio gain for the Live Event.
	InitialAudioGain *int32
	// Indicates how MediaLive pipelines are synchronized. PIPELINE_LOCKING - MediaLive
	// will attempt to synchronize the output of each pipeline to the other.
	// EPOCH_LOCKING - MediaLive will attempt to synchronize the output of each
	// pipeline to the Unix epoch.
	OutputLockingMode GlobalConfigurationOutputLockingMode
	// Settings for system actions when input is lost.
	InputLossBehavior *InputLossBehavior
	// Indicates the action to take when the current input completes (e.g.
	// end-of-file). When switchAndLoopInputs is configured the encoder will restart at
	// the beginning of the first input. When "none" is configured the encoder will
	// transcode either black, a solid color, or a user specified slate images per the
	// "Input Loss Behavior" configuration until the next input switch occurs (which is
	// controlled through the Channel Schedule API).
	InputEndAction GlobalConfigurationInputEndAction
}

// H264 Color Space Settings
type H264ColorSpaceSettings struct {
	// Rec601 Settings
	Rec601Settings *Rec601Settings
	// Rec709 Settings
	Rec709Settings *Rec709Settings
	// Passthrough applies no color space conversion to the output
	ColorSpacePassthroughSettings *ColorSpacePassthroughSettings
}

// H264 Filter Settings
type H264FilterSettings struct {
	// Temporal Filter Settings
	TemporalFilterSettings *TemporalFilterSettings
}

// H264 Settings
type H264Settings struct {
	// Color Space settings
	ColorSpaceSettings *H264ColorSpaceSettings
	// Softness. Selects quantizer matrix, larger values reduce high-frequency content
	// in the encoded image.
	Softness *int32
	// Documentation update needed
	GopBReference H264GopBReference
	// Pixel Aspect Ratio denominator.
	ParDenominator *int32
	// Average bitrate in bits/second. Required when the rate control mode is VBR or
	// CBR. Not used for QVBR. In an MS Smooth output group, each output must have a
	// unique value when its bitrate is rounded down to the nearest multiple of 1000.
	Bitrate *int32
	// If set to enabled, adjust quantization within each frame based on spatial
	// variation of content complexity.
	SpatialAq H264SpatialAq
	// Entropy encoding mode. Use cabac (must be in Main or High profile) or cavlc.
	EntropyEncoding H264EntropyEncoding
	// Indicates if the gopSize is specified in frames or seconds. If seconds the
	// system will convert the gopSize into a frame count at run time.
	GopSizeUnits H264GopSizeUnits
	// Four bit AFD value to write on all frames of video in the output stream. Only
	// valid when afdSignaling is set to 'Fixed'.
	FixedAfd FixedAfd
	// Indicates that AFD values will be written into the output stream. If
	// afdSignaling is "auto", the system will try to preserve the input AFD value (in
	// cases where multiple AFD values are valid). If set to "fixed", the AFD value
	// will be the value configured in the fixedAfd parameter.
	AfdSignaling AfdSignaling
	// GOP size (keyframe interval) in units of either frames or seconds per
	// gopSizeUnits. If gopSizeUnits is frames, gopSize must be an integer and must be
	// greater than or equal to 1. If gopSizeUnits is seconds, gopSize must be greater
	// than 0, but need not be an integer.
	GopSize *float64
	// Scene change detection.
	//
	//     * On: inserts I-frames when scene change is
	// detected.
	//
	//     * Off: does not force an I-frame when scene change is detected.
	SceneChangeDetect H264SceneChangeDetect
	// This setting applies only when scan type is "interlaced." It controls whether
	// coding is performed on a field basis or on a frame basis. (When the video is
	// progressive, the coding is always performed on a frame basis.) enabled: Force
	// MediaLive to code on a field basis, so that odd and even sets of fields are
	// coded separately. disabled: Code the two sets of fields separately (on a field
	// basis) or together (on a frame basis using PAFF), depending on what is most
	// appropriate for the content.
	ForceFieldPictures H264ForceFieldPictures
	// Only meaningful if sceneChangeDetect is set to enabled. Defaults to 5 if
	// multiplex rate control is used. Enforces separation between repeated (cadence)
	// I-frames and I-frames inserted by Scene Change Detection. If a scene change
	// I-frame is within I-interval frames of a cadence I-frame, the GOP is shrunk
	// and/or stretched to the scene change I-frame. GOP stretch requires enabling
	// lookahead as well as setting I-interval. The normal cadence resumes for the next
	// GOP. Note: Maximum GOP stretch = GOP size + Min-I-interval - 1
	MinIInterval *int32
	// Leave as STANDARD_QUALITY or choose a different value (which might result in
	// additional costs to run the channel).
	//
	//     * ENHANCED_QUALITY: Produces a
	// slightly better video quality without an increase in the bitrate. Has an effect
	// only when the Rate control mode is QVBR or CBR. If this channel is in a
	// MediaLive multiplex, the value must be ENHANCED_QUALITY.
	//
	//     *
	// STANDARD_QUALITY: Valid for any Rate control mode.
	QualityLevel H264QualityLevel
	// Framerate denominator.
	FramerateDenominator *int32
	// This field indicates how the output video frame rate is specified. If
	// "specified" is selected then the output video frame rate is determined by
	// framerateNumerator and framerateDenominator, else if "initializeFromSource" is
	// selected then the output video frame rate will be set equal to the input video
	// frame rate of the first input.
	FramerateControl H264FramerateControl
	// Adaptive quantization. Allows intra-frame quantizers to vary to improve visual
	// quality.
	AdaptiveQuantization H264AdaptiveQuantization
	// Optional filters that you can apply to an encode.
	FilterSettings *H264FilterSettings
	// Number of reference frames to use. The encoder may use more than requested if
	// using B-frames and/or interlaced encoding.
	NumRefFrames *int32
	// Produces a bitstream compliant with SMPTE RP-2027.
	Syntax H264Syntax
	// H.264 Level.
	Level H264Level
	// This field indicates how the output pixel aspect ratio is specified. If
	// "specified" is selected then the output video pixel aspect ratio is determined
	// by parNumerator and parDenominator, else if "initializeFromSource" is selected
	// then the output pixsel aspect ratio will be set equal to the input video pixel
	// aspect ratio of the first input.
	ParControl H264ParControl
	// If set to enabled, adjust quantization within each frame based on temporal
	// variation of content complexity.
	TemporalAq H264TemporalAq
	// Frequency of closed GOPs. In streaming applications, it is recommended that this
	// be set to 1 so a decoder joining mid-stream will receive an IDR frame as quickly
	// as possible. Setting this value to 0 will break output segmenting.
	GopClosedCadence *int32
	// Framerate numerator - framerate is a fraction, e.g. 24000 / 1001 = 23.976 fps.
	FramerateNumerator *int32
	// If set to enabled, adjust quantization within each frame to reduce flicker or
	// 'pop' on I-frames.
	FlickerAq H264FlickerAq
	// H.264 Profile.
	Profile H264Profile
	// Rate control mode. QVBR: Quality will match the specified quality level except
	// when it is constrained by the maximum bitrate. Recommended if you or your
	// viewers pay for bandwidth. VBR: Quality and bitrate vary, depending on the video
	// complexity. Recommended instead of QVBR if you want to maintain a specific
	// average bitrate over the duration of the channel. CBR: Quality varies, depending
	// on the video complexity. Recommended only if you distribute your assets to
	// devices that cannot handle variable bitrates. Multiplex: This rate control mode
	// is only supported (and is required) when the video is being delivered to a
	// MediaLive Multiplex in which case the rate control configuration is controlled
	// by the properties within the Multiplex Program.
	RateControlMode H264RateControlMode
	// For QVBR: See the tooltip for Quality level For VBR: Set the maximum bitrate in
	// order to accommodate expected spikes in the complexity of the video.
	MaxBitrate *int32
	// Includes colorspace metadata in the output.
	ColorMetadata H264ColorMetadata
	// Controls the target quality for the video encode. Applies only when the rate
	// control mode is QVBR. Set values for the QVBR quality level field and Max
	// bitrate field that suit your most important viewing devices. Recommended values
	// are:
	//
	//     * Primary screen: Quality level: 8 to 10. Max bitrate: 4M
	//
	//     * PC or
	// tablet: Quality level: 7. Max bitrate: 1.5M to 3M
	//
	//     * Smartphone: Quality
	// level: 6. Max bitrate: 1M to 1.5M
	QvbrQualityLevel *int32
	// If set to fixed, use gopNumBFrames B-frames per sub-GOP. If set to dynamic,
	// optimize the number of B-frames used for each sub-GOP to improve visual quality.
	SubgopLength H264SubGopLength
	// Number of slices per picture. Must be less than or equal to the number of
	// macroblock rows for progressive pictures, and less than or equal to half the
	// number of macroblock rows for interlaced pictures. This field is optional; when
	// no value is specified the encoder will choose the number of slices based on
	// encode resolution.
	Slices *int32
	// Amount of lookahead. A value of low can decrease latency and memory usage, while
	// high can produce better quality for certain content.
	LookAheadRateControl H264LookAheadRateControl
	// Size of buffer (HRD buffer model) in bits.
	BufSize *int32
	// Determines how timecodes should be inserted into the video elementary stream.
	//
	//
	// * 'disabled': Do not include timecodes
	//
	//     * 'picTimingSei': Pass through
	// picture timing SEI messages from the source specified in Timecode Config
	TimecodeInsertion H264TimecodeInsertionBehavior
	// Sets the scan type of the output to progressive or top-field-first interlaced.
	ScanType H264ScanType
	// Percentage of the buffer that should initially be filled (HRD buffer model).
	BufFillPct *int32
	// Pixel Aspect Ratio numerator.
	ParNumerator *int32
	// Number of B-frames between reference frames.
	GopNumBFrames *int32
}

// H265 Color Space Settings
type H265ColorSpaceSettings struct {
	// Hdr10 Settings
	Hdr10Settings *Hdr10Settings
	// Rec601 Settings
	Rec601Settings *Rec601Settings
	// Rec709 Settings
	Rec709Settings *Rec709Settings
	// Passthrough applies no color space conversion to the output
	ColorSpacePassthroughSettings *ColorSpacePassthroughSettings
}

// H265 Filter Settings
type H265FilterSettings struct {
	// Temporal Filter Settings
	TemporalFilterSettings *TemporalFilterSettings
}

// H265 Settings
type H265Settings struct {
	// Whether or not EML should insert an Alternative Transfer Function SEI message to
	// support backwards compatibility with non-HDR decoders and displays.
	AlternativeTransferFunction H265AlternativeTransferFunction
	// Pixel Aspect Ratio denominator.
	ParDenominator *int32
	// Color Space settings
	ColorSpaceSettings *H265ColorSpaceSettings
	// H.265 Tier.
	Tier H265Tier
	// For QVBR: See the tooltip for Quality level
	MaxBitrate *int32
	// Indicates that AFD values will be written into the output stream. If
	// afdSignaling is "auto", the system will try to preserve the input AFD value (in
	// cases where multiple AFD values are valid). If set to "fixed", the AFD value
	// will be the value configured in the fixedAfd parameter.
	AfdSignaling AfdSignaling
	// Four bit AFD value to write on all frames of video in the output stream. Only
	// valid when afdSignaling is set to 'Fixed'.
	FixedAfd FixedAfd
	// Indicates if the gopSize is specified in frames or seconds. If seconds the
	// system will convert the gopSize into a frame count at run time.
	GopSizeUnits H265GopSizeUnits
	// Size of buffer (HRD buffer model) in bits.
	BufSize *int32
	// Includes colorspace metadata in the output.
	ColorMetadata H265ColorMetadata
	// Pixel Aspect Ratio numerator.
	ParNumerator *int32
	// Sets the scan type of the output to progressive or top-field-first interlaced.
	ScanType H265ScanType
	// Determines how timecodes should be inserted into the video elementary stream.
	//
	//
	// * 'disabled': Do not include timecodes
	//
	//     * 'picTimingSei': Pass through
	// picture timing SEI messages from the source specified in Timecode Config
	TimecodeInsertion H265TimecodeInsertionBehavior
	// H.265 Level.
	Level H265Level
	// Number of slices per picture. Must be less than or equal to the number of
	// macroblock rows for progressive pictures, and less than or equal to half the
	// number of macroblock rows for interlaced pictures. This field is optional; when
	// no value is specified the encoder will choose the number of slices based on
	// encode resolution.
	Slices *int32
	// Controls the target quality for the video encode. Applies only when the rate
	// control mode is QVBR. Set values for the QVBR quality level field and Max
	// bitrate field that suit your most important viewing devices. Recommended values
	// are:
	//
	//     * Primary screen: Quality level: 8 to 10. Max bitrate: 4M
	//
	//     * PC or
	// tablet: Quality level: 7. Max bitrate: 1.5M to 3M
	//
	//     * Smartphone: Quality
	// level: 6. Max bitrate: 1M to 1.5M
	QvbrQualityLevel *int32
	// Amount of lookahead. A value of low can decrease latency and memory usage, while
	// high can produce better quality for certain content.
	LookAheadRateControl H265LookAheadRateControl
	// If set to enabled, adjust quantization within each frame to reduce flicker or
	// 'pop' on I-frames.
	FlickerAq H265FlickerAq
	// Framerate numerator - framerate is a fraction, e.g. 24000 / 1001 = 23.976 fps.
	FramerateNumerator *int32
	// H.265 Profile.
	Profile H265Profile
	// Average bitrate in bits/second. Required when the rate control mode is VBR or
	// CBR. Not used for QVBR. In an MS Smooth output group, each output must have a
	// unique value when its bitrate is rounded down to the nearest multiple of 1000.
	Bitrate *int32
	// Adaptive quantization. Allows intra-frame quantizers to vary to improve visual
	// quality.
	AdaptiveQuantization H265AdaptiveQuantization
	// Frequency of closed GOPs. In streaming applications, it is recommended that this
	// be set to 1 so a decoder joining mid-stream will receive an IDR frame as quickly
	// as possible. Setting this value to 0 will break output segmenting.
	GopClosedCadence *int32
	// Rate control mode. QVBR: Quality will match the specified quality level except
	// when it is constrained by the maximum bitrate. Recommended if you or your
	// viewers pay for bandwidth. CBR: Quality varies, depending on the video
	// complexity. Recommended only if you distribute your assets to devices that
	// cannot handle variable bitrates. Multiplex: This rate control mode is only
	// supported (and is required) when the video is being delivered to a MediaLive
	// Multiplex in which case the rate control configuration is controlled by the
	// properties within the Multiplex Program.
	RateControlMode H265RateControlMode
	// Framerate denominator.
	FramerateDenominator *int32
	// Optional filters that you can apply to an encode.
	FilterSettings *H265FilterSettings
	// Scene change detection.
	SceneChangeDetect H265SceneChangeDetect
	// GOP size (keyframe interval) in units of either frames or seconds per
	// gopSizeUnits. If gopSizeUnits is frames, gopSize must be an integer and must be
	// greater than or equal to 1. If gopSizeUnits is seconds, gopSize must be greater
	// than 0, but need not be an integer.
	GopSize *float64
	// Only meaningful if sceneChangeDetect is set to enabled. Defaults to 5 if
	// multiplex rate control is used. Enforces separation between repeated (cadence)
	// I-frames and I-frames inserted by Scene Change Detection. If a scene change
	// I-frame is within I-interval frames of a cadence I-frame, the GOP is shrunk
	// and/or stretched to the scene change I-frame. GOP stretch requires enabling
	// lookahead as well as setting I-interval. The normal cadence resumes for the next
	// GOP. Note: Maximum GOP stretch = GOP size + Min-I-interval - 1
	MinIInterval *int32
}

// Hdr10 Settings
type Hdr10Settings struct {
	// Maximum Content Light Level An integer metadata value defining the maximum light
	// level, in nits, of any single pixel within an encoded HDR video stream or file.
	MaxCll *int32
	// Maximum Frame Average Light Level An integer metadata value defining the maximum
	// average light level, in nits, for any single frame within an encoded HDR video
	// stream or file.
	MaxFall *int32
}

// Hls Akamai Settings
type HlsAkamaiSettings struct {
	// Size in seconds of file cache for streaming outputs.
	FilecacheDuration *int32
	// Token parameter for authenticated akamai. If not specified, gda is used.
	Token *string
	// Salt for authenticated Akamai.
	Salt *string
	// Specify whether or not to use chunked transfer encoding to Akamai. User should
	// contact Akamai to enable this feature.
	HttpTransferMode HlsAkamaiHttpTransferMode
	// Number of seconds to wait before retrying connection to the CDN if the
	// connection is lost.
	ConnectionRetryInterval *int32
	// If a streaming output fails, number of seconds to wait until a restart is
	// initiated. A value of 0 means never restart.
	RestartDelay *int32
	// Number of retry attempts that will be made before the Live Event is put into an
	// error state.
	NumRetries *int32
}

// Hls Basic Put Settings
type HlsBasicPutSettings struct {
	// If a streaming output fails, number of seconds to wait until a restart is
	// initiated. A value of 0 means never restart.
	RestartDelay *int32
	// Number of seconds to wait before retrying connection to the CDN if the
	// connection is lost.
	ConnectionRetryInterval *int32
	// Size in seconds of file cache for streaming outputs.
	FilecacheDuration *int32
	// Number of retry attempts that will be made before the Live Event is put into an
	// error state.
	NumRetries *int32
}

// Hls Cdn Settings
type HlsCdnSettings struct {
	// Hls Akamai Settings
	HlsAkamaiSettings *HlsAkamaiSettings
	// Hls Webdav Settings
	HlsWebdavSettings *HlsWebdavSettings
	// Hls Basic Put Settings
	HlsBasicPutSettings *HlsBasicPutSettings
	// Hls Media Store Settings
	HlsMediaStoreSettings *HlsMediaStoreSettings
}

// Hls Group Settings
type HlsGroupSettings struct {
	// Indicates whether the output manifest should use floating point or integer
	// values for segment duration.
	ManifestDurationFormat HlsManifestDurationFormat
	// Place segments in subdirectories.
	DirectoryStructure HlsDirectoryStructure
	// Timed Metadata interval in seconds.
	TimedMetadataId3Period *int32
	// Applies only if Mode field is LIVE. Specifies the number of media segments (.ts
	// files) to retain in the destination directory.
	KeepSegments *int32
	// When set to gzip, compresses HLS playlist.
	ManifestCompression HlsManifestCompression
	// Length of MPEG-2 Transport Stream segments to create (in seconds). Note that
	// segments will end on the next keyframe after this number of seconds, so actual
	// segment length may be longer.
	SegmentLength *int32
	// The key provider settings.
	KeyProviderSettings *KeyProviderSettings
	// Applies only if Mode field is LIVE. Specifies the maximum number of segments in
	// the media manifest file. After this maximum, older segments are removed from the
	// media manifest. This number must be less than or equal to the Keep Segments
	// field.
	IndexNSegments *int32
	// Mapping of up to 4 caption channels to caption languages. Is only meaningful if
	// captionLanguageSetting is set to "insert".
	CaptionLanguageMappings []*CaptionLanguageMapping
	// SEGMENTED_FILES: Emit the program as segments - multiple .ts media files.
	// SINGLE_FILE: Applies only if Mode field is VOD. Emit the program as a single .ts
	// media file. The media manifest includes #EXT-X-BYTERANGE tags to index segments
	// for playback. A typical use for this value is when sending the output to AWS
	// Elemental MediaConvert, which can accept only a single media file. Playback
	// while the channel is running is not guaranteed due to HTTP server caching.
	TsFileMode HlsTsFileMode
	// For use with encryptionType. The IV (Initialization Vector) is a 128-bit number
	// used in conjunction with the key for encrypting blocks. If this setting is
	// "followsSegmentNumber", it will cause the IV to change every segment (to match
	// the segment number). If this is set to "explicit", you must enter a constantIv
	// value.
	IvSource HlsIvSource
	// Optional. One value per output group. This field is required only if you are
	// completing Base URL content A, and the downstream system has notified you that
	// the media files for pipeline 1 of all outputs are in a location different from
	// the media files for pipeline 0.
	BaseUrlContent1 *string
	// useInputSegmentation has been deprecated. The configured segment size is always
	// used.
	SegmentationMode HlsSegmentationMode
	// The value specifies how the key is represented in the resource identified by the
	// URI. If parameter is absent, an implicit value of "identity" is used. A reverse
	// DNS string can also be given.
	KeyFormat *string
	// Includes or excludes EXT-X-PROGRAM-DATE-TIME tag in .m3u8 manifest files. The
	// value is calculated as follows: either the program date and time are initialized
	// using the input timecode source, or the time is initialized using the input
	// timecode source and the date is initialized using the timestampOffset.
	ProgramDateTime HlsProgramDateTime
	// A partial URI prefix that will be prepended to each output in the media .m3u8
	// file. Can be used if base manifest is delivered from a different URL than the
	// main .m3u8 file.
	BaseUrlManifest *string
	// Choose one or more ad marker types to pass SCTE35 signals through to this group
	// of Apple HLS outputs.
	AdMarkers []HlsAdMarkers
	// A partial URI prefix that will be prepended to each output in the media .m3u8
	// file. Can be used if base manifest is delivered from a different URL than the
	// main .m3u8 file.
	BaseUrlContent *string
	// Provides an extra millisecond delta offset to fine tune the timestamps.
	TimestampDeltaMilliseconds *int32
	// Number of segments to write to a subdirectory before starting a new one.
	// directoryStructure must be subdirectoryPerStream for this setting to have an
	// effect.
	SegmentsPerSubdirectory *int32
	// Applies only to 608 Embedded output captions. insert: Include CLOSED-CAPTIONS
	// lines in the manifest. Specify at least one language in the CC1 Language Code
	// field. One CLOSED-CAPTION line is added for each Language Code you specify. Make
	// sure to specify the languages in the order in which they appear in the original
	// source (if the source is embedded format) or the order of the caption selectors
	// (if the source is other than embedded). Otherwise, languages in the manifest
	// will not match up properly with the output captions. none: Include
	// CLOSED-CAPTIONS=NONE line in the manifest. omit: Omit any CLOSED-CAPTIONS line
	// from the manifest.
	CaptionLanguageSetting HlsCaptionLanguageSetting
	// DISABLED: Do not create an I-frame-only manifest, but do create the master and
	// media manifests (according to the Output Selection field). STANDARD: Create an
	// I-frame-only manifest for each output that contains video, as well as the other
	// manifests (according to the Output Selection field). The I-frame manifest
	// contains a #EXT-X-I-FRAMES-ONLY tag to indicate it is I-frame only, and one or
	// more #EXT-X-BYTERANGE entries identifying the I-frame position. For example,
	// #EXT-X-BYTERANGE:160364@1461888"
	IFrameOnlyPlaylists IFrameOnlyPlaylistType
	// For use with encryptionType. The IV (Initialization Vector) is a 128-bit number
	// used in conjunction with the key for encrypting blocks. If set to "include", IV
	// is listed in the manifest, otherwise the IV is not in the manifest.
	IvInManifest HlsIvInManifest
	// MANIFESTS_AND_SEGMENTS: Generates manifests (master manifest, if applicable, and
	// media manifests) for this output group. VARIANT_MANIFESTS_AND_SEGMENTS:
	// Generates media manifests for this output group, but not a master manifest.
	// SEGMENTS_ONLY: Does not generate any manifests for this output group.
	OutputSelection HlsOutputSelection
	// Include or exclude RESOLUTION attribute for video in EXT-X-STREAM-INF tag of
	// variant manifest.
	StreamInfResolution HlsStreamInfResolution
	// ENABLED: The master manifest (.m3u8 file) for each pipeline includes information
	// about both pipelines: first its own media files, then the media files of the
	// other pipeline. This feature allows playout device that support stale manifest
	// detection to switch from one manifest to the other, when the current manifest
	// seems to be stale. There are still two destinations and two master manifests,
	// but both master manifests reference the media files from both pipelines.
	// DISABLED: The master manifest (.m3u8 file) for each pipeline includes
	// information about its own pipeline only. For an HLS output group with
	// MediaPackage as the destination, the DISABLED behavior is always followed.
	// MediaPackage regenerates the manifests it serves to players so a redundant
	// manifest from MediaLive is irrelevant.
	RedundantManifest HlsRedundantManifest
	// Period of insertion of EXT-X-PROGRAM-DATE-TIME entry, in seconds.
	ProgramDateTimePeriod *int32
	// Indicates ID3 frame that has the timecode.
	TimedMetadataId3Frame HlsTimedMetadataId3Frame
	// When set to "disabled", sets the #EXT-X-ALLOW-CACHE:no tag in the manifest,
	// which prevents clients from saving media segments for later replay.
	ClientCache HlsClientCache
	// When set, minimumSegmentLength is enforced by looking ahead and back within the
	// specified range for a nearby avail and extending the segment size if needed.
	MinSegmentLength *int32
	// Optional. One value per output group. Complete this field only if you are
	// completing Base URL manifest A, and the downstream system has notified you that
	// the child manifest files for pipeline 1 of all outputs are in a location
	// different from the child manifest files for pipeline 0.
	BaseUrlManifest1 *string
	// If "vod", all segments are indexed and kept permanently in the destination and
	// manifest. If "live", only the number segments specified in keepSegments and
	// indexNSegments are kept; newer segments replace older segments, which may
	// prevent players from rewinding all the way to the beginning of the event. VOD
	// mode uses HLS EXT-X-PLAYLIST-TYPE of EVENT while the channel is running,
	// converting it to a "VOD" type manifest on completion of the stream.
	Mode HlsMode
	// Specification to use (RFC-6381 or the default RFC-4281) during m3u8 playlist
	// generation.
	CodecSpecification HlsCodecSpecification
	// A directory or HTTP destination for the HLS segments, manifest files, and
	// encryption keys (if enabled).
	Destination *OutputLocationRef
	// Parameter that control output group behavior on input loss.
	InputLossAction InputLossActionForHlsOut
	// Encrypts the segments with the given encryption scheme. Exclude this parameter
	// if no encryption is desired.
	EncryptionType HlsEncryptionType
	// For use with encryptionType. This is a 128-bit, 16-byte hex value represented by
	// a 32-character text string. If ivSource is set to "explicit" then this parameter
	// is required and is used as the IV for encryption.
	ConstantIv *string
	// Either a single positive integer version value or a slash delimited list of
	// version values (1/2/3).
	KeyFormatVersions *string
	// State of HLS ID3 Segment Tagging
	HlsId3SegmentTagging HlsId3SegmentTaggingState
	// Parameters that control interactions with the CDN.
	HlsCdnSettings *HlsCdnSettings
}

// Settings for the action to insert a user-defined ID3 tag in each HLS segment
type HlsId3SegmentTaggingScheduleActionSettings struct {
	// ID3 tag to insert into each segment. Supports special keyword identifiers to
	// substitute in segment-related values.\nSupported keyword identifiers:
	// https://docs.aws.amazon.com/medialive/latest/ug/variable-data-identifiers.html
	Tag *string
}

// Hls Input Settings
type HlsInputSettings struct {
	// The number of seconds between retries when an attempt to read a manifest or
	// segment fails.
	RetryInterval *int32
	// When specified, reading of the HLS input will begin this many buffer segments
	// from the end (most recently written segment). When not specified, the HLS input
	// will begin with the first segment specified in the m3u8.
	BufferSegments *int32
	// When specified the HLS stream with the m3u8 BANDWIDTH that most closely matches
	// this value will be chosen, otherwise the highest bandwidth stream in the m3u8
	// will be chosen. The bitrate is specified in bits per second, as in an HLS
	// manifest.
	Bandwidth *int32
	// The number of consecutive times that attempts to read a manifest or segment must
	// fail before the input is considered unavailable.
	Retries *int32
}

// Hls Media Store Settings
type HlsMediaStoreSettings struct {
	// Number of retry attempts that will be made before the Live Event is put into an
	// error state.
	NumRetries *int32
	// If a streaming output fails, number of seconds to wait until a restart is
	// initiated. A value of 0 means never restart.
	RestartDelay *int32
	// When set to temporal, output files are stored in non-persistent memory for
	// faster reading and writing.
	MediaStoreStorageClass HlsMediaStoreStorageClass
	// Number of seconds to wait before retrying connection to the CDN if the
	// connection is lost.
	ConnectionRetryInterval *int32
	// Size in seconds of file cache for streaming outputs.
	FilecacheDuration *int32
}

// Hls Output Settings
type HlsOutputSettings struct {
	// String concatenated to the end of the destination filename. Accepts "Format
	// Identifiers":#formatIdentifierParameters.
	NameModifier *string
	// Settings regarding the underlying stream. These settings are different for
	// audio-only outputs.
	HlsSettings *HlsSettings
	// Only applicable when this output is referencing an H.265 video description.
	// Specifies whether MP4 segments should be packaged as HEV1 or HVC1.
	H265PackagingType HlsH265PackagingType
	// String concatenated to end of segment filenames.
	SegmentModifier *string
}

// Hls Settings
type HlsSettings struct {
	// Standard Hls Settings
	StandardHlsSettings *StandardHlsSettings
	// Fmp4 Hls Settings
	Fmp4HlsSettings *Fmp4HlsSettings
	// Audio Only Hls Settings
	AudioOnlyHlsSettings *AudioOnlyHlsSettings
}

// Settings for the action to emit HLS metadata
type HlsTimedMetadataScheduleActionSettings struct {
	// Base64 string formatted according to the ID3 specification:
	// http://id3.org/id3v2.4.0-structure
	Id3 *string
}

// Hls Webdav Settings
type HlsWebdavSettings struct {
	// Specify whether or not to use chunked transfer encoding to WebDAV.
	HttpTransferMode HlsWebdavHttpTransferMode
	// Number of retry attempts that will be made before the Live Event is put into an
	// error state.
	NumRetries *int32
	// Size in seconds of file cache for streaming outputs.
	FilecacheDuration *int32
	// If a streaming output fails, number of seconds to wait until a restart is
	// initiated. A value of 0 means never restart.
	RestartDelay *int32
	// Number of seconds to wait before retrying connection to the CDN if the
	// connection is lost.
	ConnectionRetryInterval *int32
}

// Settings to configure an action so that it occurs as soon as possible.
type ImmediateModeScheduleActionStartSettings struct {
}

// Placeholder documentation for Input
type Input struct {
	// A list of IDs for all the Input Security Groups attached to the input.
	SecurityGroups []*string
	// The Amazon Resource Name (ARN) of the role this input assumes during and after
	// creation.
	RoleArn *string
	// STANDARD - MediaLive expects two sources to be connected to this input. If the
	// channel is also STANDARD, both sources will be ingested. If the channel is
	// SINGLE_PIPELINE, only the first source will be ingested; the second source will
	// always be ignored, even if the first source fails. SINGLE_PIPELINE - You can
	// connect only one source to this input. If the ChannelClass is also
	// SINGLE_PIPELINE, this value is valid. If the ChannelClass is STANDARD, this
	// value is not valid because the channel requires two sources in the input.
	InputClass InputClass
	// The Unique ARN of the input (generated, immutable).
	Arn *string
	// The generated ID of the input (unique for user account, immutable).
	Id *string
	// A list of the sources of the input (PULL-type).
	Sources []*InputSource
	// A list of the destinations of the input (PUSH-type).
	Destinations []*InputDestination
	// The user-assigned name (This is a mutable value).
	Name *string
	// Placeholder documentation for InputState
	State InputState
	// A list of MediaConnect Flows for this input.
	MediaConnectFlows []*MediaConnectFlow
	// Certain pull input sources can be dynamic, meaning that they can have their
	// URL's dynamically changes during input switch actions. Presently, this
	// functionality only works with MP4_FILE inputs.
	InputSourceType InputSourceType
	// Placeholder documentation for InputType
	Type InputType
	// A collection of key-value pairs.
	Tags map[string]*string
	// A list of channel IDs that that input is attached to (currently an input can
	// only be attached to one channel).
	AttachedChannels []*string
	// Settings for the input devices.
	InputDevices []*InputDeviceSettings
}

// Placeholder documentation for InputAttachment
type InputAttachment struct {
	// User-specified name for the attachment. This is required if the user wants to
	// use this input in an input switch action.
	InputAttachmentName *string
	// The ID of the input
	InputId *string
	// User-specified settings for defining what the conditions are for declaring the
	// input unhealthy and failing over to a different input.
	AutomaticInputFailoverSettings *AutomaticInputFailoverSettings
	// Settings of an input (caption selector, etc.)
	InputSettings *InputSettings
}

// Input Channel Level
type InputChannelLevel struct {
	// The index of the input channel used as a source.
	InputChannel *int32
	// Remixing value. Units are in dB and acceptable values are within the range from
	// -60 (mute) and 6 dB.
	Gain *int32
}

// Settings to let you create a clip of the file input, in order to set up the
// input to ingest only a portion of the file.
type InputClippingSettings struct {
	// The source of the timecodes in the source being clipped.
	InputTimecodeSource InputTimecodeSource
	// Settings to identify the end of the clip.
	StopTimecode *StopTimecode
	// Settings to identify the start of the clip.
	StartTimecode *StartTimecode
}

// The settings for a PUSH type input.
type InputDestination struct {
	// The port number for the input.
	Port *string
	// The properties for a VPC type input destination.
	Vpc *InputDestinationVpc
	// The system-generated static IP address of endpoint. It remains fixed for the
	// lifetime of the input.
	Ip *string
	// This represents the endpoint that the customer stream will be pushed to.
	Url *string
}

// Endpoint settings for a PUSH type input.
type InputDestinationRequest struct {
	// A unique name for the location the RTMP stream is being pushed to.
	StreamName *string
}

// The properties for a VPC type input destination.
type InputDestinationVpc struct {
	// The network interface ID of the Input destination in the VPC.
	NetworkInterfaceId *string
	// The availability zone of the Input destination.
	AvailabilityZone *string
}

// Configurable settings for the input device.
type InputDeviceConfigurableSettings struct {
	// The maximum bitrate in bits per second. Set a value here to throttle the bitrate
	// of the source video.
	MaxBitrate *int32
	// The input source that you want to use. If the device has a source connected to
	// only one of its input ports, or if you don't care which source the device sends,
	// specify Auto. If the device has sources connected to both its input ports, and
	// you want to use a specific source, specify the source.
	ConfiguredInput InputDeviceConfiguredInput
}

// Settings that describe the active source from the input device, and the video
// characteristics of that source.
type InputDeviceHdSettings struct {
	// The width of the video source, in pixels.
	Width *int32
	// The height of the video source, in pixels.
	Height *int32
	// If you specified Auto as the configured input, specifies which of the sources is
	// currently active (SDI or HDMI).
	ActiveInput InputDeviceActiveInput
	// The frame rate of the video source.
	Framerate *float64
	// The state of the input device.
	DeviceState InputDeviceState
	// The current maximum bitrate for ingesting this source, in bits per second. You
	// can specify this maximum.
	MaxBitrate *int32
	// The source at the input device that is currently active. You can specify this
	// source.
	ConfiguredInput InputDeviceConfiguredInput
	// The scan type of the video source.
	ScanType InputDeviceScanType
}

// The network settings for the input device.
type InputDeviceNetworkSettings struct {
	// The subnet mask of the input device.
	SubnetMask *string
	// The network gateway IP address.
	Gateway *string
	// The DNS addresses of the input device.
	DnsAddresses []*string
	// Specifies whether the input device has been configured (outside of MediaLive) to
	// use a dynamic IP address assignment (DHCP) or a static IP address.
	IpScheme InputDeviceIpScheme
	// The IP address of the input device.
	IpAddress *string
}

// Settings for an input device.
type InputDeviceRequest struct {
	// The unique ID for the device.
	Id *string
}

// Settings for an input device.
type InputDeviceSettings struct {
	// The unique ID for the device.
	Id *string
}

// Details of the input device.
type InputDeviceSummary struct {
	// The status of the action to synchronize the device configuration. If you change
	// the configuration of the input device (for example, the maximum bitrate),
	// MediaLive sends the new data to the device. The device might not update itself
	// immediately. SYNCED means the device has updated its configuration. SYNCING
	// means that it has not updated its configuration.
	DeviceSettingsSyncState DeviceSettingsSyncState
	// A name that you specify for the input device.
	Name *string
	// The unique ID of the input device.
	Id *string
	// The network MAC address of the input device.
	MacAddress *string
	// Settings that describe an input device that is type HD.
	HdDeviceSettings *InputDeviceHdSettings
	// The state of the connection between the input device and AWS.
	ConnectionState InputDeviceConnectionState
	// The unique ARN of the input device.
	Arn *string
	// Network settings for the input device.
	NetworkSettings *InputDeviceNetworkSettings
	// The type of the input device.
	Type InputDeviceType
	// The unique serial number of the input device.
	SerialNumber *string
}

// Input Location
type InputLocation struct {
	// Uniform Resource Identifier - This should be a path to a file accessible to the
	// Live system (eg. a http:// URI) depending on the output type. For example, a
	// RTMP destination should have a uri simliar to: "rtmp://fmsserver/live".
	Uri *string
	// key used to extract the password from EC2 Parameter store
	PasswordParam *string
	// Documentation update needed
	Username *string
}

// Input Loss Behavior
type InputLossBehavior struct {
	// Documentation update needed
	RepeatFrameMsec *int32
	// Documentation update needed
	BlackFrameMsec *int32
	// Indicates whether to substitute a solid color or a slate into the output after
	// input loss exceeds blackFrameMsec.
	InputLossImageType InputLossImageType
	// When input loss image type is "color" this field specifies the color to use.
	// Value: 6 hex characters representing the values of RGB.
	InputLossImageColor *string
	// When input loss image type is "slate" these fields specify the parameters for
	// accessing the slate.
	InputLossImageSlate *InputLocation
}

// Action to prepare an input for a future immediate input switch.
type InputPrepareScheduleActionSettings struct {
	// Settings to let you create a clip of the file input, in order to set up the
	// input to ingest only a portion of the file.
	InputClippingSettings *InputClippingSettings
	// The value for the variable portion of the URL for the dynamic input, for this
	// instance of the input. Each time you use the same dynamic input in an input
	// switch action, you can provide a different value, in order to connect the input
	// to a different content source.
	UrlPath []*string
	// The name of the input attachment that should be prepared by this action. If no
	// name is provided, the action will stop the most recent prepare (if any) when
	// activated.
	InputAttachmentNameReference *string
}

// An Input Security Group
type InputSecurityGroup struct {
	// The Id of the Input Security Group
	Id *string
	// Whitelist rules and their sync status
	WhitelistRules []*InputWhitelistRule
	// Unique ARN of Input Security Group
	Arn *string
	// The current state of the Input Security Group.
	State InputSecurityGroupState
	// The list of inputs currently using this Input Security Group.
	Inputs []*string
	// A collection of key-value pairs.
	Tags map[string]*string
}

// Live Event input parameters. There can be multiple inputs in a single Live
// Event.
type InputSettings struct {
	// Turns on the filter for this input. MPEG-2 inputs have the deblocking filter
	// enabled by default.
	//
	//     * auto - filtering will be applied depending on input
	// type/quality
	//
	//     * disabled - no filtering will be applied to the input
	//
	//     *
	// forced - filtering will be applied regardless of input type
	InputFilter InputFilter
	// Adjusts the magnitude of filtering from 1 (minimal) to 5 (strongest).
	FilterStrength *int32
	// Specifies whether to extract applicable ancillary data from a SMPTE-2038 source
	// in this input. Applicable data types are captions, timecode, AFD, and SCTE-104
	// messages.
	//
	//     * PREFER: Extract from SMPTE-2038 if present in this input,
	// otherwise extract from another source (if any).
	//
	//     * IGNORE: Never extract any
	// ancillary data from SMPTE-2038.
	Smpte2038DataPreference Smpte2038DataPreference
	// Used to select the caption input to use for inputs that have multiple available.
	CaptionSelectors []*CaptionSelector
	// Used to select the audio stream to decode for inputs that have multiple
	// available.
	AudioSelectors []*AudioSelector
	// Informs which video elementary stream to decode for input types that have
	// multiple available.
	VideoSelector *VideoSelector
	// Loop input if it is a file. This allows a file input to be streamed
	// indefinitely.
	SourceEndBehavior InputSourceEndBehavior
	// Enable or disable the deblock filter when filtering.
	DeblockFilter InputDeblockFilter
	// Input settings.
	NetworkInputSettings *NetworkInputSettings
	// Enable or disable the denoise filter when filtering.
	DenoiseFilter InputDenoiseFilter
}

// The settings for a PULL type input.
type InputSource struct {
	// This represents the customer's source URL where stream is pulled from.
	Url *string
	// The username for the input source.
	Username *string
	// The key used to extract the password from EC2 Parameter store.
	PasswordParam *string
}

// Settings for for a PULL type input.
type InputSourceRequest struct {
	// This represents the customer's source URL where stream is pulled from.
	Url *string
	// The username for the input source.
	Username *string
	// The key used to extract the password from EC2 Parameter store.
	PasswordParam *string
}

// Placeholder documentation for InputSpecification
type InputSpecification struct {
	// Input codec
	Codec InputCodec
	// Input resolution, categorized coarsely
	Resolution InputResolution
	// Maximum input bitrate, categorized coarsely
	MaximumBitrate InputMaximumBitrate
}

// Settings for the "switch input" action: to switch from ingesting one input to
// ingesting another input.
type InputSwitchScheduleActionSettings struct {
	// The name of the input attachment (not the name of the input!) to switch to. The
	// name is specified in the channel configuration.
	InputAttachmentNameReference *string
	// The value for the variable portion of the URL for the dynamic input, for this
	// instance of the input. Each time you use the same dynamic input in an input
	// switch action, you can provide a different value, in order to connect the input
	// to a different content source.
	UrlPath []*string
	// Settings to let you create a clip of the file input, in order to set up the
	// input to ingest only a portion of the file.
	InputClippingSettings *InputClippingSettings
}

// Settings for a private VPC Input. When this property is specified, the input
// destination addresses will be created in a VPC rather than with public Internet
// addresses. This property requires setting the roleArn property on Input
// creation. Not compatible with the inputSecurityGroups property.
type InputVpcRequest struct {
	// A list of 2 VPC subnet IDs from the same VPC. Subnet IDs must be mapped to two
	// unique availability zones (AZ).
	SubnetIds []*string
	// A list of up to 5 EC2 VPC security group IDs to attach to the Input VPC network
	// interfaces. Requires subnetIds. If none are specified then the VPC default
	// security group will be used.
	SecurityGroupIds []*string
}

// Whitelist rule
type InputWhitelistRule struct {
	// The IPv4 CIDR that's whitelisted.
	Cidr *string
}

// An IPv4 CIDR to whitelist.
type InputWhitelistRuleCidr struct {
	// The IPv4 CIDR to whitelist.
	Cidr *string
}

// Key Provider Settings
type KeyProviderSettings struct {
	// Static Key Settings
	StaticKeySettings *StaticKeySettings
}

// M2ts Settings
type M2tsSettings struct {
	// Packet Identifier (PID) of the SCTE-35 stream in the transport stream. Can be
	// entered as a decimal or hexadecimal value. Valid values are 32 (or 0x20)..8182
	// (or 0x1ff6).
	Scte35Pid *string
	// Packet Identifier (PID) for input source SCTE-27 data to this output. Multiple
	// values are accepted, and can be entered in ranges and/or by comma separation.
	// Can be entered as decimal or hexadecimal values. Each PID specified must be in
	// the range of 32 (or 0x20)..8182 (or 0x1ff6).
	Scte27Pids *string
	// Controls placement of EBP on Audio PIDs. If set to videoAndAudioPids, EBP
	// markers will be placed on the video PID and all audio PIDs. If set to videoPid,
	// EBP markers will be placed on only the video PID.
	EbpPlacement M2tsEbpPlacement
	// When set to enabled, generates captionServiceDescriptor in PMT.
	CcDescriptor M2tsCcDescriptor
	// Packet Identifier (PID) for input source ETV Signal data to this output. Can be
	// entered as a decimal or hexadecimal value. Valid values are 32 (or 0x20)..8182
	// (or 0x1ff6).
	EtvSignalPid *string
	// The value of the transport stream ID field in the Program Map Table.
	TransportStreamId *int32
	// The number of audio frames to insert for each PES packet.
	AudioFramesPerPes *int32
	// Packet Identifier (PID) of the elementary audio stream(s) in the transport
	// stream. Multiple values are accepted, and can be entered in ranges and/or by
	// comma separation. Can be entered as decimal or hexadecimal values. Each PID
	// specified must be in the range of 32 (or 0x20)..8182 (or 0x1ff6).
	AudioPids *string
	// Packet Identifier (PID) for ARIB Captions in the transport stream. Can be
	// entered as a decimal or hexadecimal value. Valid values are 32 (or 0x20)..8182
	// (or 0x1ff6).
	AribCaptionsPid *string
	// The output bitrate of the transport stream in bits per second. Setting to 0 lets
	// the muxer automatically determine the appropriate bitrate.
	Bitrate *int32
	// Packet Identifier (PID) of the elementary video stream in the transport stream.
	// Can be entered as a decimal or hexadecimal value. Valid values are 32 (or
	// 0x20)..8182 (or 0x1ff6).
	VideoPid *string
	// Inserts segmentation markers at each segmentationTime period. raiSegstart sets
	// the Random Access Indicator bit in the adaptation field. raiAdapt sets the RAI
	// bit and adds the current timecode in the private data bytes. psiSegstart inserts
	// PAT and PMT tables at the start of segments. ebp adds Encoder Boundary Point
	// information to the adaptation field as per OpenCable specification
	// OC-SP-EBP-I01-130118. ebpLegacy adds Encoder Boundary Point information to the
	// adaptation field using a legacy proprietary format.
	SegmentationMarkers M2tsSegmentationMarkers
	// Packet Identifier (PID) for input source ETV Platform data to this output. Can
	// be entered as a decimal or hexadecimal value. Valid values are 32 (or
	// 0x20)..8182 (or 0x1ff6).
	EtvPlatformPid *string
	// The length in seconds of each fragment. Only used with EBP markers.
	FragmentTime *float64
	// When set to drop, output audio streams will be removed from the program if the
	// selected input audio stream is removed from the input. This allows the output
	// audio configuration to dynamically change based on input configuration. If this
	// is set to encodeSilence, all output audio streams will output encoded silence
	// when not connected to an active input stream.
	AbsentInputAudioBehavior M2tsAbsentInputAudioBehavior
	// The number of milliseconds between instances of this table in the output
	// transport stream. Valid values are 0, 10..1000.
	PatInterval *int32
	// Maximum time in milliseconds between Program Clock Reference (PCRs) inserted
	// into the transport stream.
	PcrPeriod *int32
	// Optionally pass SCTE-35 signals from the input source to this output.
	Scte35Control M2tsScte35Control
	// When set to passthrough, timed metadata will be passed through from input to
	// output.
	TimedMetadataBehavior M2tsTimedMetadataBehavior
	// Inserts DVB Network Information Table (NIT) at the specified table repetition
	// interval.
	DvbNitSettings *DvbNitSettings
	// The segmentation style parameter controls how segmentation markers are inserted
	// into the transport stream. With avails, it is possible that segments may be
	// truncated, which can influence where future segmentation markers are inserted.
	// When a segmentation style of "resetCadence" is selected and a segment is
	// truncated due to an avail, we will reset the segmentation cadence. This means
	// the subsequent segment will have a duration of $segmentationTime seconds. When a
	// segmentation style of "maintainCadence" is selected and a segment is truncated
	// due to an avail, we will not reset the segmentation cadence. This means the
	// subsequent segment will likely be truncated as well. However, all segments after
	// that will have a duration of $segmentationTime seconds. Note that EBP lookahead
	// is a slight exception to this rule.
	SegmentationStyle M2tsSegmentationStyle
	// Inserts DVB Time and Date Table (TDT) at the specified table repetition
	// interval.
	DvbTdtSettings *DvbTdtSettings
	// If set to auto, pid number used for ARIB Captions will be auto-selected from
	// unused pids. If set to useConfigured, ARIB Captions will be on the configured
	// pid number.
	AribCaptionsPidControl M2tsAribCaptionsPidControl
	// If set to passthrough, passes any KLV data from the input source to this output.
	Klv M2tsKlv
	// When set to atsc, uses stream type = 0x81 for AC3 and stream type = 0x87 for
	// EAC3. When set to dvb, uses stream type = 0x06.
	AudioStreamType M2tsAudioStreamType
	// When set, enforces that Encoder Boundary Points do not come within the specified
	// time interval of each other by looking ahead at input video. If another EBP is
	// going to come in within the specified time interval, the current EBP is not
	// emitted, and the segment is "stretched" to the next marker. The lookahead value
	// does not add latency to the system. The Live Event must be configured elsewhere
	// to create sufficient latency to make the lookahead accurate.
	EbpLookaheadMs *int32
	// Include or exclude the ES Rate field in the PES header.
	EsRateInPes M2tsEsRateInPes
	// If set to passthrough, Nielsen inaudible tones for media tracking will be
	// detected in the input audio and an equivalent ID3 tag will be inserted in the
	// output.
	NielsenId3Behavior M2tsNielsenId3Behavior
	// When set to enabled, uses ARIB-compliant field muxing and removes video
	// descriptor.
	Arib M2tsArib
	// Packet Identifier (PID) for input source KLV data to this output. Multiple
	// values are accepted, and can be entered in ranges and/or by comma separation.
	// Can be entered as decimal or hexadecimal values. Each PID specified must be in
	// the range of 32 (or 0x20)..8182 (or 0x1ff6).
	KlvDataPids *string
	// Packet Identifier (PID) for the Program Map Table (PMT) in the transport stream.
	// Can be entered as a decimal or hexadecimal value. Valid values are 32 (or
	// 0x20)..8182 (or 0x1ff6).
	PmtPid *string
	// Packet Identifier (PID) for input source DVB Teletext data to this output. Can
	// be entered as a decimal or hexadecimal value. Valid values are 32 (or
	// 0x20)..8182 (or 0x1ff6).
	DvbTeletextPid *string
	// The value of the program number field in the Program Map Table.
	ProgramNum *int32
	// When set to pcrEveryPesPacket, a Program Clock Reference value is inserted for
	// every Packetized Elementary Stream (PES) header. This parameter is effective
	// only when the PCR PID is the same as the video or audio elementary stream.
	PcrControl M2tsPcrControl
	// When vbr, does not insert null packets into transport stream to fill specified
	// bitrate. The bitrate setting acts as the maximum bitrate when vbr is set.
	RateMode M2tsRateMode
	// Packet Identifier (PID) for input source DVB Subtitle data to this output.
	// Multiple values are accepted, and can be entered in ranges and/or by comma
	// separation. Can be entered as decimal or hexadecimal values. Each PID specified
	// must be in the range of 32 (or 0x20)..8182 (or 0x1ff6).
	DvbSubPids *string
	// When videoAndFixedIntervals is selected, audio EBP markers will be added to
	// partitions 3 and 4. The interval between these additional markers will be fixed,
	// and will be slightly shorter than the video EBP marker interval. Only available
	// when EBP Cablelabs segmentation markers are selected. Partitions 1 and 2 will
	// always follow the video interval.
	EbpAudioInterval M2tsAudioInterval
	// Packet Identifier (PID) of the Program Clock Reference (PCR) in the transport
	// stream. When no value is given, the encoder will assign the same value as the
	// Video PID. Can be entered as a decimal or hexadecimal value. Valid values are 32
	// (or 0x20)..8182 (or 0x1ff6).
	PcrPid *string
	// The number of milliseconds between instances of this table in the output
	// transport stream. Valid values are 0, 10..1000.
	PmtInterval *int32
	// The length in seconds of each segment. Required unless markers is set to none.
	SegmentationTime *float64
	// If set to multiplex, use multiplex buffer model for accurate interleaving.
	// Setting to bufferModel to none can lead to lower latency, but low-memory devices
	// may not be able to play back the stream without interruptions.
	BufferModel M2tsBufferModel
	// Packet Identifier (PID) of the timed metadata stream in the transport stream.
	// Can be entered as a decimal or hexadecimal value. Valid values are 32 (or
	// 0x20)..8182 (or 0x1ff6).
	TimedMetadataPid *string
	// This field is unused and deprecated.
	EcmPid *string
	// Value in bits per second of extra null packets to insert into the transport
	// stream. This can be used if a downstream encryption system requires periodic
	// null packets.
	NullPacketBitrate *float64
	// Inserts DVB Service Description Table (SDT) at the specified table repetition
	// interval.
	DvbSdtSettings *DvbSdtSettings
	// If set to passthrough, passes any EBIF data from the input source to this
	// output.
	Ebif M2tsEbifControl
	// When set to dvb, uses DVB buffer model for Dolby Digital audio. When set to
	// atsc, the ATSC model is used.
	AudioBufferModel M2tsAudioBufferModel
}

// Settings information for the .m3u8 container
type M3u8Settings struct {
	// Packet Identifier (PID) of the SCTE-35 stream in the transport stream. Can be
	// entered as a decimal or hexadecimal value.
	Scte35Pid *string
	// When set to passthrough, timed metadata is passed through from input to output.
	TimedMetadataBehavior M3u8TimedMetadataBehavior
	// Packet Identifier (PID) of the elementary video stream in the transport stream.
	// Can be entered as a decimal or hexadecimal value.
	VideoPid *string
	// Packet Identifier (PID) of the timed metadata stream in the transport stream.
	// Can be entered as a decimal or hexadecimal value. Valid values are 32 (or
	// 0x20)..8182 (or 0x1ff6).
	TimedMetadataPid *string
	// If set to passthrough, Nielsen inaudible tones for media tracking will be
	// detected in the input audio and an equivalent ID3 tag will be inserted in the
	// output.
	NielsenId3Behavior M3u8NielsenId3Behavior
	// Maximum time in milliseconds between Program Clock References (PCRs) inserted
	// into the transport stream.
	PcrPeriod *int32
	// The value of the program number field in the Program Map Table.
	ProgramNum *int32
	// Packet Identifier (PID) of the elementary audio stream(s) in the transport
	// stream. Multiple values are accepted, and can be entered in ranges and/or by
	// comma separation. Can be entered as decimal or hexadecimal values.
	AudioPids *string
	// The number of milliseconds between instances of this table in the output
	// transport stream. A value of "0" writes out the PMT once per segment file.
	PatInterval *int32
	// This parameter is unused and deprecated.
	EcmPid *string
	// When set to pcrEveryPesPacket, a Program Clock Reference value is inserted for
	// every Packetized Elementary Stream (PES) header. This parameter is effective
	// only when the PCR PID is the same as the video or audio elementary stream.
	PcrControl M3u8PcrControl
	// Packet Identifier (PID) for the Program Map Table (PMT) in the transport stream.
	// Can be entered as a decimal or hexadecimal value.
	PmtPid *string
	// If set to passthrough, passes any SCTE-35 signals from the input source to this
	// output.
	Scte35Behavior M3u8Scte35Behavior
	// The value of the transport stream ID field in the Program Map Table.
	TransportStreamId *int32
	// The number of audio frames to insert for each PES packet.
	AudioFramesPerPes *int32
	// Packet Identifier (PID) of the Program Clock Reference (PCR) in the transport
	// stream. When no value is given, the encoder will assign the same value as the
	// Video PID. Can be entered as a decimal or hexadecimal value.
	PcrPid *string
	// The number of milliseconds between instances of this table in the output
	// transport stream. A value of "0" writes out the PMT once per segment file.
	PmtInterval *int32
}

// The settings for a MediaConnect Flow.
type MediaConnectFlow struct {
	// The unique ARN of the MediaConnect Flow being used as a source.
	FlowArn *string
}

// The settings for a MediaConnect Flow.
type MediaConnectFlowRequest struct {
	// The ARN of the MediaConnect Flow that you want to use as a source.
	FlowArn *string
}

// Media Package Group Settings
type MediaPackageGroupSettings struct {
	// MediaPackage channel destination.
	Destination *OutputLocationRef
}

// MediaPackage Output Destination Settings
type MediaPackageOutputDestinationSettings struct {
	// ID of the channel in MediaPackage that is the destination for this output group.
	// You do not need to specify the individual inputs in MediaPackage; MediaLive will
	// handle the connection of the two MediaLive pipelines to the two MediaPackage
	// inputs. The MediaPackage channel and MediaLive channel must be in the same
	// region.
	ChannelId *string
}

// Media Package Output Settings
type MediaPackageOutputSettings struct {
}

// Mp2 Settings
type Mp2Settings struct {
	// Sample rate in Hz.
	SampleRate *float64
	// The MPEG2 Audio coding mode. Valid values are codingMode10 (for mono) or
	// codingMode20 (for stereo).
	CodingMode Mp2CodingMode
	// Average bitrate in bits/second.
	Bitrate *float64
}

// Ms Smooth Group Settings
type MsSmoothGroupSettings struct {
	// Number of milliseconds to delay the output from the second pipeline.
	SendDelayMs *int32
	// MS Smooth event ID to be sent to the IIS server. Should only be specified if
	// eventIdMode is set to useConfigured.
	EventId *string
	// Size in seconds of file cache for streaming outputs.
	FilecacheDuration *int32
	// Number of seconds to wait before retrying connection to the IIS server if the
	// connection is lost. Content will be cached during this time and the cache will
	// be be delivered to the IIS server once the connection is re-established.
	ConnectionRetryInterval *int32
	// Number of seconds before initiating a restart due to output failure, due to
	// exhausting the numRetries on one segment, or exceeding filecacheDuration.
	RestartDelay *int32
	// useInputSegmentation has been deprecated. The configured segment size is always
	// used.
	SegmentationMode SmoothGroupSegmentationMode
	// Parameter that control output group behavior on input loss.
	InputLossAction InputLossActionForMsSmoothOut
	// Timestamp offset for the event. Only used if timestampOffsetMode is set to
	// useConfiguredOffset.
	TimestampOffset *string
	// When set to send, send stream manifest so publishing point doesn't start until
	// all streams start.
	StreamManifestBehavior SmoothGroupStreamManifestBehavior
	// Type of timestamp date offset to use.
	//
	//     * useEventStartDate: Use the date the
	// event was started as the offset
	//
	//     * useConfiguredOffset: Use an explicitly
	// configured date as the offset
	TimestampOffsetMode SmoothGroupTimestampOffsetMode
	// Length of mp4 fragments to generate (in seconds). Fragment length must be
	// compatible with GOP size and framerate.
	FragmentLength *int32
	// Specifies whether or not to send an event ID to the IIS server. If no event ID
	// is sent and the same Live Event is used without changing the publishing point,
	// clients might see cached video from the previous run. Options:
	//
	//     *
	// "useConfigured" - use the value provided in eventId
	//
	//     * "useTimestamp" -
	// generate and send an event ID based on the current timestamp
	//
	//     * "noEventId"
	// - do not send an event ID to the IIS server.
	EventIdMode SmoothGroupEventIdMode
	// If set to verifyAuthenticity, verify the https certificate chain to a trusted
	// Certificate Authority (CA). This will cause https outputs to self-signed
	// certificates to fail.
	CertificateMode SmoothGroupCertificateMode
	// Smooth Streaming publish point on an IIS server. Elemental Live acts as a "Push"
	// encoder to IIS.
	Destination *OutputLocationRef
	// Number of retry attempts.
	NumRetries *int32
	// Identifies the type of data to place in the sparse track:
	//
	//     * SCTE35: Insert
	// SCTE-35 messages from the source content. With each message, insert an IDR frame
	// to start a new segment.
	//
	//     * SCTE35_WITHOUT_SEGMENTATION: Insert SCTE-35
	// messages from the source content. With each message, insert an IDR frame but
	// don't start a new segment.
	//
	//     * NONE: Don't generate a sparse track for any
	// outputs in this output group.
	SparseTrackType SmoothGroupSparseTrackType
	// When set to sendEos, send EOS signal to IIS server when stopping the event
	EventStopBehavior SmoothGroupEventStopBehavior
	// If set to passthrough for an audio-only MS Smooth output, the fragment absolute
	// time will be set to the current timecode. This option does not write timecodes
	// to the audio elementary stream.
	AudioOnlyTimecodeControl SmoothGroupAudioOnlyTimecodeControl
	// The ID to include in each message in the sparse track. Ignored if
	// sparseTrackType is NONE.
	AcquisitionPointId *string
}

// Ms Smooth Output Settings
type MsSmoothOutputSettings struct {
	// String concatenated to the end of the destination filename. Required for
	// multiple outputs of the same type.
	NameModifier *string
	// Only applicable when this output is referencing an H.265 video description.
	// Specifies whether MP4 segments should be packaged as HEV1 or HVC1.
	H265PackagingType MsSmoothH265PackagingType
}

// The multiplex object.
type Multiplex struct {
	// The number of currently healthy pipelines.
	PipelinesRunningCount *int32
	// The number of programs in the multiplex.
	ProgramCount *int32
	// The name of the multiplex.
	Name *string
	// The current state of the multiplex.
	State MultiplexState
	// The unique id of the multiplex.
	Id *string
	// Configuration for a multiplex event.
	MultiplexSettings *MultiplexSettings
	// The unique arn of the multiplex.
	Arn *string
	// A list of availability zones for the multiplex.
	AvailabilityZones []*string
	// A collection of key-value pairs.
	Tags map[string]*string
	// A list of the multiplex output destinations.
	Destinations []*MultiplexOutputDestination
}

// Multiplex Group Settings
type MultiplexGroupSettings struct {
}

// Multiplex MediaConnect output destination settings.
type MultiplexMediaConnectOutputDestinationSettings struct {
	// The MediaConnect entitlement ARN available as a Flow source.
	EntitlementArn *string
}

// Multiplex output destination settings
type MultiplexOutputDestination struct {
	// Multiplex MediaConnect output destination settings.
	MediaConnectSettings *MultiplexMediaConnectOutputDestinationSettings
}

// Multiplex Output Settings
type MultiplexOutputSettings struct {
	// Destination is a Multiplex.
	Destination *OutputLocationRef
}

// The multiplex program object.
type MultiplexProgram struct {
	// The name of the multiplex program.
	ProgramName *string
	// The MediaLive channel associated with the program.
	ChannelId *string
	// The settings for this multiplex program.
	MultiplexProgramSettings *MultiplexProgramSettings
	// The packet identifier map for this multiplex program.
	PacketIdentifiersMap *MultiplexProgramPacketIdentifiersMap
}

// Multiplex Program Input Destination Settings for outputting a Channel to a
// Multiplex
type MultiplexProgramChannelDestinationSettings struct {
	// The program name of the Multiplex program that the encoder is providing output
	// to.
	ProgramName *string
	// The ID of the Multiplex that the encoder is providing output to. You do not need
	// to specify the individual inputs to the Multiplex; MediaLive will handle the
	// connection of the two MediaLive pipelines to the two Multiplex instances. The
	// Multiplex must be in the same region as the Channel.
	MultiplexId *string
}

// Packet identifiers map for a given Multiplex program.
type MultiplexProgramPacketIdentifiersMap struct {
	// Placeholder documentation for __integer
	EtvPlatformPid *int32
	// Placeholder documentation for __integer
	TimedMetadataPid *int32
	// Placeholder documentation for __listOf__integer
	DvbSubPids []*int32
	// Placeholder documentation for __listOf__integer
	Scte27Pids []*int32
	// Placeholder documentation for __integer
	PcrPid *int32
	// Placeholder documentation for __integer
	EtvSignalPid *int32
	// Placeholder documentation for __listOf__integer
	AudioPids []*int32
	// Placeholder documentation for __integer
	Scte35Pid *int32
	// Placeholder documentation for __integer
	PrivateMetadataPid *int32
	// Placeholder documentation for __integer
	PmtPid *int32
	// Placeholder documentation for __integer
	DvbTeletextPid *int32
	// Placeholder documentation for __integer
	VideoPid *int32
	// Placeholder documentation for __listOf__integer
	KlvDataPids []*int32
}

// Transport stream service descriptor configuration for the Multiplex program.
type MultiplexProgramServiceDescriptor struct {
	// Name of the service.
	ServiceName *string
	// Name of the provider.
	ProviderName *string
}

// Multiplex Program settings configuration.
type MultiplexProgramSettings struct {
	// Indicates which pipeline is preferred by the multiplex for program ingest.
	PreferredChannelPipeline PreferredChannelPipeline
	// Transport stream service descriptor configuration for the Multiplex program.
	ServiceDescriptor *MultiplexProgramServiceDescriptor
	// Program video settings configuration.
	VideoSettings *MultiplexVideoSettings
	// Unique program number.
	ProgramNumber *int32
}

// Placeholder documentation for MultiplexProgramSummary
type MultiplexProgramSummary struct {
	// The name of the multiplex program.
	ProgramName *string
	// The MediaLive Channel associated with the program.
	ChannelId *string
}

// Contains configuration for a Multiplex event
type MultiplexSettings struct {
	// Transport stream reserved bit rate.
	TransportStreamReservedBitrate *int32
	// Transport stream ID.
	TransportStreamId *int32
	// Transport stream bit rate.
	TransportStreamBitrate *int32
	// Maximum video buffer delay in milliseconds.
	MaximumVideoBufferDelayMilliseconds *int32
}

// Contains summary configuration for a Multiplex event.
type MultiplexSettingsSummary struct {
	// Transport stream bit rate.
	TransportStreamBitrate *int32
}

// Statmux rate control settings
type MultiplexStatmuxVideoSettings struct {
	// Maximum statmux bitrate.
	MaximumBitrate *int32
	// Minimum statmux bitrate.
	MinimumBitrate *int32
}

// Placeholder documentation for MultiplexSummary
type MultiplexSummary struct {
	// The current state of the multiplex.
	State MultiplexState
	// The number of programs in the multiplex.
	ProgramCount *int32
	// The unique arn of the multiplex.
	Arn *string
	// Configuration for a multiplex event.
	MultiplexSettings *MultiplexSettingsSummary
	// The number of currently healthy pipelines.
	PipelinesRunningCount *int32
	// The unique id of the multiplex.
	Id *string
	// A collection of key-value pairs.
	Tags map[string]*string
	// A list of availability zones for the multiplex.
	AvailabilityZones []*string
	// The name of the multiplex.
	Name *string
}

// The video configuration for each program in a multiplex.
type MultiplexVideoSettings struct {
	// Statmux rate control settings. When this field is defined, ConstantBitrate must
	// be undefined.
	StatmuxSettings *MultiplexStatmuxVideoSettings
	// The constant bitrate configuration for the video encode. When this field is
	// defined, StatmuxSettings must be undefined.
	ConstantBitrate *int32
}

// Network source to transcode. Must be accessible to the Elemental Live node that
// is running the live event through a network connection.
type NetworkInputSettings struct {
	// Specifies HLS input settings when the uri is for a HLS manifest.
	HlsInputSettings *HlsInputSettings
	// Check HTTPS server certificates. When set to checkCryptographyOnly, cryptography
	// in the certificate will be checked, but not the server's name. Certain
	// subdomains (notably S3 buckets that use dots in the bucket name) do not strictly
	// match the corresponding certificate's wildcard pattern and would otherwise cause
	// the event to error. This setting is ignored for protocols that do not use https.
	ServerValidation NetworkInputServerValidation
}

// Nielsen Configuration
type NielsenConfiguration struct {
	// Enter the Distributor ID assigned to your organization by Nielsen.
	DistributorId *string
	// Enables Nielsen PCM to ID3 tagging
	NielsenPcmToId3Tagging NielsenPcmToId3TaggingState
}

// Reserved resources available for purchase
type Offering struct {
	// One-time charge for each reserved resource, e.g. '0.0' for a NO_UPFRONT offering
	FixedPrice *float64
	// AWS region, e.g. 'us-west-2'
	Region *string
	// Unique offering ARN, e.g.
	// 'arn:aws:medialive:us-west-2:123456789012:offering:87654321'
	Arn *string
	// Units for duration, e.g. 'MONTHS'
	DurationUnits OfferingDurationUnits
	// Currency code for usagePrice and fixedPrice in ISO-4217 format, e.g. 'USD'
	CurrencyCode *string
	// Unique offering ID, e.g. '87654321'
	OfferingId *string
	// Offering type, e.g. 'NO_UPFRONT'
	OfferingType OfferingType
	// Offering description, e.g. 'HD AVC output at 10-20 Mbps, 30 fps, and standard VQ
	// in US West (Oregon)'
	OfferingDescription *string
	// Recurring usage charge for each reserved resource, e.g. '157.0'
	UsagePrice *float64
	// Lease duration, e.g. '12'
	Duration *int32
	// Resource configuration details
	ResourceSpecification *ReservationResourceSpecification
}

// Output settings. There can be multiple outputs within a group.
type Output struct {
	// The names of the AudioDescriptions used as audio sources for this output.
	AudioDescriptionNames []*string
	// The names of the CaptionDescriptions used as caption sources for this output.
	CaptionDescriptionNames []*string
	// The name used to identify an output.
	OutputName *string
	// The name of the VideoDescription used as the source for this output.
	VideoDescriptionName *string
	// Output type-specific settings.
	OutputSettings *OutputSettings
}

// Placeholder documentation for OutputDestination
type OutputDestination struct {
	// User-specified id. This is used in an output group or an output.
	Id *string
	// Destination settings for a Multiplex output; one destination for both encoders.
	MultiplexSettings *MultiplexProgramChannelDestinationSettings
	// Destination settings for a MediaPackage output; one destination for both
	// encoders.
	MediaPackageSettings []*MediaPackageOutputDestinationSettings
	// Destination settings for a standard output; one destination for each redundant
	// encoder.
	Settings []*OutputDestinationSettings
}

// Placeholder documentation for OutputDestinationSettings
type OutputDestinationSettings struct {
	// A URL specifying a destination
	Url *string
	// Stream name for RTMP destinations (URLs of type rtmp://)
	StreamName *string
	// key used to extract the password from EC2 Parameter store
	PasswordParam *string
	// username for destination
	Username *string
}

// Output groups for this Live Event. Output groups contain information about where
// streams should be distributed.
type OutputGroup struct {
	// Custom output group name optionally defined by the user. Only letters, numbers,
	// and the underscore character allowed; only 32 characters allowed.
	Name *string
	// Settings associated with the output group.
	OutputGroupSettings *OutputGroupSettings
	// Placeholder documentation for __listOfOutput
	Outputs []*Output
}

// Output Group Settings
type OutputGroupSettings struct {
	// Rtmp Group Settings
	RtmpGroupSettings *RtmpGroupSettings
	// Frame Capture Group Settings
	FrameCaptureGroupSettings *FrameCaptureGroupSettings
	// Multiplex Group Settings
	MultiplexGroupSettings *MultiplexGroupSettings
	// Archive Group Settings
	ArchiveGroupSettings *ArchiveGroupSettings
	// Hls Group Settings
	HlsGroupSettings *HlsGroupSettings
	// Ms Smooth Group Settings
	MsSmoothGroupSettings *MsSmoothGroupSettings
	// Media Package Group Settings
	MediaPackageGroupSettings *MediaPackageGroupSettings
	// Udp Group Settings
	UdpGroupSettings *UdpGroupSettings
}

// Reference to an OutputDestination ID defined in the channel
type OutputLocationRef struct {
	// Placeholder documentation for __string
	DestinationRefId *string
}

// Output Settings
type OutputSettings struct {
	// Media Package Output Settings
	MediaPackageOutputSettings *MediaPackageOutputSettings
	// Multiplex Output Settings
	MultiplexOutputSettings *MultiplexOutputSettings
	// Ms Smooth Output Settings
	MsSmoothOutputSettings *MsSmoothOutputSettings
	// Archive Output Settings
	ArchiveOutputSettings *ArchiveOutputSettings
	// Frame Capture Output Settings
	FrameCaptureOutputSettings *FrameCaptureOutputSettings
	// Hls Output Settings
	HlsOutputSettings *HlsOutputSettings
	// Rtmp Output Settings
	RtmpOutputSettings *RtmpOutputSettings
	// Udp Output Settings
	UdpOutputSettings *UdpOutputSettings
}

// Pass Through Settings
type PassThroughSettings struct {
}

// Settings for the action to set pause state of a channel.
type PauseStateScheduleActionSettings struct {
	// Placeholder documentation for __listOfPipelinePauseStateSettings
	Pipelines []*PipelinePauseStateSettings
}

// Runtime details of a pipeline when a channel is running.
type PipelineDetail struct {
	// The name of the active input attachment currently being ingested by this
	// pipeline.
	ActiveInputAttachmentName *string
	// The name of the input switch schedule action that occurred most recently and
	// that resulted in the switch to the current input attachment for this pipeline.
	ActiveInputSwitchActionName *string
	// Pipeline ID
	PipelineId *string
}

// Settings for pausing a pipeline.
type PipelinePauseStateSettings struct {
	// Pipeline ID to pause ("PIPELINE_0" or "PIPELINE_1").
	PipelineId PipelineId
}

// Rec601 Settings
type Rec601Settings struct {
}

// Rec709 Settings
type Rec709Settings struct {
}

// Remix Settings
type RemixSettings struct {
	// Number of output channels to be produced. Valid values: 1, 2, 4, 6, 8
	ChannelsOut *int32
	// Mapping of input channels to output channels, with appropriate gain adjustments.
	ChannelMappings []*AudioChannelMapping
	// Number of input channels to be used.
	ChannelsIn *int32
}

// Reserved resources available to use
type Reservation struct {
	// One-time charge for each reserved resource, e.g. '0.0' for a NO_UPFRONT offering
	FixedPrice *float64
	// Offering type, e.g. 'NO_UPFRONT'
	OfferingType OfferingType
	// Current state of reservation, e.g. 'ACTIVE'
	State ReservationState
	// Units for duration, e.g. 'MONTHS'
	DurationUnits OfferingDurationUnits
	// Currency code for usagePrice and fixedPrice in ISO-4217 format, e.g. 'USD'
	CurrencyCode *string
	// AWS region, e.g. 'us-west-2'
	Region *string
	// Unique offering ID, e.g. '87654321'
	OfferingId *string
	// A collection of key-value pairs
	Tags map[string]*string
	// Recurring usage charge for each reserved resource, e.g. '157.0'
	UsagePrice *float64
	// Unique reservation ARN, e.g.
	// 'arn:aws:medialive:us-west-2:123456789012:reservation:1234567'
	Arn *string
	// Reservation UTC start date and time in ISO-8601 format, e.g.
	// '2018-03-01T00:00:00'
	Start *string
	// Reservation UTC end date and time in ISO-8601 format, e.g. '2019-03-01T00:00:00'
	End *string
	// Lease duration, e.g. '12'
	Duration *int32
	// Unique reservation ID, e.g. '1234567'
	ReservationId *string
	// Offering description, e.g. 'HD AVC output at 10-20 Mbps, 30 fps, and standard VQ
	// in US West (Oregon)'
	OfferingDescription *string
	// User specified reservation name
	Name *string
	// Resource configuration details
	ResourceSpecification *ReservationResourceSpecification
	// Number of reserved resources
	Count *int32
}

// Resource configuration (codec, resolution, bitrate, ...)
type ReservationResourceSpecification struct {
	// Maximum framerate, e.g. 'MAX_30_FPS' (Outputs only)
	MaximumFramerate ReservationMaximumFramerate
	// Resolution, e.g. 'HD'
	Resolution ReservationResolution
	// Codec, e.g. 'AVC'
	Codec ReservationCodec
	// Special feature, e.g. 'AUDIO_NORMALIZATION' (Channels only)
	SpecialFeature ReservationSpecialFeature
	// Maximum bitrate, e.g. 'MAX_20_MBPS'
	MaximumBitrate ReservationMaximumBitrate
	// Channel class, e.g. 'STANDARD'
	ChannelClass ChannelClass
	// Resource type, 'INPUT', 'OUTPUT', 'MULTIPLEX', or 'CHANNEL'
	ResourceType ReservationResourceType
	// Video quality, e.g. 'STANDARD' (Outputs only)
	VideoQuality ReservationVideoQuality
}

// Rtmp Caption Info Destination Settings
type RtmpCaptionInfoDestinationSettings struct {
}

// Rtmp Group Settings
type RtmpGroupSettings struct {
	// Controls behavior when content cache fills up. If remote origin server stalls
	// the RTMP connection and does not accept content fast enough the 'Media Cache'
	// will fill up. When the cache reaches the duration specified by cacheLength the
	// cache will stop accepting new content. If set to disconnectImmediately, the RTMP
	// output will force a disconnect. Clear the media cache, and reconnect after
	// restartDelay seconds. If set to waitForServer, the RTMP output will wait up to 5
	// minutes to allow the origin server to begin accepting data again.
	CacheFullBehavior RtmpCacheFullBehavior
	// Controls the types of data that passes to onCaptionInfo outputs. If set to 'all'
	// then 608 and 708 carried DTVCC data will be passed. If set to
	// 'field1AndField2608' then DTVCC data will be stripped out, but 608 data from
	// both fields will be passed. If set to 'field1608' then only the data carried in
	// 608 from field 1 video will be passed.
	CaptionData RtmpCaptionData
	// If a streaming output fails, number of seconds to wait until a restart is
	// initiated. A value of 0 means never restart.
	RestartDelay *int32
	// Cache length, in seconds, is used to calculate buffer size.
	CacheLength *int32
	// Controls the behavior of this RTMP group if input becomes unavailable.
	//
	//     *
	// emitOutput: Emit a slate until input returns.
	//
	//     * pauseOutput: Stop
	// transmitting data until input returns. This does not close the underlying RTMP
	// connection.
	InputLossAction InputLossActionForRtmpOut
	// Authentication scheme to use when connecting with CDN
	AuthenticationScheme AuthenticationScheme
}

// Rtmp Output Settings
type RtmpOutputSettings struct {
	// Number of retry attempts.
	NumRetries *int32
	// If set to verifyAuthenticity, verify the tls certificate chain to a trusted
	// Certificate Authority (CA). This will cause rtmps outputs with self-signed
	// certificates to fail.
	CertificateMode RtmpOutputCertificateMode
	// Number of seconds to wait before retrying a connection to the Flash Media server
	// if the connection is lost.
	ConnectionRetryInterval *int32
	// The RTMP endpoint excluding the stream name (eg. rtmp://host/appname). For
	// connection to Akamai, a username and password must be supplied. URI fields
	// accept format identifiers.
	Destination *OutputLocationRef
}

// Contains information on a single schedule action.
type ScheduleAction struct {
	// The time for the action to start in the channel.
	ScheduleActionStartSettings *ScheduleActionStartSettings
	// Settings for this schedule action.
	ScheduleActionSettings *ScheduleActionSettings
	// The name of the action, must be unique within the schedule. This name provides
	// the main reference to an action once it is added to the schedule. A name is
	// unique if it is no longer in the schedule. The schedule is automatically cleaned
	// up to remove actions with a start time of more than 1 hour ago (approximately)
	// so at that point a name can be reused.
	ActionName *string
}

// Holds the settings for a single schedule action.
type ScheduleActionSettings struct {
	// Action to pause or unpause one or both channel pipelines
	PauseStateSettings *PauseStateScheduleActionSettings
	// Action to insert SCTE-35 splice_insert message
	Scte35SpliceInsertSettings *Scte35SpliceInsertScheduleActionSettings
	// Action to switch the input
	InputSwitchSettings *InputSwitchScheduleActionSettings
	// Action to deactivate a static image overlay
	StaticImageDeactivateSettings *StaticImageDeactivateScheduleActionSettings
	// Action to insert SCTE-35 time_signal message
	Scte35TimeSignalSettings *Scte35TimeSignalScheduleActionSettings
	// Action to insert HLS metadata
	HlsTimedMetadataSettings *HlsTimedMetadataScheduleActionSettings
	// Action to insert HLS ID3 segment tagging
	HlsId3SegmentTaggingSettings *HlsId3SegmentTaggingScheduleActionSettings
	// Action to insert SCTE-35 return_to_network message
	Scte35ReturnToNetworkSettings *Scte35ReturnToNetworkScheduleActionSettings
	// Action to activate a static image overlay
	StaticImageActivateSettings *StaticImageActivateScheduleActionSettings
	// Action to prepare an input for a future immediate input switch
	InputPrepareSettings *InputPrepareScheduleActionSettings
}

// Settings to specify when an action should occur. Only one of the options must be
// selected.
type ScheduleActionStartSettings struct {
	// Option for specifying an action that should be applied immediately.
	ImmediateModeScheduleActionStartSettings *ImmediateModeScheduleActionStartSettings
	// Option for specifying an action as relative to another action.
	FollowModeScheduleActionStartSettings *FollowModeScheduleActionStartSettings
	// Option for specifying the start time for an action.
	FixedModeScheduleActionStartSettings *FixedModeScheduleActionStartSettings
}

// Scte20 Plus Embedded Destination Settings
type Scte20PlusEmbeddedDestinationSettings struct {
}

// Scte20 Source Settings
type Scte20SourceSettings struct {
	// If upconvert, 608 data is both passed through via the "608 compatibility bytes"
	// fields of the 708 wrapper as well as translated into 708. 708 data present in
	// the source content will be discarded.
	Convert608To708 Scte20Convert608To708
	// Specifies the 608/708 channel number within the video track from which to
	// extract captions. Unused for passthrough.
	Source608ChannelNumber *int32
}

// Scte27 Destination Settings
type Scte27DestinationSettings struct {
}

// Scte27 Source Settings
type Scte27SourceSettings struct {
	// The pid field is used in conjunction with the caption selector languageCode
	// field as follows:
	//
	//     * Specify PID and Language: Extracts captions from that
	// PID; the language is "informational".
	//
	//     * Specify PID and omit Language:
	// Extracts the specified PID.
	//
	//     * Omit PID and specify Language: Extracts the
	// specified language, whichever PID that happens to be.
	//
	//     * Omit PID and omit
	// Language: Valid only if source is DVB-Sub that is being passed through; all
	// languages will be passed through.
	Pid *int32
}

// Corresponds to SCTE-35 delivery_not_restricted_flag parameter. To declare
// delivery restrictions, include this element and its four "restriction" flags. To
// declare that there are no restrictions, omit this element.
type Scte35DeliveryRestrictions struct {
	// Corresponds to SCTE-35 no_regional_blackout_flag parameter.
	NoRegionalBlackoutFlag Scte35NoRegionalBlackoutFlag
	// Corresponds to SCTE-35 web_delivery_allowed_flag parameter.
	WebDeliveryAllowedFlag Scte35WebDeliveryAllowedFlag
	// Corresponds to SCTE-35 archive_allowed_flag.
	ArchiveAllowedFlag Scte35ArchiveAllowedFlag
	// Corresponds to SCTE-35 device_restrictions parameter.
	DeviceRestrictions Scte35DeviceRestrictions
}

// Holds one set of SCTE-35 Descriptor Settings.
type Scte35Descriptor struct {
	// SCTE-35 Descriptor Settings.
	Scte35DescriptorSettings *Scte35DescriptorSettings
}

// SCTE-35 Descriptor settings.
type Scte35DescriptorSettings struct {
	// SCTE-35 Segmentation Descriptor.
	SegmentationDescriptorScte35DescriptorSettings *Scte35SegmentationDescriptor
}

// Settings for a SCTE-35 return_to_network message.
type Scte35ReturnToNetworkScheduleActionSettings struct {
	// The splice_event_id for the SCTE-35 splice_insert, as defined in SCTE-35.
	SpliceEventId *int64
}

// Corresponds to SCTE-35 segmentation_descriptor.
type Scte35SegmentationDescriptor struct {
	// Corresponds to SCTE-35 segment_num. A value that is valid for the specified
	// segmentation_type_id.
	SegmentNum *int32
	// Holds the four SCTE-35 delivery restriction parameters.
	DeliveryRestrictions *Scte35DeliveryRestrictions
	// Corresponds to SCTE-35 segmentation_type_id. One of the segmentation_type_id
	// values listed in the SCTE-35 specification. On the console, enter the ID in
	// decimal (for example, "52"). In the CLI, API, or an SDK, enter the ID in hex
	// (for example, "0x34") or decimal (for example, "52").
	SegmentationTypeId *int32
	// Corresponds to SCTE-35 sub_segments_expected. A value that is valid for the
	// specified segmentation_type_id.
	SubSegmentsExpected *int32
	// Corresponds to SCTE-35 segmentation_upid_type. On the console, enter one of the
	// types listed in the SCTE-35 specification, converted to a decimal. For example,
	// "0x0C" hex from the specification is "12" in decimal. In the CLI, API, or an
	// SDK, enter one of the types listed in the SCTE-35 specification, in either hex
	// (for example, "0x0C" ) or in decimal (for example, "12").
	SegmentationUpidType *int32
	// Corresponds to SCTE-35 segments_expected. A value that is valid for the
	// specified segmentation_type_id.
	SegmentsExpected *int32
	// Corresponds to SCTE-35 sub_segment_num. A value that is valid for the specified
	// segmentation_type_id.
	SubSegmentNum *int32
	// Corresponds to SCTE-35 segmentation_event_cancel_indicator.
	SegmentationCancelIndicator Scte35SegmentationCancelIndicator
	// Corresponds to SCTE-35 segmentation_upid. Enter a string containing the
	// hexadecimal representation of the characters that make up the SCTE-35
	// segmentation_upid value. Must contain an even number of hex characters. Do not
	// include spaces between each hex pair. For example, the ASCII "ADS Information"
	// becomes hex "41445320496e666f726d6174696f6e.
	SegmentationUpid *string
	// Corresponds to SCTE-35 segmentation_event_id.
	SegmentationEventId *int64
	// Corresponds to SCTE-35 segmentation_duration. Optional. The duration for the
	// time_signal, in 90 KHz ticks. To convert seconds to ticks, multiple the seconds
	// by 90,000. Enter time in 90 KHz clock ticks. If you do not enter a duration, the
	// time_signal will continue until you insert a cancellation message.
	SegmentationDuration *int64
}

// Scte35 Splice Insert
type Scte35SpliceInsert struct {
	// When set to ignore, Segment Descriptors with noRegionalBlackoutFlag set to 0
	// will no longer trigger blackouts or Ad Avail slates
	NoRegionalBlackoutFlag Scte35SpliceInsertNoRegionalBlackoutBehavior
	// When specified, this offset (in milliseconds) is added to the input Ad Avail PTS
	// time. This only applies to embedded SCTE 104/35 messages and does not apply to
	// OOB messages.
	AdAvailOffset *int32
	// When set to ignore, Segment Descriptors with webDeliveryAllowedFlag set to 0
	// will no longer trigger blackouts or Ad Avail slates
	WebDeliveryAllowedFlag Scte35SpliceInsertWebDeliveryAllowedBehavior
}

// Settings for a SCTE-35 splice_insert message.
type Scte35SpliceInsertScheduleActionSettings struct {
	// Optional, the duration for the splice_insert, in 90 KHz ticks. To convert
	// seconds to ticks, multiple the seconds by 90,000. If you enter a duration, there
	// is an expectation that the downstream system can read the duration and cue in at
	// that time. If you do not enter a duration, the splice_insert will continue
	// indefinitely and there is an expectation that you will enter a return_to_network
	// to end the splice_insert at the appropriate time.
	Duration *int64
	// The splice_event_id for the SCTE-35 splice_insert, as defined in SCTE-35.
	SpliceEventId *int64
}

// Scte35 Time Signal Apos
type Scte35TimeSignalApos struct {
	// When set to ignore, Segment Descriptors with webDeliveryAllowedFlag set to 0
	// will no longer trigger blackouts or Ad Avail slates
	WebDeliveryAllowedFlag Scte35AposWebDeliveryAllowedBehavior
	// When set to ignore, Segment Descriptors with noRegionalBlackoutFlag set to 0
	// will no longer trigger blackouts or Ad Avail slates
	NoRegionalBlackoutFlag Scte35AposNoRegionalBlackoutBehavior
	// When specified, this offset (in milliseconds) is added to the input Ad Avail PTS
	// time. This only applies to embedded SCTE 104/35 messages and does not apply to
	// OOB messages.
	AdAvailOffset *int32
}

// Settings for a SCTE-35 time_signal.
type Scte35TimeSignalScheduleActionSettings struct {
	// The list of SCTE-35 descriptors accompanying the SCTE-35 time_signal.
	Scte35Descriptors []*Scte35Descriptor
}

// Smpte Tt Destination Settings
type SmpteTtDestinationSettings struct {
}

// Standard Hls Settings
type StandardHlsSettings struct {
	// List all the audio groups that are used with the video output stream. Input all
	// the audio GROUP-IDs that are associated to the video, separate by ','.
	AudioRenditionSets *string
	// Settings information for the .m3u8 container
	M3u8Settings *M3u8Settings
}

// Settings to identify the start of the clip.
type StartTimecode struct {
	// The timecode for the frame where you want to start the clip. Optional; if not
	// specified, the clip starts at first frame in the file. Enter the timecode as
	// HH:MM:SS:FF or HH:MM:SS;FF.
	Timecode *string
}

// Settings for the action to activate a static image.
type StaticImageActivateScheduleActionSettings struct {
	// The time in milliseconds for the image to fade in. The fade-in starts at the
	// start time of the overlay. Default is 0 (no fade-in).
	FadeIn *int32
	// Opacity of image where 0 is transparent and 100 is fully opaque. Default is 100.
	Opacity *int32
	// Applies only if a duration is specified. The time in milliseconds for the image
	// to fade out. The fade-out starts when the duration time is hit, so it
	// effectively extends the duration. Default is 0 (no fade-out).
	FadeOut *int32
	// The height of the image when inserted into the video, in pixels. The overlay
	// will be scaled up or down to the specified height. Leave blank to use the native
	// height of the overlay.
	Height *int32
	// Placement of the top edge of the overlay relative to the top edge of the video
	// frame, in pixels. 0 (the default) is the top edge of the frame. If the placement
	// causes the overlay to extend beyond the bottom edge of the underlying video,
	// then the overlay is cropped on the bottom.
	ImageY *int32
	// Placement of the left edge of the overlay relative to the left edge of the video
	// frame, in pixels. 0 (the default) is the left edge of the frame. If the
	// placement causes the overlay to extend beyond the right edge of the underlying
	// video, then the overlay is cropped on the right.
	ImageX *int32
	// The number of the layer, 0 to 7. There are 8 layers that can be overlaid on the
	// video, each layer with a different image. The layers are in Z order, which means
	// that overlays with higher values of layer are inserted on top of overlays with
	// lower values of layer. Default is 0.
	Layer *int32
	// The duration in milliseconds for the image to remain on the video. If omitted or
	// set to 0 the duration is unlimited and the image will remain until it is
	// explicitly deactivated.
	Duration *int32
	// The location and filename of the image file to overlay on the video. The file
	// must be a 32-bit BMP, PNG, or TGA file, and must not be larger (in pixels) than
	// the input video.
	Image *InputLocation
	// The width of the image when inserted into the video, in pixels. The overlay will
	// be scaled up or down to the specified width. Leave blank to use the native width
	// of the overlay.
	Width *int32
}

// Settings for the action to deactivate the image in a specific layer.
type StaticImageDeactivateScheduleActionSettings struct {
	// The image overlay layer to deactivate, 0 to 7. Default is 0.
	Layer *int32
	// The time in milliseconds for the image to fade out. Default is 0 (no fade-out).
	FadeOut *int32
}

// Static Key Settings
type StaticKeySettings struct {
	// Static key value as a 32 character hexadecimal string.
	StaticKeyValue *string
	// The URL of the license server used for protecting content.
	KeyProviderServer *InputLocation
}

// Settings to identify the end of the clip.
type StopTimecode struct {
	// If you specify a StopTimecode in an input (in order to clip the file), you can
	// specify if you want the clip to exclude (the default) or include the frame
	// specified by the timecode.
	LastFrameClippingBehavior LastFrameClippingBehavior
	// The timecode for the frame where you want to stop the clip. Optional; if not
	// specified, the clip continues to the end of the file. Enter the timecode as
	// HH:MM:SS:FF or HH:MM:SS;FF.
	Timecode *string
}

// Teletext Destination Settings
type TeletextDestinationSettings struct {
}

// Teletext Source Settings
type TeletextSourceSettings struct {
	// Specifies the teletext page number within the data stream from which to extract
	// captions. Range of 0x100 (256) to 0x8FF (2303). Unused for passthrough. Should
	// be specified as a hexadecimal string with no "0x" prefix.
	PageNumber *string
}

// Temporal Filter Settings
type TemporalFilterSettings struct {
	// If you enable this filter, the results are the following:
	//
	//     * If the source
	// content is noisy (it contains excessive digital artifacts), the filter cleans up
	// the source.
	//
	//     * If the source content is already clean, the filter tends to
	// decrease the bitrate, especially when the rate control mode is QVBR.
	PostFilterSharpening TemporalFilterPostFilterSharpening
	// Choose a filter strength. We recommend a strength of 1 or 2. A higher strength
	// might take out good information, resulting in an image that is overly soft.
	Strength TemporalFilterStrength
}

// Timecode Config
type TimecodeConfig struct {
	// Threshold in frames beyond which output timecode is resynchronized to the input
	// timecode. Discrepancies below this threshold are permitted to avoid unnecessary
	// discontinuities in the output timecode. No timecode sync when this is not
	// specified.
	SyncThreshold *int32
	// Identifies the source for the timecode that will be associated with the events
	// outputs. -Embedded (embedded): Initialize the output timecode with timecode from
	// the the source. If no embedded timecode is detected in the source, the system
	// falls back to using "Start at 0" (zerobased). -System Clock (systemclock): Use
	// the UTC time. -Start at 0 (zerobased): The time of the first frame of the event
	// will be 00:00:00:00.
	Source TimecodeConfigSource
}

// Ttml Destination Settings
type TtmlDestinationSettings struct {
	// When set to passthrough, passes through style and position information from a
	// TTML-like input source (TTML, SMPTE-TT, CFF-TT) to the CFF-TT output or TTML
	// output.
	StyleControl TtmlDestinationStyleControl
}

// Udp Container Settings
type UdpContainerSettings struct {
	// M2ts Settings
	M2tsSettings *M2tsSettings
}

// Udp Group Settings
type UdpGroupSettings struct {
	// Specifies behavior of last resort when input video is lost, and no more backup
	// inputs are available. When dropTs is selected the entire transport stream will
	// stop being emitted. When dropProgram is selected the program can be dropped from
	// the transport stream (and replaced with null packets to meet the TS bitrate
	// requirement). Or, when emitProgram is chosen the transport stream will continue
	// to be produced normally with repeat frames, black frames, or slate frames
	// substituted for the absent input video.
	InputLossAction InputLossActionForUdpOut
	// Indicates ID3 frame that has the timecode.
	TimedMetadataId3Frame UdpTimedMetadataId3Frame
	// Timed Metadata interval in seconds.
	TimedMetadataId3Period *int32
}

// Udp Output Settings
type UdpOutputSettings struct {
	// Destination address and port number for RTP or UDP packets. Can be unicast or
	// multicast RTP or UDP (eg. rtp://239.10.10.10:5001 or udp://10.100.100.100:5002).
	Destination *OutputLocationRef
	// Udp Container Settings
	ContainerSettings *UdpContainerSettings
	// UDP output buffering in milliseconds. Larger values increase latency through the
	// transcoder but simultaneously assist the transcoder in maintaining a constant,
	// low-jitter UDP/RTP output while accommodating clock recovery, input switching,
	// input disruptions, picture reordering, etc.
	BufferMsec *int32
	// Settings for enabling and adjusting Forward Error Correction on UDP outputs.
	FecOutputSettings *FecOutputSettings
}

// Placeholder documentation for ValidationError
type ValidationError struct {
	// Path to the source of the error.
	ElementPath *string
	// The error message.
	ErrorMessage *string
}

// Video Codec Settings
type VideoCodecSettings struct {
	// Frame Capture Settings
	FrameCaptureSettings *FrameCaptureSettings
	// H265 Settings
	H265Settings *H265Settings
	// H264 Settings
	H264Settings *H264Settings
}

// Video settings for this stream.
type VideoDescription struct {
	// Output video height, in pixels. Must be an even number. For most codecs, you can
	// leave this field and width blank in order to use the height and width
	// (resolution) from the source. Note, however, that leaving blank is not
	// recommended. For the Frame Capture codec, height and width are required.
	Height *int32
	// Output video width, in pixels. Must be an even number. For most codecs, you can
	// leave this field and height blank in order to use the height and width
	// (resolution) from the source. Note, however, that leaving blank is not
	// recommended. For the Frame Capture codec, height and width are required.
	Width *int32
	// Indicates how to respond to the AFD values in the input stream. RESPOND causes
	// input video to be clipped, depending on the AFD value, input display aspect
	// ratio, and output display aspect ratio, and (except for FRAME_CAPTURE codec)
	// includes the values in the output. PASSTHROUGH (does not apply to FRAME_CAPTURE
	// codec) ignores the AFD values and includes the values in the output, so input
	// video is not clipped. NONE ignores the AFD values and does not include the
	// values through to the output, so input video is not clipped.
	RespondToAfd VideoDescriptionRespondToAfd
	// STRETCH_TO_OUTPUT configures the output position to stretch the video to the
	// specified output resolution (height and width). This option will override any
	// position value. DEFAULT may insert black boxes (pillar boxes or letter boxes)
	// around the video to provide the specified output resolution.
	ScalingBehavior VideoDescriptionScalingBehavior
	// The name of this VideoDescription. Outputs will use this name to uniquely
	// identify this Description. Description names should be unique within this Live
	// Event.
	Name *string
	// Changes the strength of the anti-alias filter used for scaling. 0 is the softest
	// setting, 100 is the sharpest. A setting of 50 is recommended for most content.
	Sharpness *int32
	// Video codec settings.
	CodecSettings *VideoCodecSettings
}

// Specifies a particular video stream within an input source. An input may have
// only a single video selector.
type VideoSelector struct {
	// Specifies the color space of an input. This setting works in tandem with
	// colorSpaceUsage and a video description's colorSpaceSettingsChoice to determine
	// if any conversion will be performed.
	ColorSpace VideoSelectorColorSpace
	// The video selector settings.
	SelectorSettings *VideoSelectorSettings
	// Applies only if colorSpace is a value other than follow. This field controls how
	// the value in the colorSpace field will be used. fallback means that when the
	// input does include color space data, that data will be used, but when the input
	// has no color space data, the value in colorSpace will be used. Choose fallback
	// if your input is sometimes missing color space data, but when it does have color
	// space data, that data is correct. force means to always use the value in
	// colorSpace. Choose force if your input usually has no color space data or might
	// have unreliable color space data.
	ColorSpaceUsage VideoSelectorColorSpaceUsage
}

// Video Selector Pid
type VideoSelectorPid struct {
	// Selects a specific PID from within a video source.
	Pid *int32
}

// Video Selector Program Id
type VideoSelectorProgramId struct {
	// Selects a specific program from within a multi-program transport stream. If the
	// program doesn't exist, the first program within the transport stream will be
	// selected by default.
	ProgramId *int32
}

// Video Selector Settings
type VideoSelectorSettings struct {
	// Video Selector Pid
	VideoSelectorPid *VideoSelectorPid
	// Video Selector Program Id
	VideoSelectorProgramId *VideoSelectorProgramId
}

// Webvtt Destination Settings
type WebvttDestinationSettings struct {
}
