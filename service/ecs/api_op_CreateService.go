// Code generated by private/model/cli/gen-api/main.go. DO NOT EDIT.

package ecs

import (
	"context"

	"github.com/aws/aws-sdk-go-v2/aws"
	"github.com/aws/aws-sdk-go-v2/service/ecs/types"
)

const opCreateService = "CreateService"

// CreateServiceRequest returns a request value for making API operation for
// Amazon EC2 Container Service.
//
// Runs and maintains a desired number of tasks from a specified task definition.
// If the number of tasks running in a service drops below the desiredCount,
// Amazon ECS runs another copy of the task in the specified cluster. To update
// an existing service, see UpdateService.
//
// In addition to maintaining the desired count of tasks in your service, you
// can optionally run your service behind one or more load balancers. The load
// balancers distribute traffic across the tasks that are associated with the
// service. For more information, see Service Load Balancing (https://docs.aws.amazon.com/AmazonECS/latest/developerguide/service-load-balancing.html)
// in the Amazon Elastic Container Service Developer Guide.
//
// Tasks for services that do not use a load balancer are considered healthy
// if they're in the RUNNING state. Tasks for services that do use a load balancer
// are considered healthy if they're in the RUNNING state and the container
// instance that they're hosted on is reported as healthy by the load balancer.
//
// There are two service scheduler strategies available:
//
//    * REPLICA - The replica scheduling strategy places and maintains the desired
//    number of tasks across your cluster. By default, the service scheduler
//    spreads tasks across Availability Zones. You can use task placement strategies
//    and constraints to customize task placement decisions. For more information,
//    see Service Scheduler Concepts (https://docs.aws.amazon.com/AmazonECS/latest/developerguide/ecs_services.html)
//    in the Amazon Elastic Container Service Developer Guide.
//
//    * DAEMON - The daemon scheduling strategy deploys exactly one task on
//    each active container instance that meets all of the task placement constraints
//    that you specify in your cluster. When using this strategy, you don't
//    need to specify a desired number of tasks, a task placement strategy,
//    or use Service Auto Scaling policies. For more information, see Service
//    Scheduler Concepts (https://docs.aws.amazon.com/AmazonECS/latest/developerguide/ecs_services.html)
//    in the Amazon Elastic Container Service Developer Guide.
//
// You can optionally specify a deployment configuration for your service. The
// deployment is triggered by changing properties, such as the task definition
// or the desired count of a service, with an UpdateService operation. The default
// value for a replica service for minimumHealthyPercent is 100%. The default
// value for a daemon service for minimumHealthyPercent is 0%.
//
// If a service is using the ECS deployment controller, the minimum healthy
// percent represents a lower limit on the number of tasks in a service that
// must remain in the RUNNING state during a deployment, as a percentage of
// the desired number of tasks (rounded up to the nearest integer), and while
// any container instances are in the DRAINING state if the service contains
// tasks using the EC2 launch type. This parameter enables you to deploy without
// using additional cluster capacity. For example, if your service has a desired
// number of four tasks and a minimum healthy percent of 50%, the scheduler
// might stop two existing tasks to free up cluster capacity before starting
// two new tasks. Tasks for services that do not use a load balancer are considered
// healthy if they're in the RUNNING state. Tasks for services that do use a
// load balancer are considered healthy if they're in the RUNNING state and
// they're reported as healthy by the load balancer. The default value for minimum
// healthy percent is 100%.
//
// If a service is using the ECS deployment controller, the maximum percent
// parameter represents an upper limit on the number of tasks in a service that
// are allowed in the RUNNING or PENDING state during a deployment, as a percentage
// of the desired number of tasks (rounded down to the nearest integer), and
// while any container instances are in the DRAINING state if the service contains
// tasks using the EC2 launch type. This parameter enables you to define the
// deployment batch size. For example, if your service has a desired number
// of four tasks and a maximum percent value of 200%, the scheduler may start
// four new tasks before stopping the four older tasks (provided that the cluster
// resources required to do this are available). The default value for maximum
// percent is 200%.
//
// If a service is using either the CODE_DEPLOY or EXTERNAL deployment controller
// types and tasks that use the EC2 launch type, the minimum healthy percent
// and maximum percent values are used only to define the lower and upper limit
// on the number of the tasks in the service that remain in the RUNNING state
// while the container instances are in the DRAINING state. If the tasks in
// the service use the Fargate launch type, the minimum healthy percent and
// maximum percent values aren't used, although they're currently visible when
// describing your service.
//
// When creating a service that uses the EXTERNAL deployment controller, you
// can specify only parameters that aren't controlled at the task set level.
// The only required parameter is the service name. You control your services
// using the CreateTaskSet operation. For more information, see Amazon ECS Deployment
// Types (https://docs.aws.amazon.com/AmazonECS/latest/developerguide/deployment-types.html)
// in the Amazon Elastic Container Service Developer Guide.
//
// When the service scheduler launches new tasks, it determines task placement
// in your cluster using the following logic:
//
//    * Determine which of the container instances in your cluster can support
//    your service's task definition (for example, they have the required CPU,
//    memory, ports, and container instance attributes).
//
//    * By default, the service scheduler attempts to balance tasks across Availability
//    Zones in this manner (although you can choose a different placement strategy)
//    with the placementStrategy parameter): Sort the valid container instances,
//    giving priority to instances that have the fewest number of running tasks
//    for this service in their respective Availability Zone. For example, if
//    zone A has one running service task and zones B and C each have zero,
//    valid container instances in either zone B or C are considered optimal
//    for placement. Place the new service task on a valid container instance
//    in an optimal Availability Zone (based on the previous steps), favoring
//    container instances with the fewest number of running tasks for this service.
//
//    // Example sending a request using CreateServiceRequest.
//    req := client.CreateServiceRequest(params)
//    resp, err := req.Send(context.TODO())
//    if err == nil {
//        fmt.Println(resp)
//    }
//
// Please also see https://docs.aws.amazon.com/goto/WebAPI/ecs-2014-11-13/CreateService
func (c *Client) CreateServiceRequest(input *types.CreateServiceInput) CreateServiceRequest {
	op := &aws.Operation{
		Name:       opCreateService,
		HTTPMethod: "POST",
		HTTPPath:   "/",
	}

	if input == nil {
		input = &types.CreateServiceInput{}
	}

	req := c.newRequest(op, input, &types.CreateServiceOutput{})
	return CreateServiceRequest{Request: req, Input: input, Copy: c.CreateServiceRequest}
}

// CreateServiceRequest is the request type for the
// CreateService API operation.
type CreateServiceRequest struct {
	*aws.Request
	Input *types.CreateServiceInput
	Copy  func(*types.CreateServiceInput) CreateServiceRequest
}

// Send marshals and sends the CreateService API request.
func (r CreateServiceRequest) Send(ctx context.Context) (*CreateServiceResponse, error) {
	r.Request.SetContext(ctx)
	err := r.Request.Send()
	if err != nil {
		return nil, err
	}

	resp := &CreateServiceResponse{
		CreateServiceOutput: r.Request.Data.(*types.CreateServiceOutput),
		response:            &aws.Response{Request: r.Request},
	}

	return resp, nil
}

// CreateServiceResponse is the response type for the
// CreateService API operation.
type CreateServiceResponse struct {
	*types.CreateServiceOutput

	response *aws.Response
}

// SDKResponseMetdata returns the response metadata for the
// CreateService request.
func (r *CreateServiceResponse) SDKResponseMetdata() *aws.Response {
	return r.response
}
