// Code generated by smithy-go-codegen DO NOT EDIT.

package types

import (
	"time"
)

// Describes hints for the buffering to perform before delivering data to the
// destination. These options are treated as hints, and therefore Kinesis Data
// Firehose might choose to use different values when it is optimal. The SizeInMBs
// and IntervalInSeconds parameters are optional. However, if specify a value for
// one of them, you must also provide a value for the other.
type BufferingHints struct {
	// Buffer incoming data to the specified size, in MiBs, before delivering it to the
	// destination. The default value is 5. This parameter is optional but if you
	// specify a value for it, you must also specify a value for IntervalInSeconds, and
	// vice versa. We recommend setting this parameter to a value greater than the
	// amount of data you typically ingest into the delivery stream in 10 seconds. For
	// example, if you typically ingest data at 1 MiB/sec, the value should be 10 MiB
	// or higher.
	SizeInMBs *int32
	// Buffer incoming data for the specified period of time, in seconds, before
	// delivering it to the destination. The default value is 300. This parameter is
	// optional but if you specify a value for it, you must also specify a value for
	// SizeInMBs, and vice versa.
	IntervalInSeconds *int32
}

// Describes the Amazon CloudWatch logging options for your delivery stream.
type CloudWatchLoggingOptions struct {
	// The CloudWatch log stream name for logging. This value is required if CloudWatch
	// logging is enabled.
	LogStreamName *string
	// Enables or disables CloudWatch logging.
	Enabled *bool
	// The CloudWatch group name for logging. This value is required if CloudWatch
	// logging is enabled.
	LogGroupName *string
}

// Describes a COPY command for Amazon Redshift.
type CopyCommand struct {
	// The name of the target table. The table must already exist in the database.
	DataTableName *string
	// Optional parameters to use with the Amazon Redshift COPY command. For more
	// information, see the "Optional Parameters" section of Amazon Redshift COPY
	// command (https://docs.aws.amazon.com/redshift/latest/dg/r_COPY.html). Some
	// possible examples that would apply to Kinesis Data Firehose are as follows:
	// delimiter '\t' lzop; - fields are delimited with "\t" (TAB character) and
	// compressed using lzop. delimiter '|' - fields are delimited with "|" (this is
	// the default delimiter). delimiter '|' escape - the delimiter should be escaped.
	// fixedwidth 'venueid:3,venuename:25,venuecity:12,venuestate:2,venueseats:6' -
	// fields are fixed width in the source, with each width specified after every
	// column in the table. JSON 's3://mybucket/jsonpaths.txt' - data is in JSON
	// format, and the path specified is the format of the data. For more examples, see
	// Amazon Redshift COPY command examples
	// (https://docs.aws.amazon.com/redshift/latest/dg/r_COPY_command_examples.html).
	CopyOptions *string
	// A comma-separated list of column names.
	DataTableColumns *string
}

// Specifies that you want Kinesis Data Firehose to convert data from the JSON
// format to the Parquet or ORC format before writing it to Amazon S3. Kinesis Data
// Firehose uses the serializer and deserializer that you specify, in addition to
// the column information from the AWS Glue table, to deserialize your input data
// from JSON and then serialize it to the Parquet or ORC format. For more
// information, see Kinesis Data Firehose Record Format Conversion
// (https://docs.aws.amazon.com/firehose/latest/dev/record-format-conversion.html).
type DataFormatConversionConfiguration struct {
	// Specifies the serializer that you want Kinesis Data Firehose to use to convert
	// the format of your data to the Parquet or ORC format. This parameter is required
	// if Enabled is set to true.
	OutputFormatConfiguration *OutputFormatConfiguration
	// Defaults to true. Set it to false if you want to disable format conversion while
	// preserving the configuration details.
	Enabled *bool
	// Specifies the deserializer that you want Kinesis Data Firehose to use to convert
	// the format of your data from JSON. This parameter is required if Enabled is set
	// to true.
	InputFormatConfiguration *InputFormatConfiguration
	// Specifies the AWS Glue Data Catalog table that contains the column information.
	// This parameter is required if Enabled is set to true.
	SchemaConfiguration *SchemaConfiguration
}

// Contains information about a delivery stream.
type DeliveryStreamDescription struct {
	// The name of the delivery stream.
	DeliveryStreamName *string
	// The destinations.
	Destinations []*DestinationDescription
	// The Amazon Resource Name (ARN) of the delivery stream. For more information, see
	// Amazon Resource Names (ARNs) and AWS Service Namespaces
	// (https://docs.aws.amazon.com/general/latest/gr/aws-arns-and-namespaces.html).
	DeliveryStreamARN *string
	// The delivery stream type. This can be one of the following values:
	//
	//     *
	// DirectPut: Provider applications access the delivery stream directly.
	//
	//     *
	// KinesisStreamAsSource: The delivery stream uses a Kinesis data stream as a
	// source.
	DeliveryStreamType DeliveryStreamType
	// Each time the destination is updated for a delivery stream, the version ID is
	// changed, and the current version ID is required when updating the destination.
	// This is so that the service knows it is applying the changes to the correct
	// version of the delivery stream.
	VersionId *string
	// The status of the delivery stream. If the status of a delivery stream is
	// CREATING_FAILED, this status doesn't change, and you can't invoke
	// CreateDeliveryStream again on it. However, you can invoke the
	// DeleteDeliveryStream () operation to delete it.
	DeliveryStreamStatus DeliveryStreamStatus
	// The date and time that the delivery stream was created.
	CreateTimestamp *time.Time
	// Indicates whether there are more destinations available to list.
	HasMoreDestinations *bool
	// Provides details in case one of the following operations fails due to an error
	// related to KMS: CreateDeliveryStream (), DeleteDeliveryStream (),
	// StartDeliveryStreamEncryption (), StopDeliveryStreamEncryption ().
	FailureDescription *FailureDescription
	// Indicates the server-side encryption (SSE) status for the delivery stream.
	DeliveryStreamEncryptionConfiguration *DeliveryStreamEncryptionConfiguration
	// The date and time that the delivery stream was last updated.
	LastUpdateTimestamp *time.Time
	// If the DeliveryStreamType parameter is KinesisStreamAsSource, a
	// SourceDescription () object describing the source Kinesis data stream.
	Source *SourceDescription
}

// Contains information about the server-side encryption (SSE) status for the
// delivery stream, the type customer master key (CMK) in use, if any, and the ARN
// of the CMK. You can get DeliveryStreamEncryptionConfiguration by invoking the
// DescribeDeliveryStream () operation.
type DeliveryStreamEncryptionConfiguration struct {
	// Provides details in case one of the following operations fails due to an error
	// related to KMS: CreateDeliveryStream (), DeleteDeliveryStream (),
	// StartDeliveryStreamEncryption (), StopDeliveryStreamEncryption ().
	FailureDescription *FailureDescription
	// If KeyType is CUSTOMER_MANAGED_CMK, this field contains the ARN of the customer
	// managed CMK. If KeyType is AWS_OWNED_CMK, DeliveryStreamEncryptionConfiguration
	// doesn't contain a value for KeyARN.
	KeyARN *string
	// Indicates the type of customer master key (CMK) that is used for encryption. The
	// default setting is AWS_OWNED_CMK. For more information about CMKs, see Customer
	// Master Keys (CMKs)
	// (https://docs.aws.amazon.com/kms/latest/developerguide/concepts.html#master_keys).
	KeyType KeyType
	// This is the server-side encryption (SSE) status for the delivery stream. For a
	// full description of the different values of this status, see
	// StartDeliveryStreamEncryption () and StopDeliveryStreamEncryption (). If this
	// status is ENABLING_FAILED or DISABLING_FAILED, it is the status of the most
	// recent attempt to enable or disable SSE, respectively.
	Status DeliveryStreamEncryptionStatus
}

// Specifies the type and Amazon Resource Name (ARN) of the CMK to use for
// Server-Side Encryption (SSE).
type DeliveryStreamEncryptionConfigurationInput struct {
	// Indicates the type of customer master key (CMK) to use for encryption. The
	// default setting is AWS_OWNED_CMK. For more information about CMKs, see Customer
	// Master Keys (CMKs)
	// (https://docs.aws.amazon.com/kms/latest/developerguide/concepts.html#master_keys).
	// When you invoke CreateDeliveryStream () or StartDeliveryStreamEncryption () with
	// KeyType set to CUSTOMER_MANAGED_CMK, Kinesis Data Firehose invokes the Amazon
	// KMS operation CreateGrant
	// (https://docs.aws.amazon.com/kms/latest/APIReference/API_CreateGrant.html) to
	// create a grant that allows the Kinesis Data Firehose service to use the customer
	// managed CMK to perform encryption and decryption. Kinesis Data Firehose manages
	// that grant. When you invoke StartDeliveryStreamEncryption () to change the CMK
	// for a delivery stream that is encrypted with a customer managed CMK, Kinesis
	// Data Firehose schedules the grant it had on the old CMK for retirement. You can
	// use a CMK of type CUSTOMER_MANAGED_CMK to encrypt up to 500 delivery streams. If
	// a CreateDeliveryStream () or StartDeliveryStreamEncryption () operation exceeds
	// this limit, Kinesis Data Firehose throws a LimitExceededException. To encrypt
	// your delivery stream, use symmetric CMKs. Kinesis Data Firehose doesn't support
	// asymmetric CMKs. For information about symmetric and asymmetric CMKs, see About
	// Symmetric and Asymmetric CMKs
	// (https://docs.aws.amazon.com/kms/latest/developerguide/symm-asymm-concepts.html)
	// in the AWS Key Management Service developer guide.
	KeyType KeyType
	// If you set KeyType to CUSTOMER_MANAGED_CMK, you must specify the Amazon Resource
	// Name (ARN) of the CMK. If you set KeyType to AWS_OWNED_CMK, Kinesis Data
	// Firehose uses a service-account CMK.
	KeyARN *string
}

// The deserializer you want Kinesis Data Firehose to use for converting the input
// data from JSON. Kinesis Data Firehose then serializes the data to its final
// format using the Serializer (). Kinesis Data Firehose supports two types of
// deserializers: the Apache Hive JSON SerDe
// (https://cwiki.apache.org/confluence/display/Hive/LanguageManual+DDL#LanguageManualDDL-JSON)
// and the OpenX JSON SerDe (https://github.com/rcongiu/Hive-JSON-Serde).
type Deserializer struct {
	// The native Hive / HCatalog JsonSerDe. Used by Kinesis Data Firehose for
	// deserializing data, which means converting it from the JSON format in
	// preparation for serializing it to the Parquet or ORC format. This is one of two
	// deserializers you can choose, depending on which one offers the functionality
	// you need. The other option is the OpenX SerDe.
	HiveJsonSerDe *HiveJsonSerDe
	// The OpenX SerDe. Used by Kinesis Data Firehose for deserializing data, which
	// means converting it from the JSON format in preparation for serializing it to
	// the Parquet or ORC format. This is one of two deserializers you can choose,
	// depending on which one offers the functionality you need. The other option is
	// the native Hive / HCatalog JsonSerDe.
	OpenXJsonSerDe *OpenXJsonSerDe
}

// Describes the destination for a delivery stream.
type DestinationDescription struct {
	// The destination in Amazon Redshift.
	RedshiftDestinationDescription *RedshiftDestinationDescription
	// The ID of the destination.
	DestinationId *string
	// Describes the specified HTTP endpoint destination.
	HttpEndpointDestinationDescription *HttpEndpointDestinationDescription
	// The destination in Amazon ES.
	ElasticsearchDestinationDescription *ElasticsearchDestinationDescription
	// The destination in Splunk.
	SplunkDestinationDescription *SplunkDestinationDescription
	// [Deprecated] The destination in Amazon S3.
	S3DestinationDescription *S3DestinationDescription
	// The destination in Amazon S3.
	ExtendedS3DestinationDescription *ExtendedS3DestinationDescription
}

// Describes the buffering to perform before delivering data to the Amazon ES
// destination.
type ElasticsearchBufferingHints struct {
	// Buffer incoming data to the specified size, in MBs, before delivering it to the
	// destination. The default value is 5. We recommend setting this parameter to a
	// value greater than the amount of data you typically ingest into the delivery
	// stream in 10 seconds. For example, if you typically ingest data at 1 MB/sec, the
	// value should be 10 MB or higher.
	SizeInMBs *int32
	// Buffer incoming data for the specified period of time, in seconds, before
	// delivering it to the destination. The default value is 300 (5 minutes).
	IntervalInSeconds *int32
}

// Describes the configuration of a destination in Amazon ES.
type ElasticsearchDestinationConfiguration struct {
	// The Elasticsearch index name.
	IndexName *string
	// The endpoint to use when communicating with the cluster. Specify either this
	// ClusterEndpoint or the DomainARN field.
	ClusterEndpoint *string
	// The configuration for the backup Amazon S3 location.
	S3Configuration *S3DestinationConfiguration
	// The buffering options. If no value is specified, the default values for
	// ElasticsearchBufferingHints are used.
	BufferingHints *ElasticsearchBufferingHints
	// The details of the VPC of the Amazon ES destination.
	VpcConfiguration *VpcConfiguration
	// The retry behavior in case Kinesis Data Firehose is unable to deliver documents
	// to Amazon ES. The default value is 300 (5 minutes).
	RetryOptions *ElasticsearchRetryOptions
	// The Amazon CloudWatch logging options for your delivery stream.
	CloudWatchLoggingOptions *CloudWatchLoggingOptions
	// The Elasticsearch type name. For Elasticsearch 6.x, there can be only one type
	// per index. If you try to specify a new type for an existing index that already
	// has another type, Kinesis Data Firehose returns an error during run time.
	// <p>For Elasticsearch 7.x, don't specify a <code>TypeName</code>.</p>
	TypeName *string
	// The Amazon Resource Name (ARN) of the IAM role to be assumed by Kinesis Data
	// Firehose for calling the Amazon ES Configuration API and for indexing documents.
	// For more information, see Grant Kinesis Data Firehose Access to an Amazon S3
	// Destination
	// (https://docs.aws.amazon.com/firehose/latest/dev/controlling-access.html#using-iam-s3)
	// and Amazon Resource Names (ARNs) and AWS Service Namespaces
	// (https://docs.aws.amazon.com/general/latest/gr/aws-arns-and-namespaces.html).
	RoleARN *string
	// The Elasticsearch index rotation period. Index rotation appends a timestamp to
	// the IndexName to facilitate the expiration of old data. For more information,
	// see Index Rotation for the Amazon ES Destination
	// (https://docs.aws.amazon.com/firehose/latest/dev/basic-deliver.html#es-index-rotation).
	// The default value is OneDay.
	IndexRotationPeriod ElasticsearchIndexRotationPeriod
	// The data processing configuration.
	ProcessingConfiguration *ProcessingConfiguration
	// Defines how documents should be delivered to Amazon S3. When it is set to
	// FailedDocumentsOnly, Kinesis Data Firehose writes any documents that could not
	// be indexed to the configured Amazon S3 destination, with elasticsearch-failed/
	// appended to the key prefix. When set to AllDocuments, Kinesis Data Firehose
	// delivers all incoming records to Amazon S3, and also writes failed documents
	// with elasticsearch-failed/ appended to the prefix. For more information, see
	// Amazon S3 Backup for the Amazon ES Destination
	// (https://docs.aws.amazon.com/firehose/latest/dev/basic-deliver.html#es-s3-backup).
	// Default value is FailedDocumentsOnly. You can't change this backup mode after
	// you create the delivery stream.
	S3BackupMode ElasticsearchS3BackupMode
	// The ARN of the Amazon ES domain. The IAM role must have permissions for
	// DescribeElasticsearchDomain, DescribeElasticsearchDomains, and
	// DescribeElasticsearchDomainConfig after assuming the role specified in RoleARN.
	// For more information, see Amazon Resource Names (ARNs) and AWS Service
	// Namespaces
	// (https://docs.aws.amazon.com/general/latest/gr/aws-arns-and-namespaces.html).
	// <p>Specify either <code>ClusterEndpoint</code> or <code>DomainARN</code>.</p>
	DomainARN *string
}

// The destination description in Amazon ES.
type ElasticsearchDestinationDescription struct {
	// The Amazon CloudWatch logging options.
	CloudWatchLoggingOptions *CloudWatchLoggingOptions
	// The Elasticsearch index name.
	IndexName *string
	// The details of the VPC of the Amazon ES destination.
	VpcConfigurationDescription *VpcConfigurationDescription
	// The data processing configuration.
	ProcessingConfiguration *ProcessingConfiguration
	// The buffering options.
	BufferingHints *ElasticsearchBufferingHints
	// The Amazon S3 backup mode.
	S3BackupMode ElasticsearchS3BackupMode
	// The Elasticsearch index rotation period
	IndexRotationPeriod ElasticsearchIndexRotationPeriod
	// The endpoint to use when communicating with the cluster. Kinesis Data Firehose
	// uses either this ClusterEndpoint or the DomainARN field to send data to Amazon
	// ES.
	ClusterEndpoint *string
	// The Elasticsearch type name. This applies to Elasticsearch 6.x and lower
	// versions. For Elasticsearch 7.x, there's no value for TypeName.
	TypeName *string
	// The Amazon Resource Name (ARN) of the AWS credentials. For more information, see
	// Amazon Resource Names (ARNs) and AWS Service Namespaces
	// (https://docs.aws.amazon.com/general/latest/gr/aws-arns-and-namespaces.html).
	RoleARN *string
	// The ARN of the Amazon ES domain. For more information, see Amazon Resource Names
	// (ARNs) and AWS Service Namespaces
	// (https://docs.aws.amazon.com/general/latest/gr/aws-arns-and-namespaces.html).
	// <p>Kinesis Data Firehose uses either <code>ClusterEndpoint</code> or
	// <code>DomainARN</code> to send data to Amazon ES.</p>
	DomainARN *string
	// The Amazon ES retry options.
	RetryOptions *ElasticsearchRetryOptions
	// The Amazon S3 destination.
	S3DestinationDescription *S3DestinationDescription
}

// Describes an update for a destination in Amazon ES.
type ElasticsearchDestinationUpdate struct {
	// The Elasticsearch type name. For Elasticsearch 6.x, there can be only one type
	// per index. If you try to specify a new type for an existing index that already
	// has another type, Kinesis Data Firehose returns an error during runtime.  <p>If
	// you upgrade Elasticsearch from 6.x to 7.x and don’t update your delivery stream,
	// Kinesis Data Firehose still delivers data to Elasticsearch with the old index
	// name and type name. If you want to update your delivery stream with a new index
	// name, provide an empty string for <code>TypeName</code>. </p>
	TypeName *string
	// The endpoint to use when communicating with the cluster. Specify either this
	// ClusterEndpoint or the DomainARN field.
	ClusterEndpoint *string
	// The CloudWatch logging options for your delivery stream.
	CloudWatchLoggingOptions *CloudWatchLoggingOptions
	// The Amazon Resource Name (ARN) of the IAM role to be assumed by Kinesis Data
	// Firehose for calling the Amazon ES Configuration API and for indexing documents.
	// For more information, see Grant Kinesis Data Firehose Access to an Amazon S3
	// Destination
	// (https://docs.aws.amazon.com/firehose/latest/dev/controlling-access.html#using-iam-s3)
	// and Amazon Resource Names (ARNs) and AWS Service Namespaces
	// (https://docs.aws.amazon.com/general/latest/gr/aws-arns-and-namespaces.html).
	RoleARN *string
	// The ARN of the Amazon ES domain. The IAM role must have permissions for
	// DescribeElasticsearchDomain, DescribeElasticsearchDomains, and
	// DescribeElasticsearchDomainConfig after assuming the IAM role specified in
	// RoleARN. For more information, see Amazon Resource Names (ARNs) and AWS Service
	// Namespaces
	// (https://docs.aws.amazon.com/general/latest/gr/aws-arns-and-namespaces.html).
	// <p>Specify either <code>ClusterEndpoint</code> or <code>DomainARN</code>.</p>
	DomainARN *string
	// The data processing configuration.
	ProcessingConfiguration *ProcessingConfiguration
	// The Amazon S3 destination.
	S3Update *S3DestinationUpdate
	// The retry behavior in case Kinesis Data Firehose is unable to deliver documents
	// to Amazon ES. The default value is 300 (5 minutes).
	RetryOptions *ElasticsearchRetryOptions
	// The Elasticsearch index name.
	IndexName *string
	// The buffering options. If no value is specified, ElasticsearchBufferingHints
	// object default values are used.
	BufferingHints *ElasticsearchBufferingHints
	// The Elasticsearch index rotation period. Index rotation appends a timestamp to
	// IndexName to facilitate the expiration of old data. For more information, see
	// Index Rotation for the Amazon ES Destination
	// (https://docs.aws.amazon.com/firehose/latest/dev/basic-deliver.html#es-index-rotation).
	// Default value is OneDay.
	IndexRotationPeriod ElasticsearchIndexRotationPeriod
}

// Configures retry behavior in case Kinesis Data Firehose is unable to deliver
// documents to Amazon ES.
type ElasticsearchRetryOptions struct {
	// After an initial failure to deliver to Amazon ES, the total amount of time
	// during which Kinesis Data Firehose retries delivery (including the first
	// attempt). After this time has elapsed, the failed documents are written to
	// Amazon S3. Default value is 300 seconds (5 minutes). A value of 0 (zero) results
	// in no retries.
	DurationInSeconds *int32
}

// Describes the encryption for a destination in Amazon S3.
type EncryptionConfiguration struct {
	// The encryption key.
	KMSEncryptionConfig *KMSEncryptionConfig
	// Specifically override existing encryption information to ensure that no
	// encryption is used.
	NoEncryptionConfig NoEncryptionConfig
}

// Describes the configuration of a destination in Amazon S3.
type ExtendedS3DestinationConfiguration struct {
	// The configuration for backup in Amazon S3.
	S3BackupConfiguration *S3DestinationConfiguration
	// The Amazon Resource Name (ARN) of the AWS credentials. For more information, see
	// Amazon Resource Names (ARNs) and AWS Service Namespaces
	// (https://docs.aws.amazon.com/general/latest/gr/aws-arns-and-namespaces.html).
	RoleARN *string
	// The encryption configuration. If no value is specified, the default is no
	// encryption.
	EncryptionConfiguration *EncryptionConfiguration
	// The Amazon S3 backup mode. After you create a delivery stream, you can update it
	// to enable Amazon S3 backup if it is disabled. If backup is enabled, you can't
	// update the delivery stream to disable it.
	S3BackupMode S3BackupMode
	// The Amazon CloudWatch logging options for your delivery stream.
	CloudWatchLoggingOptions *CloudWatchLoggingOptions
	// The serializer, deserializer, and schema for converting data from the JSON
	// format to the Parquet or ORC format before writing it to Amazon S3.
	DataFormatConversionConfiguration *DataFormatConversionConfiguration
	// The "YYYY/MM/DD/HH" time format prefix is automatically used for delivered
	// Amazon S3 files. You can also specify a custom prefix, as described in Custom
	// Prefixes for Amazon S3 Objects
	// (https://docs.aws.amazon.com/firehose/latest/dev/s3-prefixes.html).
	Prefix *string
	// The data processing configuration.
	ProcessingConfiguration *ProcessingConfiguration
	// The buffering option.
	BufferingHints *BufferingHints
	// The compression format. If no value is specified, the default is UNCOMPRESSED.
	CompressionFormat CompressionFormat
	// The ARN of the S3 bucket. For more information, see Amazon Resource Names (ARNs)
	// and AWS Service Namespaces
	// (https://docs.aws.amazon.com/general/latest/gr/aws-arns-and-namespaces.html).
	BucketARN *string
	// A prefix that Kinesis Data Firehose evaluates and adds to failed records before
	// writing them to S3. This prefix appears immediately following the bucket name.
	// For information about how to specify this prefix, see Custom Prefixes for Amazon
	// S3 Objects (https://docs.aws.amazon.com/firehose/latest/dev/s3-prefixes.html).
	ErrorOutputPrefix *string
}

// Describes a destination in Amazon S3.
type ExtendedS3DestinationDescription struct {
	// The buffering option.
	BufferingHints *BufferingHints
	// The encryption configuration. If no value is specified, the default is no
	// encryption.
	EncryptionConfiguration *EncryptionConfiguration
	// The Amazon S3 backup mode.
	S3BackupMode S3BackupMode
	// The Amazon Resource Name (ARN) of the AWS credentials. For more information, see
	// Amazon Resource Names (ARNs) and AWS Service Namespaces
	// (https://docs.aws.amazon.com/general/latest/gr/aws-arns-and-namespaces.html).
	RoleARN *string
	// A prefix that Kinesis Data Firehose evaluates and adds to failed records before
	// writing them to S3. This prefix appears immediately following the bucket name.
	// For information about how to specify this prefix, see Custom Prefixes for Amazon
	// S3 Objects (https://docs.aws.amazon.com/firehose/latest/dev/s3-prefixes.html).
	ErrorOutputPrefix *string
	// The ARN of the S3 bucket. For more information, see Amazon Resource Names (ARNs)
	// and AWS Service Namespaces
	// (https://docs.aws.amazon.com/general/latest/gr/aws-arns-and-namespaces.html).
	BucketARN *string
	// The compression format. If no value is specified, the default is UNCOMPRESSED.
	CompressionFormat CompressionFormat
	// The data processing configuration.
	ProcessingConfiguration *ProcessingConfiguration
	// The configuration for backup in Amazon S3.
	S3BackupDescription *S3DestinationDescription
	// The Amazon CloudWatch logging options for your delivery stream.
	CloudWatchLoggingOptions *CloudWatchLoggingOptions
	// The serializer, deserializer, and schema for converting data from the JSON
	// format to the Parquet or ORC format before writing it to Amazon S3.
	DataFormatConversionConfiguration *DataFormatConversionConfiguration
	// The "YYYY/MM/DD/HH" time format prefix is automatically used for delivered
	// Amazon S3 files. You can also specify a custom prefix, as described in Custom
	// Prefixes for Amazon S3 Objects
	// (https://docs.aws.amazon.com/firehose/latest/dev/s3-prefixes.html).
	Prefix *string
}

// Describes an update for a destination in Amazon S3.
type ExtendedS3DestinationUpdate struct {
	// The encryption configuration. If no value is specified, the default is no
	// encryption.
	EncryptionConfiguration *EncryptionConfiguration
	// The buffering option.
	BufferingHints *BufferingHints
	// The Amazon Resource Name (ARN) of the AWS credentials. For more information, see
	// Amazon Resource Names (ARNs) and AWS Service Namespaces
	// (https://docs.aws.amazon.com/general/latest/gr/aws-arns-and-namespaces.html).
	RoleARN *string
	// The Amazon S3 destination for backup.
	S3BackupUpdate *S3DestinationUpdate
	// The ARN of the S3 bucket. For more information, see Amazon Resource Names (ARNs)
	// and AWS Service Namespaces
	// (https://docs.aws.amazon.com/general/latest/gr/aws-arns-and-namespaces.html).
	BucketARN *string
	// A prefix that Kinesis Data Firehose evaluates and adds to failed records before
	// writing them to S3. This prefix appears immediately following the bucket name.
	// For information about how to specify this prefix, see Custom Prefixes for Amazon
	// S3 Objects (https://docs.aws.amazon.com/firehose/latest/dev/s3-prefixes.html).
	ErrorOutputPrefix *string
	// The compression format. If no value is specified, the default is UNCOMPRESSED.
	CompressionFormat CompressionFormat
	// The serializer, deserializer, and schema for converting data from the JSON
	// format to the Parquet or ORC format before writing it to Amazon S3.
	DataFormatConversionConfiguration *DataFormatConversionConfiguration
	// The data processing configuration.
	ProcessingConfiguration *ProcessingConfiguration
	// The "YYYY/MM/DD/HH" time format prefix is automatically used for delivered
	// Amazon S3 files. You can also specify a custom prefix, as described in Custom
	// Prefixes for Amazon S3 Objects
	// (https://docs.aws.amazon.com/firehose/latest/dev/s3-prefixes.html).
	Prefix *string
	// The Amazon CloudWatch logging options for your delivery stream.
	CloudWatchLoggingOptions *CloudWatchLoggingOptions
	// You can update a delivery stream to enable Amazon S3 backup if it is disabled.
	// If backup is enabled, you can't update the delivery stream to disable it.
	S3BackupMode S3BackupMode
}

// Provides details in case one of the following operations fails due to an error
// related to KMS: CreateDeliveryStream (), DeleteDeliveryStream (),
// StartDeliveryStreamEncryption (), StopDeliveryStreamEncryption ().
type FailureDescription struct {
	// The type of error that caused the failure.
	Type DeliveryStreamFailureType
	// A message providing details about the error that caused the failure.
	Details *string
}

// The native Hive / HCatalog JsonSerDe. Used by Kinesis Data Firehose for
// deserializing data, which means converting it from the JSON format in
// preparation for serializing it to the Parquet or ORC format. This is one of two
// deserializers you can choose, depending on which one offers the functionality
// you need. The other option is the OpenX SerDe.
type HiveJsonSerDe struct {
	// Indicates how you want Kinesis Data Firehose to parse the date and timestamps
	// that may be present in your input data JSON. To specify these format strings,
	// follow the pattern syntax of JodaTime's DateTimeFormat format strings. For more
	// information, see Class DateTimeFormat
	// (https://www.joda.org/joda-time/apidocs/org/joda/time/format/DateTimeFormat.html).
	// You can also use the special value millis to parse timestamps in epoch
	// milliseconds. If you don't specify a format, Kinesis Data Firehose uses
	// java.sql.Timestamp::valueOf by default.
	TimestampFormats []*string
}

// Describes the buffering options that can be applied before data is delivered to
// the HTTP endpoint destination. Kinesis Data Firehose treats these options as
// hints, and it might choose to use more optimal values. The SizeInMBs and
// IntervalInSeconds parameters are optional. However, if specify a value for one
// of them, you must also provide a value for the other.
type HttpEndpointBufferingHints struct {
	// Buffer incoming data for the specified period of time, in seconds, before
	// delivering it to the destination. The default value is 300 (5 minutes).
	IntervalInSeconds *int32
	// Buffer incoming data to the specified size, in MBs, before delivering it to the
	// destination. The default value is 5. We recommend setting this parameter to a
	// value greater than the amount of data you typically ingest into the delivery
	// stream in 10 seconds. For example, if you typically ingest data at 1 MB/sec, the
	// value should be 10 MB or higher.
	SizeInMBs *int32
}

// Describes the metadata that's delivered to the specified HTTP endpoint
// destination.
type HttpEndpointCommonAttribute struct {
	// The name of the HTTP endpoint common attribute.
	AttributeName *string
	// The value of the HTTP endpoint common attribute.
	AttributeValue *string
}

// Describes the configuration of the HTTP endpoint to which Kinesis Firehose
// delivers data.
type HttpEndpointConfiguration struct {
	// The access key required for Kinesis Firehose to authenticate with the HTTP
	// endpoint selected as the destination.
	AccessKey *string
	// The URL of the HTTP endpoint selected as the destination.
	Url *string
	// The name of the HTTP endpoint selected as the destination.
	Name *string
}

// Describes the HTTP endpoint selected as the destination.
type HttpEndpointDescription struct {
	// The name of the HTTP endpoint selected as the destination.
	Name *string
	// The URL of the HTTP endpoint selected as the destination.
	Url *string
}

// Describes the configuration of the HTTP endpoint destination.
type HttpEndpointDestinationConfiguration struct {
	// Describes a data processing configuration.
	ProcessingConfiguration *ProcessingConfiguration
	// Describes the retry behavior in case Kinesis Data Firehose is unable to deliver
	// data to the specified HTTP endpoint destination, or if it doesn't receive a
	// valid acknowledgment of receipt from the specified HTTP endpoint destination.
	RetryOptions *HttpEndpointRetryOptions
	// The configuration of the HTTP endpoint selected as the destination.
	EndpointConfiguration *HttpEndpointConfiguration
	// The configuration of the requeste sent to the HTTP endpoint specified as the
	// destination.
	RequestConfiguration *HttpEndpointRequestConfiguration
	// Describes the S3 bucket backup options for the data that Kinesis Data Firehose
	// delivers to the HTTP endpoint destination. You can back up all documents
	// (AllData) or only the documents that Kinesis Data Firehose could not deliver to
	// the specified HTTP endpoint destination (FailedDataOnly).
	S3BackupMode HttpEndpointS3BackupMode
	// Describes the Amazon CloudWatch logging options for your delivery stream.
	CloudWatchLoggingOptions *CloudWatchLoggingOptions
	// Kinesis Data Firehose uses this IAM role for all the permissions that the
	// delivery stream needs.
	RoleARN *string
	// Describes the configuration of a destination in Amazon S3.
	S3Configuration *S3DestinationConfiguration
	// The buffering options that can be used before data is delivered to the specified
	// destination. Kinesis Data Firehose treats these options as hints, and it might
	// choose to use more optimal values. The SizeInMBs and IntervalInSeconds
	// parameters are optional. However, if you specify a value for one of them, you
	// must also provide a value for the other.
	BufferingHints *HttpEndpointBufferingHints
}

// Describes the HTTP endpoint destination.
type HttpEndpointDestinationDescription struct {
	// Describes a destination in Amazon S3.
	S3DestinationDescription *S3DestinationDescription
	// Describes the retry behavior in case Kinesis Data Firehose is unable to deliver
	// data to the specified HTTP endpoint destination, or if it doesn't receive a
	// valid acknowledgment of receipt from the specified HTTP endpoint destination.
	RetryOptions *HttpEndpointRetryOptions
	// Describes the Amazon CloudWatch logging options for your delivery stream.
	CloudWatchLoggingOptions *CloudWatchLoggingOptions
	// Describes a data processing configuration.
	ProcessingConfiguration *ProcessingConfiguration
	// Kinesis Data Firehose uses this IAM role for all the permissions that the
	// delivery stream needs.
	RoleARN *string
	// Describes the S3 bucket backup options for the data that Kinesis Firehose
	// delivers to the HTTP endpoint destination. You can back up all documents
	// (AllData) or only the documents that Kinesis Data Firehose could not deliver to
	// the specified HTTP endpoint destination (FailedDataOnly).
	S3BackupMode HttpEndpointS3BackupMode
	// Describes buffering options that can be applied to the data before it is
	// delivered to the HTTPS endpoint destination. Kinesis Data Firehose teats these
	// options as hints, and it might choose to use more optimal values. The SizeInMBs
	// and IntervalInSeconds parameters are optional. However, if specify a value for
	// one of them, you must also provide a value for the other.
	BufferingHints *HttpEndpointBufferingHints
	// The configuration of request sent to the HTTP endpoint specified as the
	// destination.
	RequestConfiguration *HttpEndpointRequestConfiguration
	// The configuration of the specified HTTP endpoint destination.
	EndpointConfiguration *HttpEndpointDescription
}

// Updates the specified HTTP endpoint destination.
type HttpEndpointDestinationUpdate struct {
	// Describes the configuration of the HTTP endpoint destination.
	EndpointConfiguration *HttpEndpointConfiguration
	// Describes a data processing configuration.
	ProcessingConfiguration *ProcessingConfiguration
	// Describes the retry behavior in case Kinesis Data Firehose is unable to deliver
	// data to the specified HTTP endpoint destination, or if it doesn't receive a
	// valid acknowledgment of receipt from the specified HTTP endpoint destination.
	RetryOptions *HttpEndpointRetryOptions
	// Kinesis Data Firehose uses this IAM role for all the permissions that the
	// delivery stream needs.
	RoleARN *string
	// Describes buffering options that can be applied to the data before it is
	// delivered to the HTTPS endpoint destination. Kinesis Data Firehose teats these
	// options as hints, and it might choose to use more optimal values. The SizeInMBs
	// and IntervalInSeconds parameters are optional. However, if specify a value for
	// one of them, you must also provide a value for the other.
	BufferingHints *HttpEndpointBufferingHints
	// The configuration of the request sent to the HTTP endpoint specified as the
	// destination.
	RequestConfiguration *HttpEndpointRequestConfiguration
	// Describes the Amazon CloudWatch logging options for your delivery stream.
	CloudWatchLoggingOptions *CloudWatchLoggingOptions
	// Describes the S3 bucket backup options for the data that Kinesis Firehose
	// delivers to the HTTP endpoint destination. You can back up all documents
	// (AllData) or only the documents that Kinesis Data Firehose could not deliver to
	// the specified HTTP endpoint destination (FailedDataOnly).
	S3BackupMode HttpEndpointS3BackupMode
	// Describes an update for a destination in Amazon S3.
	S3Update *S3DestinationUpdate
}

// The configuration of the HTTP endpoint request.
type HttpEndpointRequestConfiguration struct {
	// Kinesis Data Firehose uses the content encoding to compress the body of a
	// request before sending the request to the destination. For more information, see
	// Content-Encoding
	// (https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Content-Encoding) in
	// MDN Web Docs, the official Mozilla documentation.
	ContentEncoding ContentEncoding
	// Describes the metadata sent to the HTTP endpoint destination.
	CommonAttributes []*HttpEndpointCommonAttribute
}

// Describes the retry behavior in case Kinesis Data Firehose is unable to deliver
// data to the specified HTTP endpoint destination, or if it doesn't receive a
// valid acknowledgment of receipt from the specified HTTP endpoint destination.
type HttpEndpointRetryOptions struct {
	// The total amount of time that Kinesis Data Firehose spends on retries. This
	// duration starts after the initial attempt to send data to the custom destination
	// via HTTPS endpoint fails. It doesn't include the periods during which Kinesis
	// Data Firehose waits for acknowledgment from the specified destination after each
	// attempt.
	DurationInSeconds *int32
}

// Specifies the deserializer you want to use to convert the format of the input
// data. This parameter is required if Enabled is set to true.
type InputFormatConfiguration struct {
	// Specifies which deserializer to use. You can choose either the Apache Hive JSON
	// SerDe or the OpenX JSON SerDe. If both are non-null, the server rejects the
	// request.
	Deserializer *Deserializer
}

// The stream and role Amazon Resource Names (ARNs) for a Kinesis data stream used
// as the source for a delivery stream.
type KinesisStreamSourceConfiguration struct {
	// The ARN of the role that provides access to the source Kinesis data stream. For
	// more information, see AWS Identity and Access Management (IAM) ARN Format
	// (https://docs.aws.amazon.com/general/latest/gr/aws-arns-and-namespaces.html#arn-syntax-iam).
	RoleARN *string
	// The ARN of the source Kinesis data stream. For more information, see Amazon
	// Kinesis Data Streams ARN Format
	// (https://docs.aws.amazon.com/general/latest/gr/aws-arns-and-namespaces.html#arn-syntax-kinesis-streams).
	KinesisStreamARN *string
}

// Details about a Kinesis data stream used as the source for a Kinesis Data
// Firehose delivery stream.
type KinesisStreamSourceDescription struct {
	// Kinesis Data Firehose starts retrieving records from the Kinesis data stream
	// starting with this timestamp.
	DeliveryStartTimestamp *time.Time
	// The Amazon Resource Name (ARN) of the source Kinesis data stream. For more
	// information, see Amazon Kinesis Data Streams ARN Format
	// (https://docs.aws.amazon.com/general/latest/gr/aws-arns-and-namespaces.html#arn-syntax-kinesis-streams).
	KinesisStreamARN *string
	// The ARN of the role used by the source Kinesis data stream. For more
	// information, see AWS Identity and Access Management (IAM) ARN Format
	// (https://docs.aws.amazon.com/general/latest/gr/aws-arns-and-namespaces.html#arn-syntax-iam).
	RoleARN *string
}

// Describes an encryption key for a destination in Amazon S3.
type KMSEncryptionConfig struct {
	// The Amazon Resource Name (ARN) of the encryption key. Must belong to the same
	// AWS Region as the destination Amazon S3 bucket. For more information, see Amazon
	// Resource Names (ARNs) and AWS Service Namespaces
	// (https://docs.aws.amazon.com/general/latest/gr/aws-arns-and-namespaces.html).
	AWSKMSKeyARN *string
}

// The OpenX SerDe. Used by Kinesis Data Firehose for deserializing data, which
// means converting it from the JSON format in preparation for serializing it to
// the Parquet or ORC format. This is one of two deserializers you can choose,
// depending on which one offers the functionality you need. The other option is
// the native Hive / HCatalog JsonSerDe.
type OpenXJsonSerDe struct {
	// Maps column names to JSON keys that aren't identical to the column names. This
	// is useful when the JSON contains keys that are Hive keywords. For example,
	// timestamp is a Hive keyword. If you have a JSON key named timestamp, set this
	// parameter to {"ts": "timestamp"} to map this key to a column named ts.
	ColumnToJsonKeyMappings map[string]*string
	// When set to true, which is the default, Kinesis Data Firehose converts JSON keys
	// to lowercase before deserializing them.
	CaseInsensitive *bool
	// When set to true, specifies that the names of the keys include dots and that you
	// want Kinesis Data Firehose to replace them with underscores. This is useful
	// because Apache Hive does not allow dots in column names. For example, if the
	// JSON contains a key whose name is "a.b", you can define the column name to be
	// "a_b" when using this option. The default is false.
	ConvertDotsInJsonKeysToUnderscores *bool
}

// A serializer to use for converting data to the ORC format before storing it in
// Amazon S3. For more information, see Apache ORC (https://orc.apache.org/docs/).
type OrcSerDe struct {
	// The column names for which you want Kinesis Data Firehose to create bloom
	// filters. The default is null.
	BloomFilterColumns []*string
	// A number between 0 and 1 that defines the tolerance for block padding as a
	// decimal fraction of stripe size. The default value is 0.05, which means 5
	// percent of stripe size. For the default values of 64 MiB ORC stripes and 256 MiB
	// HDFS blocks, the default block padding tolerance of 5 percent reserves a maximum
	// of 3.2 MiB for padding within the 256 MiB block. In such a case, if the
	// available size within the block is more than 3.2 MiB, a new, smaller stripe is
	// inserted to fit within that space. This ensures that no stripe crosses block
	// boundaries and causes remote reads within a node-local task. Kinesis Data
	// Firehose ignores this parameter when OrcSerDe$EnablePadding () is false.
	PaddingTolerance *float64
	// Represents the fraction of the total number of non-null rows. To turn off
	// dictionary encoding, set this fraction to a number that is less than the number
	// of distinct keys in a dictionary. To always use dictionary encoding, set this
	// threshold to 1.
	DictionaryKeyThreshold *float64
	// The Hadoop Distributed File System (HDFS) block size. This is useful if you
	// intend to copy the data from Amazon S3 to HDFS before querying. The default is
	// 256 MiB and the minimum is 64 MiB. Kinesis Data Firehose uses this value for
	// padding calculations.
	BlockSizeBytes *int32
	// The number of rows between index entries. The default is 10,000 and the minimum
	// is 1,000.
	RowIndexStride *int32
	// The number of bytes in each stripe. The default is 64 MiB and the minimum is 8
	// MiB.
	StripeSizeBytes *int32
	// The version of the file to write. The possible values are V0_11 and V0_12. The
	// default is V0_12.
	FormatVersion OrcFormatVersion
	// The compression code to use over data blocks. The default is SNAPPY.
	Compression OrcCompression
	// The Bloom filter false positive probability (FPP). The lower the FPP, the bigger
	// the Bloom filter. The default value is 0.05, the minimum is 0, and the maximum
	// is 1.
	BloomFilterFalsePositiveProbability *float64
	// Set this to true to indicate that you want stripes to be padded to the HDFS
	// block boundaries. This is useful if you intend to copy the data from Amazon S3
	// to HDFS before querying. The default is false.
	EnablePadding *bool
}

// Specifies the serializer that you want Kinesis Data Firehose to use to convert
// the format of your data before it writes it to Amazon S3. This parameter is
// required if Enabled is set to true.
type OutputFormatConfiguration struct {
	// Specifies which serializer to use. You can choose either the ORC SerDe or the
	// Parquet SerDe. If both are non-null, the server rejects the request.
	Serializer *Serializer
}

// A serializer to use for converting data to the Parquet format before storing it
// in Amazon S3. For more information, see Apache Parquet
// (https://parquet.apache.org/documentation/latest/).
type ParquetSerDe struct {
	// The compression code to use over data blocks. The possible values are
	// UNCOMPRESSED, SNAPPY, and GZIP, with the default being SNAPPY. Use SNAPPY for
	// higher decompression speed. Use GZIP if the compression ratio is more important
	// than speed.
	Compression ParquetCompression
	// The Hadoop Distributed File System (HDFS) block size. This is useful if you
	// intend to copy the data from Amazon S3 to HDFS before querying. The default is
	// 256 MiB and the minimum is 64 MiB. Kinesis Data Firehose uses this value for
	// padding calculations.
	BlockSizeBytes *int32
	// The Parquet page size. Column chunks are divided into pages. A page is
	// conceptually an indivisible unit (in terms of compression and encoding). The
	// minimum value is 64 KiB and the default is 1 MiB.
	PageSizeBytes *int32
	// Indicates the version of row format to output. The possible values are V1 and
	// V2. The default is V1.
	WriterVersion ParquetWriterVersion
	// Indicates whether to enable dictionary compression.
	EnableDictionaryCompression *bool
	// The maximum amount of padding to apply. This is useful if you intend to copy the
	// data from Amazon S3 to HDFS before querying. The default is 0.
	MaxPaddingBytes *int32
}

// Describes a data processing configuration.
type ProcessingConfiguration struct {
	// Enables or disables data processing.
	Enabled *bool
	// The data processors.
	Processors []*Processor
}

// Describes a data processor.
type Processor struct {
	// The type of processor.
	Type ProcessorType
	// The processor parameters.
	Parameters []*ProcessorParameter
}

// Describes the processor parameter.
type ProcessorParameter struct {
	// The name of the parameter.
	ParameterName ProcessorParameterName
	// The parameter value.
	ParameterValue *string
}

// Contains the result for an individual record from a PutRecordBatch () request.
// If the record is successfully added to your delivery stream, it receives a
// record ID. If the record fails to be added to your delivery stream, the result
// includes an error code and an error message.
type PutRecordBatchResponseEntry struct {
	// The error message for an individual record result.
	ErrorMessage *string
	// The ID of the record.
	RecordId *string
	// The error code for an individual record result.
	ErrorCode *string
}

// The unit of data in a delivery stream.
type Record struct {
	// The data blob, which is base64-encoded when the blob is serialized. The maximum
	// size of the data blob, before base64-encoding, is 1,000 KiB.
	Data []byte
}

// Describes the configuration of a destination in Amazon Redshift.
type RedshiftDestinationConfiguration struct {
	// The configuration for the intermediate Amazon S3 location from which Amazon
	// Redshift obtains data. Restrictions are described in the topic for
	// CreateDeliveryStream (). The compression formats SNAPPY or ZIP cannot be
	// specified in RedshiftDestinationConfiguration.S3Configuration because the Amazon
	// Redshift COPY operation that reads from the S3 bucket doesn't support these
	// compression formats.
	S3Configuration *S3DestinationConfiguration
	// The name of the user.
	Username *string
	// The Amazon Resource Name (ARN) of the AWS credentials. For more information, see
	// Amazon Resource Names (ARNs) and AWS Service Namespaces
	// (https://docs.aws.amazon.com/general/latest/gr/aws-arns-and-namespaces.html).
	RoleARN *string
	// The configuration for backup in Amazon S3.
	S3BackupConfiguration *S3DestinationConfiguration
	// The CloudWatch logging options for your delivery stream.
	CloudWatchLoggingOptions *CloudWatchLoggingOptions
	// The database connection string.
	ClusterJDBCURL *string
	// The user password.
	Password *string
	// The Amazon S3 backup mode. After you create a delivery stream, you can update it
	// to enable Amazon S3 backup if it is disabled. If backup is enabled, you can't
	// update the delivery stream to disable it.
	S3BackupMode RedshiftS3BackupMode
	// The data processing configuration.
	ProcessingConfiguration *ProcessingConfiguration
	// The retry behavior in case Kinesis Data Firehose is unable to deliver documents
	// to Amazon Redshift. Default value is 3600 (60 minutes).
	RetryOptions *RedshiftRetryOptions
	// The COPY command.
	CopyCommand *CopyCommand
}

// Describes a destination in Amazon Redshift.
type RedshiftDestinationDescription struct {
	// The Amazon S3 backup mode.
	S3BackupMode RedshiftS3BackupMode
	// The Amazon Resource Name (ARN) of the AWS credentials. For more information, see
	// Amazon Resource Names (ARNs) and AWS Service Namespaces
	// (https://docs.aws.amazon.com/general/latest/gr/aws-arns-and-namespaces.html).
	RoleARN *string
	// The Amazon S3 destination.
	S3DestinationDescription *S3DestinationDescription
	// The retry behavior in case Kinesis Data Firehose is unable to deliver documents
	// to Amazon Redshift. Default value is 3600 (60 minutes).
	RetryOptions *RedshiftRetryOptions
	// The COPY command.
	CopyCommand *CopyCommand
	// The data processing configuration.
	ProcessingConfiguration *ProcessingConfiguration
	// The Amazon CloudWatch logging options for your delivery stream.
	CloudWatchLoggingOptions *CloudWatchLoggingOptions
	// The name of the user.
	Username *string
	// The database connection string.
	ClusterJDBCURL *string
	// The configuration for backup in Amazon S3.
	S3BackupDescription *S3DestinationDescription
}

// Describes an update for a destination in Amazon Redshift.
type RedshiftDestinationUpdate struct {
	// The Amazon S3 destination for backup.
	S3BackupUpdate *S3DestinationUpdate
	// The COPY command.
	CopyCommand *CopyCommand
	// The retry behavior in case Kinesis Data Firehose is unable to deliver documents
	// to Amazon Redshift. Default value is 3600 (60 minutes).
	RetryOptions *RedshiftRetryOptions
	// The data processing configuration.
	ProcessingConfiguration *ProcessingConfiguration
	// The name of the user.
	Username *string
	// The Amazon S3 destination. The compression formats SNAPPY or ZIP cannot be
	// specified in RedshiftDestinationUpdate.S3Update because the Amazon Redshift COPY
	// operation that reads from the S3 bucket doesn't support these compression
	// formats.
	S3Update *S3DestinationUpdate
	// The user password.
	Password *string
	// The Amazon Resource Name (ARN) of the AWS credentials. For more information, see
	// Amazon Resource Names (ARNs) and AWS Service Namespaces
	// (https://docs.aws.amazon.com/general/latest/gr/aws-arns-and-namespaces.html).
	RoleARN *string
	// The Amazon CloudWatch logging options for your delivery stream.
	CloudWatchLoggingOptions *CloudWatchLoggingOptions
	// The database connection string.
	ClusterJDBCURL *string
	// You can update a delivery stream to enable Amazon S3 backup if it is disabled.
	// If backup is enabled, you can't update the delivery stream to disable it.
	S3BackupMode RedshiftS3BackupMode
}

// Configures retry behavior in case Kinesis Data Firehose is unable to deliver
// documents to Amazon Redshift.
type RedshiftRetryOptions struct {
	// The length of time during which Kinesis Data Firehose retries delivery after a
	// failure, starting from the initial request and including the first attempt. The
	// default value is 3600 seconds (60 minutes). Kinesis Data Firehose does not retry
	// if the value of DurationInSeconds is 0 (zero) or if the first delivery attempt
	// takes longer than the current value.
	DurationInSeconds *int32
}

// Describes the configuration of a destination in Amazon S3.
type S3DestinationConfiguration struct {
	// The compression format. If no value is specified, the default is UNCOMPRESSED.
	// The compression formats SNAPPY or ZIP cannot be specified for Amazon Redshift
	// destinations because they are not supported by the Amazon Redshift COPY
	// operation that reads from the S3 bucket.
	CompressionFormat CompressionFormat
	// The "YYYY/MM/DD/HH" time format prefix is automatically used for delivered
	// Amazon S3 files. You can also specify a custom prefix, as described in Custom
	// Prefixes for Amazon S3 Objects
	// (https://docs.aws.amazon.com/firehose/latest/dev/s3-prefixes.html).
	Prefix *string
	// The buffering option. If no value is specified, BufferingHints object default
	// values are used.
	BufferingHints *BufferingHints
	// The encryption configuration. If no value is specified, the default is no
	// encryption.
	EncryptionConfiguration *EncryptionConfiguration
	// The Amazon Resource Name (ARN) of the AWS credentials. For more information, see
	// Amazon Resource Names (ARNs) and AWS Service Namespaces
	// (https://docs.aws.amazon.com/general/latest/gr/aws-arns-and-namespaces.html).
	RoleARN *string
	// A prefix that Kinesis Data Firehose evaluates and adds to failed records before
	// writing them to S3. This prefix appears immediately following the bucket name.
	// For information about how to specify this prefix, see Custom Prefixes for Amazon
	// S3 Objects (https://docs.aws.amazon.com/firehose/latest/dev/s3-prefixes.html).
	ErrorOutputPrefix *string
	// The CloudWatch logging options for your delivery stream.
	CloudWatchLoggingOptions *CloudWatchLoggingOptions
	// The ARN of the S3 bucket. For more information, see Amazon Resource Names (ARNs)
	// and AWS Service Namespaces
	// (https://docs.aws.amazon.com/general/latest/gr/aws-arns-and-namespaces.html).
	BucketARN *string
}

// Describes a destination in Amazon S3.
type S3DestinationDescription struct {
	// The Amazon CloudWatch logging options for your delivery stream.
	CloudWatchLoggingOptions *CloudWatchLoggingOptions
	// A prefix that Kinesis Data Firehose evaluates and adds to failed records before
	// writing them to S3. This prefix appears immediately following the bucket name.
	// For information about how to specify this prefix, see Custom Prefixes for Amazon
	// S3 Objects (https://docs.aws.amazon.com/firehose/latest/dev/s3-prefixes.html).
	ErrorOutputPrefix *string
	// The ARN of the S3 bucket. For more information, see Amazon Resource Names (ARNs)
	// and AWS Service Namespaces
	// (https://docs.aws.amazon.com/general/latest/gr/aws-arns-and-namespaces.html).
	BucketARN *string
	// The compression format. If no value is specified, the default is UNCOMPRESSED.
	CompressionFormat CompressionFormat
	// The Amazon Resource Name (ARN) of the AWS credentials. For more information, see
	// Amazon Resource Names (ARNs) and AWS Service Namespaces
	// (https://docs.aws.amazon.com/general/latest/gr/aws-arns-and-namespaces.html).
	RoleARN *string
	// The "YYYY/MM/DD/HH" time format prefix is automatically used for delivered
	// Amazon S3 files. You can also specify a custom prefix, as described in Custom
	// Prefixes for Amazon S3 Objects
	// (https://docs.aws.amazon.com/firehose/latest/dev/s3-prefixes.html).
	Prefix *string
	// The buffering option. If no value is specified, BufferingHints object default
	// values are used.
	BufferingHints *BufferingHints
	// The encryption configuration. If no value is specified, the default is no
	// encryption.
	EncryptionConfiguration *EncryptionConfiguration
}

// Describes an update for a destination in Amazon S3.
type S3DestinationUpdate struct {
	// The encryption configuration. If no value is specified, the default is no
	// encryption.
	EncryptionConfiguration *EncryptionConfiguration
	// The buffering option. If no value is specified, BufferingHints object default
	// values are used.
	BufferingHints *BufferingHints
	// The Amazon Resource Name (ARN) of the AWS credentials. For more information, see
	// Amazon Resource Names (ARNs) and AWS Service Namespaces
	// (https://docs.aws.amazon.com/general/latest/gr/aws-arns-and-namespaces.html).
	RoleARN *string
	// The ARN of the S3 bucket. For more information, see Amazon Resource Names (ARNs)
	// and AWS Service Namespaces
	// (https://docs.aws.amazon.com/general/latest/gr/aws-arns-and-namespaces.html).
	BucketARN *string
	// A prefix that Kinesis Data Firehose evaluates and adds to failed records before
	// writing them to S3. This prefix appears immediately following the bucket name.
	// For information about how to specify this prefix, see Custom Prefixes for Amazon
	// S3 Objects (https://docs.aws.amazon.com/firehose/latest/dev/s3-prefixes.html).
	ErrorOutputPrefix *string
	// The compression format. If no value is specified, the default is UNCOMPRESSED.
	// The compression formats SNAPPY or ZIP cannot be specified for Amazon Redshift
	// destinations because they are not supported by the Amazon Redshift COPY
	// operation that reads from the S3 bucket.
	CompressionFormat CompressionFormat
	// The CloudWatch logging options for your delivery stream.
	CloudWatchLoggingOptions *CloudWatchLoggingOptions
	// The "YYYY/MM/DD/HH" time format prefix is automatically used for delivered
	// Amazon S3 files. You can also specify a custom prefix, as described in Custom
	// Prefixes for Amazon S3 Objects
	// (https://docs.aws.amazon.com/firehose/latest/dev/s3-prefixes.html).
	Prefix *string
}

// Specifies the schema to which you want Kinesis Data Firehose to configure your
// data before it writes it to Amazon S3. This parameter is required if Enabled is
// set to true.
type SchemaConfiguration struct {
	// Specifies the name of the AWS Glue database that contains the schema for the
	// output data.
	DatabaseName *string
	// The role that Kinesis Data Firehose can use to access AWS Glue. This role must
	// be in the same account you use for Kinesis Data Firehose. Cross-account roles
	// aren't allowed.
	RoleARN *string
	// Specifies the AWS Glue table that contains the column information that
	// constitutes your data schema.
	TableName *string
	// If you don't specify an AWS Region, the default is the current Region.
	Region *string
	// The ID of the AWS Glue Data Catalog. If you don't supply this, the AWS account
	// ID is used by default.
	CatalogId *string
	// Specifies the table version for the output data schema. If you don't specify
	// this version ID, or if you set it to LATEST, Kinesis Data Firehose uses the most
	// recent version. This means that any updates to the table are automatically
	// picked up.
	VersionId *string
}

// The serializer that you want Kinesis Data Firehose to use to convert data to the
// target format before writing it to Amazon S3. Kinesis Data Firehose supports two
// types of serializers: the ORC SerDe
// (https://hive.apache.org/javadocs/r1.2.2/api/org/apache/hadoop/hive/ql/io/orc/OrcSerde.html)
// and the Parquet SerDe
// (https://hive.apache.org/javadocs/r1.2.2/api/org/apache/hadoop/hive/ql/io/parquet/serde/ParquetHiveSerDe.html).
type Serializer struct {
	// A serializer to use for converting data to the ORC format before storing it in
	// Amazon S3. For more information, see Apache ORC (https://orc.apache.org/docs/).
	OrcSerDe *OrcSerDe
	// A serializer to use for converting data to the Parquet format before storing it
	// in Amazon S3. For more information, see Apache Parquet
	// (https://parquet.apache.org/documentation/latest/).
	ParquetSerDe *ParquetSerDe
}

// Details about a Kinesis data stream used as the source for a Kinesis Data
// Firehose delivery stream.
type SourceDescription struct {
	// The KinesisStreamSourceDescription () value for the source Kinesis data stream.
	KinesisStreamSourceDescription *KinesisStreamSourceDescription
}

// Describes the configuration of a destination in Splunk.
type SplunkDestinationConfiguration struct {
	// The amount of time that Kinesis Data Firehose waits to receive an acknowledgment
	// from Splunk after it sends it data. At the end of the timeout period, Kinesis
	// Data Firehose either tries to send the data again or considers it an error,
	// based on your retry settings.
	HECAcknowledgmentTimeoutInSeconds *int32
	// This is a GUID that you obtain from your Splunk cluster when you create a new
	// HEC endpoint.
	HECToken *string
	// The retry behavior in case Kinesis Data Firehose is unable to deliver data to
	// Splunk, or if it doesn't receive an acknowledgment of receipt from Splunk.
	RetryOptions *SplunkRetryOptions
	// This type can be either "Raw" or "Event."
	HECEndpointType HECEndpointType
	// The data processing configuration.
	ProcessingConfiguration *ProcessingConfiguration
	// Defines how documents should be delivered to Amazon S3. When set to
	// FailedEventsOnly, Kinesis Data Firehose writes any data that could not be
	// indexed to the configured Amazon S3 destination. When set to AllEvents, Kinesis
	// Data Firehose delivers all incoming records to Amazon S3, and also writes failed
	// documents to Amazon S3. The default value is FailedEventsOnly. You can update
	// this backup mode from FailedEventsOnly to AllEvents. You can't update it from
	// AllEvents to FailedEventsOnly.
	S3BackupMode SplunkS3BackupMode
	// The Amazon CloudWatch logging options for your delivery stream.
	CloudWatchLoggingOptions *CloudWatchLoggingOptions
	// The configuration for the backup Amazon S3 location.
	S3Configuration *S3DestinationConfiguration
	// The HTTP Event Collector (HEC) endpoint to which Kinesis Data Firehose sends
	// your data.
	HECEndpoint *string
}

// Describes a destination in Splunk.
type SplunkDestinationDescription struct {
	// Defines how documents should be delivered to Amazon S3. When set to
	// FailedDocumentsOnly, Kinesis Data Firehose writes any data that could not be
	// indexed to the configured Amazon S3 destination. When set to AllDocuments,
	// Kinesis Data Firehose delivers all incoming records to Amazon S3, and also
	// writes failed documents to Amazon S3. Default value is FailedDocumentsOnly.
	S3BackupMode SplunkS3BackupMode
	// A GUID you obtain from your Splunk cluster when you create a new HEC endpoint.
	HECToken *string
	// The retry behavior in case Kinesis Data Firehose is unable to deliver data to
	// Splunk or if it doesn't receive an acknowledgment of receipt from Splunk.
	RetryOptions *SplunkRetryOptions
	// This type can be either "Raw" or "Event."
	HECEndpointType HECEndpointType
	// The amount of time that Kinesis Data Firehose waits to receive an acknowledgment
	// from Splunk after it sends it data. At the end of the timeout period, Kinesis
	// Data Firehose either tries to send the data again or considers it an error,
	// based on your retry settings.
	HECAcknowledgmentTimeoutInSeconds *int32
	// The data processing configuration.
	ProcessingConfiguration *ProcessingConfiguration
	// The HTTP Event Collector (HEC) endpoint to which Kinesis Data Firehose sends
	// your data.
	HECEndpoint *string
	// The Amazon CloudWatch logging options for your delivery stream.
	CloudWatchLoggingOptions *CloudWatchLoggingOptions
	// The Amazon S3 destination.>
	S3DestinationDescription *S3DestinationDescription
}

// Describes an update for a destination in Splunk.
type SplunkDestinationUpdate struct {
	// The Amazon CloudWatch logging options for your delivery stream.
	CloudWatchLoggingOptions *CloudWatchLoggingOptions
	// The HTTP Event Collector (HEC) endpoint to which Kinesis Data Firehose sends
	// your data.
	HECEndpoint *string
	// The data processing configuration.
	ProcessingConfiguration *ProcessingConfiguration
	// This type can be either "Raw" or "Event."
	HECEndpointType HECEndpointType
	// The retry behavior in case Kinesis Data Firehose is unable to deliver data to
	// Splunk or if it doesn't receive an acknowledgment of receipt from Splunk.
	RetryOptions *SplunkRetryOptions
	// The amount of time that Kinesis Data Firehose waits to receive an acknowledgment
	// from Splunk after it sends data. At the end of the timeout period, Kinesis Data
	// Firehose either tries to send the data again or considers it an error, based on
	// your retry settings.
	HECAcknowledgmentTimeoutInSeconds *int32
	// A GUID that you obtain from your Splunk cluster when you create a new HEC
	// endpoint.
	HECToken *string
	// Your update to the configuration of the backup Amazon S3 location.
	S3Update *S3DestinationUpdate
	// Specifies how you want Kinesis Data Firehose to back up documents to Amazon S3.
	// When set to FailedDocumentsOnly, Kinesis Data Firehose writes any data that
	// could not be indexed to the configured Amazon S3 destination. When set to
	// AllEvents, Kinesis Data Firehose delivers all incoming records to Amazon S3, and
	// also writes failed documents to Amazon S3. The default value is
	// FailedEventsOnly. You can update this backup mode from FailedEventsOnly to
	// AllEvents. You can't update it from AllEvents to FailedEventsOnly.
	S3BackupMode SplunkS3BackupMode
}

// Configures retry behavior in case Kinesis Data Firehose is unable to deliver
// documents to Splunk, or if it doesn't receive an acknowledgment from Splunk.
type SplunkRetryOptions struct {
	// The total amount of time that Kinesis Data Firehose spends on retries. This
	// duration starts after the initial attempt to send data to Splunk fails. It
	// doesn't include the periods during which Kinesis Data Firehose waits for
	// acknowledgment from Splunk after each attempt.
	DurationInSeconds *int32
}

// Metadata that you can assign to a delivery stream, consisting of a key-value
// pair.
type Tag struct {
	// An optional string, which you can use to describe or define the tag. Maximum
	// length: 256 characters. Valid characters: Unicode letters, digits, white space,
	// _ . / = + - % @
	Value *string
	// A unique identifier for the tag. Maximum length: 128 characters. Valid
	// characters: Unicode letters, digits, white space, _ . / = + - % @
	Key *string
}

// The details of the VPC of the Amazon ES destination.
type VpcConfiguration struct {
	// The IDs of the security groups that you want Kinesis Data Firehose to use when
	// it creates ENIs in the VPC of the Amazon ES destination. You can use the same
	// security group that the Amazon ES domain uses or different ones. If you specify
	// different security groups here, ensure that they allow outbound HTTPS traffic to
	// the Amazon ES domain's security group. Also ensure that the Amazon ES domain's
	// security group allows HTTPS traffic from the security groups specified here. If
	// you use the same security group for both your delivery stream and the Amazon ES
	// domain, make sure the security group inbound rule allows HTTPS traffic. For more
	// information about security group rules, see Security group rules
	// (https://docs.aws.amazon.com/vpc/latest/userguide/VPC_SecurityGroups.html#SecurityGroupRules)
	// in the Amazon VPC documentation.
	SecurityGroupIds []*string
	// The IDs of the subnets that you want Kinesis Data Firehose to use to create ENIs
	// in the VPC of the Amazon ES destination. Make sure that the routing tables and
	// inbound and outbound rules allow traffic to flow from the subnets whose IDs are
	// specified here to the subnets that have the destination Amazon ES endpoints.
	// Kinesis Data Firehose creates at least one ENI in each of the subnets that are
	// specified here. Do not delete or modify these ENIs. The number of ENIs that
	// Kinesis Data Firehose creates in the subnets specified here scales up and down
	// automatically based on throughput. To enable Kinesis Data Firehose to scale up
	// the number of ENIs to match throughput, ensure that you have sufficient quota.
	// To help you calculate the quota you need, assume that Kinesis Data Firehose can
	// create up to three ENIs for this delivery stream for each of the subnets
	// specified here. For more information about ENI quota, see Network Interfaces
	// (https://docs.aws.amazon.com/vpc/latest/userguide/amazon-vpc-limits.html#vpc-limits-enis)
	// in the Amazon VPC Quotas topic.
	SubnetIds []*string
	// The ARN of the IAM role that you want the delivery stream to use to create
	// endpoints in the destination VPC. You can use your existing Kinesis Data
	// Firehose delivery role or you can specify a new role. In either case, make sure
	// that the role trusts the Kinesis Data Firehose service principal and that it
	// grants the following permissions:
	//
	//     * ec2:DescribeVpcs
	//
	//     *
	// ec2:DescribeVpcAttribute
	//
	//     * ec2:DescribeSubnets
	//
	//     *
	// ec2:DescribeSecurityGroups
	//
	//     * ec2:DescribeNetworkInterfaces
	//
	//     *
	// ec2:CreateNetworkInterface
	//
	//     * ec2:CreateNetworkInterfacePermission
	//
	//     *
	// ec2:DeleteNetworkInterface
	//
	// If you revoke these permissions after you create the
	// delivery stream, Kinesis Data Firehose can't scale out by creating more ENIs
	// when necessary. You might therefore see a degradation in performance.
	RoleARN *string
}

// The details of the VPC of the Amazon ES destination.
type VpcConfigurationDescription struct {
	// The IDs of the subnets that Kinesis Data Firehose uses to create ENIs in the VPC
	// of the Amazon ES destination. Make sure that the routing tables and inbound and
	// outbound rules allow traffic to flow from the subnets whose IDs are specified
	// here to the subnets that have the destination Amazon ES endpoints. Kinesis Data
	// Firehose creates at least one ENI in each of the subnets that are specified
	// here. Do not delete or modify these ENIs. The number of ENIs that Kinesis Data
	// Firehose creates in the subnets specified here scales up and down automatically
	// based on throughput. To enable Kinesis Data Firehose to scale up the number of
	// ENIs to match throughput, ensure that you have sufficient quota. To help you
	// calculate the quota you need, assume that Kinesis Data Firehose can create up to
	// three ENIs for this delivery stream for each of the subnets specified here. For
	// more information about ENI quota, see Network Interfaces
	// (https://docs.aws.amazon.com/vpc/latest/userguide/amazon-vpc-limits.html#vpc-limits-enis)
	// in the Amazon VPC Quotas topic.
	SubnetIds []*string
	// The IDs of the security groups that Kinesis Data Firehose uses when it creates
	// ENIs in the VPC of the Amazon ES destination. You can use the same security
	// group that the Amazon ES domain uses or different ones. If you specify different
	// security groups, ensure that they allow outbound HTTPS traffic to the Amazon ES
	// domain's security group. Also ensure that the Amazon ES domain's security group
	// allows HTTPS traffic from the security groups specified here. If you use the
	// same security group for both your delivery stream and the Amazon ES domain, make
	// sure the security group inbound rule allows HTTPS traffic. For more information
	// about security group rules, see Security group rules
	// (https://docs.aws.amazon.com/vpc/latest/userguide/VPC_SecurityGroups.html#SecurityGroupRules)
	// in the Amazon VPC documentation.
	SecurityGroupIds []*string
	// The ARN of the IAM role that the delivery stream uses to create endpoints in the
	// destination VPC. You can use your existing Kinesis Data Firehose delivery role
	// or you can specify a new role. In either case, make sure that the role trusts
	// the Kinesis Data Firehose service principal and that it grants the following
	// permissions:
	//
	//     * ec2:DescribeVpcs
	//
	//     * ec2:DescribeVpcAttribute
	//
	//     *
	// ec2:DescribeSubnets
	//
	//     * ec2:DescribeSecurityGroups
	//
	//     *
	// ec2:DescribeNetworkInterfaces
	//
	//     * ec2:CreateNetworkInterface
	//
	//     *
	// ec2:CreateNetworkInterfacePermission
	//
	//     * ec2:DeleteNetworkInterface
	//
	// If you
	// revoke these permissions after you create the delivery stream, Kinesis Data
	// Firehose can't scale out by creating more ENIs when necessary. You might
	// therefore see a degradation in performance.
	RoleARN *string
	// The ID of the Amazon ES destination's VPC.
	VpcId *string
}
