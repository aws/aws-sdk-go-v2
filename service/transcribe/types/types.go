// Code generated by smithy-go-codegen DO NOT EDIT.

package types

import (
	"time"
)

// Settings for content redaction within a transcription job.
type ContentRedaction struct {

	// The output transcript file stored in either the default S3 bucket or in a bucket
	// you specify. When you choose redacted Amazon Transcribe outputs only the
	// redacted transcript. When you choose redacted_and_unredacted Amazon Transcribe
	// outputs both the redacted and unredacted transcripts.
	//
	// This member is required.
	RedactionOutput RedactionOutput

	// Request parameter that defines the entities to be redacted. The only accepted
	// value is PII.
	//
	// This member is required.
	RedactionType RedactionType
}

// The object that contains the Amazon S3 object location and access role required
// to train and tune your custom language model.
type InputDataConfig struct {

	// The Amazon Resource Name (ARN) that uniquely identifies the permissions you've
	// given Amazon Transcribe to access your Amazon S3 buckets containing your media
	// files or text data.
	//
	// This member is required.
	DataAccessRoleArn *string

	// The Amazon S3 prefix you specify to access the plain text files that you use to
	// train your custom language model.
	//
	// This member is required.
	S3Uri *string

	// The Amazon S3 prefix you specify to access the plain text files that you use to
	// tune your custom language model.
	TuningDataS3Uri *string
}

// Provides information about when a transcription job should be executed.
type JobExecutionSettings struct {

	// Indicates whether a job should be queued by Amazon Transcribe when the
	// concurrent execution limit is exceeded. When the AllowDeferredExecution field is
	// true, jobs are queued and executed when the number of executing jobs falls below
	// the concurrent execution limit. If the field is false, Amazon Transcribe returns
	// a LimitExceededException exception. If you specify the AllowDeferredExecution
	// field, you must specify the DataAccessRoleArn field.
	AllowDeferredExecution *bool

	// The Amazon Resource Name (ARN) of a role that has access to the S3 bucket that
	// contains the input files. Amazon Transcribe assumes this role to read queued
	// media files. If you have specified an output S3 bucket for the transcription
	// results, this role should have access to the output bucket as well. If you
	// specify the AllowDeferredExecution field, you must specify the DataAccessRoleArn
	// field.
	DataAccessRoleArn *string
}

// The structure used to describe a custom language model.
type LanguageModel struct {

	// The Amazon Transcribe standard language model, or base model used to create the
	// custom language model.
	BaseModelName BaseModelName

	// The time the custom language model was created.
	CreateTime *time.Time

	// The reason why the custom language model couldn't be created.
	FailureReason *string

	// The data access role and Amazon S3 prefixes for the input files used to train
	// the custom language model.
	InputDataConfig *InputDataConfig

	// The language code you used to create your custom language model.
	LanguageCode CLMLanguageCode

	// The most recent time the custom language model was modified.
	LastModifiedTime *time.Time

	// The name of the custom language model.
	ModelName *string

	// The creation status of a custom language model. When the status is COMPLETED the
	// model is ready for use.
	ModelStatus ModelStatus

	// Whether the base model used for the custom language model is up to date. If this
	// field is true then you are running the most up-to-date version of the base model
	// in your custom language model.
	UpgradeAvailability *bool
}

// Describes the input media file in a transcription request.
type Media struct {

	// The S3 object location of the input media file. The URI must be in the same
	// region as the API endpoint that you are calling. The general form is: For
	// example: For more information about S3 object names, see Object Keys
	// (http://docs.aws.amazon.com/AmazonS3/latest/dev/UsingMetadata.html#object-keys)
	// in the Amazon S3 Developer Guide.
	MediaFileUri *string
}

// Identifies the location of a medical transcript.
type MedicalTranscript struct {

	// The S3 object location of the medical transcript. Use this URI to access the
	// medical transcript. This URI points to the S3 bucket you created to store the
	// medical transcript.
	TranscriptFileUri *string
}

// The data structure that contains the information for a medical transcription
// job.
type MedicalTranscriptionJob struct {

	// A timestamp that shows when the job was completed.
	CompletionTime *time.Time

	// A timestamp that shows when the job was created.
	CreationTime *time.Time

	// If the TranscriptionJobStatus field is FAILED, this field contains information
	// about why the job failed. The FailureReason field contains one of the following
	// values:
	//
	// * Unsupported media format- The media format specified in the
	// MediaFormat field of the request isn't valid. See the description of the
	// MediaFormat field for a list of valid values.
	//
	// * The media format provided does
	// not match the detected media format- The media format of the audio file doesn't
	// match the format specified in the MediaFormat field in the request. Check the
	// media format of your media file and make sure the two values match.
	//
	// * Invalid
	// sample rate for audio file- The sample rate specified in the
	// MediaSampleRateHertz of the request isn't valid. The sample rate must be between
	// 8000 and 48000 Hertz.
	//
	// * The sample rate provided does not match the detected
	// sample rate- The sample rate in the audio file doesn't match the sample rate
	// specified in the MediaSampleRateHertz field in the request. Check the sample
	// rate of your media file and make sure that the two values match.
	//
	// * Invalid file
	// size: file size too large- The size of your audio file is larger than what
	// Amazon Transcribe Medical can process. For more information, see Guidelines and
	// Quotas
	// (https://docs.aws.amazon.com/transcribe/latest/dg/limits-guidelines.html#limits)
	// in the Amazon Transcribe Medical Guide
	//
	// * Invalid number of channels: number of
	// channels too large- Your audio contains more channels than Amazon Transcribe
	// Medical is configured to process. To request additional channels, see Amazon
	// Transcribe Medical Endpoints and Quotas
	// (https://docs.aws.amazon.com/general/latest/gr/transcribe-medical.html) in the
	// Amazon Web Services General Reference
	FailureReason *string

	// The language code for the language spoken in the source audio file. US English
	// (en-US) is the only supported language for medical transcriptions. Any other
	// value you enter for language code results in a BadRequestException error.
	LanguageCode LanguageCode

	// Describes the input media file in a transcription request.
	Media *Media

	// The format of the input media file.
	MediaFormat MediaFormat

	// The sample rate, in Hertz, of the source audio containing medical information.
	// If you don't specify the sample rate, Amazon Transcribe Medical determines it
	// for you. If you choose to specify the sample rate, it must match the rate
	// detected by Amazon Transcribe Medical. In most cases, you should leave the
	// MediaSampleHertz blank and let Amazon Transcribe Medical determine the sample
	// rate.
	MediaSampleRateHertz *int32

	// The name for a given medical transcription job.
	MedicalTranscriptionJobName *string

	// Object that contains object.
	Settings *MedicalTranscriptionSetting

	// The medical specialty of any clinicians providing a dictation or having a
	// conversation. PRIMARYCARE is the only available setting for this object. This
	// specialty enables you to generate transcriptions for the following medical
	// fields:
	//
	// * Family Medicine
	Specialty Specialty

	// A timestamp that shows when the job started processing.
	StartTime *time.Time

	// An object that contains the MedicalTranscript. The MedicalTranscript contains
	// the TranscriptFileUri.
	Transcript *MedicalTranscript

	// The completion status of a medical transcription job.
	TranscriptionJobStatus TranscriptionJobStatus

	// The type of speech in the transcription job. CONVERSATION is generally used for
	// patient-physician dialogues. DICTATION is the setting for physicians speaking
	// their notes after seeing a patient. For more information, see how-it-works-med
	Type Type
}

// Provides summary information about a transcription job.
type MedicalTranscriptionJobSummary struct {

	// A timestamp that shows when the job was completed.
	CompletionTime *time.Time

	// A timestamp that shows when the medical transcription job was created.
	CreationTime *time.Time

	// If the TranscriptionJobStatus field is FAILED, a description of the error.
	FailureReason *string

	// The language of the transcript in the source audio file.
	LanguageCode LanguageCode

	// The name of a medical transcription job.
	MedicalTranscriptionJobName *string

	// Indicates the location of the transcription job's output. The CUSTOMER_BUCKET is
	// the S3 location provided in the OutputBucketName field when the
	OutputLocationType OutputLocationType

	// The medical specialty of the transcription job. Primary care is the only valid
	// value.
	Specialty Specialty

	// A timestamp that shows when the job began processing.
	StartTime *time.Time

	// The status of the medical transcription job.
	TranscriptionJobStatus TranscriptionJobStatus

	// The speech of the clinician in the input audio.
	Type Type
}

// Optional settings for the StartMedicalTranscriptionJob operation.
type MedicalTranscriptionSetting struct {

	// Instructs Amazon Transcribe Medical to process each audio channel separately and
	// then merge the transcription output of each channel into a single transcription.
	// Amazon Transcribe Medical also produces a transcription of each item detected on
	// an audio channel, including the start time and end time of the item and
	// alternative transcriptions of item. The alternative transcriptions also come
	// with confidence scores provided by Amazon Transcribe Medical. You can't set both
	// ShowSpeakerLabels and ChannelIdentification in the same request. If you set
	// both, your request returns a BadRequestException
	ChannelIdentification *bool

	// The maximum number of alternatives that you tell the service to return. If you
	// specify the MaxAlternatives field, you must set the ShowAlternatives field to
	// true.
	MaxAlternatives *int32

	// The maximum number of speakers to identify in the input audio. If there are more
	// speakers in the audio than this number, multiple speakers are identified as a
	// single speaker. If you specify the MaxSpeakerLabels field, you must set the
	// ShowSpeakerLabels field to true.
	MaxSpeakerLabels *int32

	// Determines whether alternative transcripts are generated along with the
	// transcript that has the highest confidence. If you set ShowAlternatives field to
	// true, you must also set the maximum number of alternatives to return in the
	// MaxAlternatives field.
	ShowAlternatives *bool

	// Determines whether the transcription job uses speaker recognition to identify
	// different speakers in the input audio. Speaker recognition labels individual
	// speakers in the audio file. If you set the ShowSpeakerLabels field to true, you
	// must also set the maximum number of speaker labels in the MaxSpeakerLabels
	// field. You can't set both ShowSpeakerLabels and ChannelIdentification in the
	// same request. If you set both, your request returns a BadRequestException.
	ShowSpeakerLabels *bool

	// The name of the vocabulary to use when processing a medical transcription job.
	VocabularyName *string
}

// The object used to call your custom language model to your transcription job.
type ModelSettings struct {

	// The name of your custom language model.
	LanguageModelName *string
}

// Provides optional settings for the StartTranscriptionJob operation.
type Settings struct {

	// Instructs Amazon Transcribe to process each audio channel separately and then
	// merge the transcription output of each channel into a single transcription.
	// Amazon Transcribe also produces a transcription of each item detected on an
	// audio channel, including the start time and end time of the item and alternative
	// transcriptions of the item including the confidence that Amazon Transcribe has
	// in the transcription. You can't set both ShowSpeakerLabels and
	// ChannelIdentification in the same request. If you set both, your request returns
	// a BadRequestException.
	ChannelIdentification *bool

	// The number of alternative transcriptions that the service should return. If you
	// specify the MaxAlternatives field, you must set the ShowAlternatives field to
	// true.
	MaxAlternatives *int32

	// The maximum number of speakers to identify in the input audio. If there are more
	// speakers in the audio than this number, multiple speakers are identified as a
	// single speaker. If you specify the MaxSpeakerLabels field, you must set the
	// ShowSpeakerLabels field to true.
	MaxSpeakerLabels *int32

	// Determines whether the transcription contains alternative transcriptions. If you
	// set the ShowAlternatives field to true, you must also set the maximum number of
	// alternatives to return in the MaxAlternatives field.
	ShowAlternatives *bool

	// Determines whether the transcription job uses speaker recognition to identify
	// different speakers in the input audio. Speaker recognition labels individual
	// speakers in the audio file. If you set the ShowSpeakerLabels field to true, you
	// must also set the maximum number of speaker labels MaxSpeakerLabels field. You
	// can't set both ShowSpeakerLabels and ChannelIdentification in the same request.
	// If you set both, your request returns a BadRequestException.
	ShowSpeakerLabels *bool

	// Set to mask to remove filtered text from the transcript and replace it with
	// three asterisks ("***") as placeholder text. Set to remove to remove filtered
	// text from the transcript without using placeholder text.
	VocabularyFilterMethod VocabularyFilterMethod

	// The name of the vocabulary filter to use when transcribing the audio. The filter
	// that you specify must have the same language code as the transcription job.
	VocabularyFilterName *string

	// The name of a vocabulary to use when processing the transcription job.
	VocabularyName *string
}

// Identifies the location of a transcription.
type Transcript struct {

	// The S3 object location of the redacted transcript. Use this URI to access the
	// redacted transcript. If you specified an S3 bucket in the OutputBucketName field
	// when you created the job, this is the URI of that bucket. If you chose to store
	// the transcript in Amazon Transcribe, this is a shareable URL that provides
	// secure access to that location.
	RedactedTranscriptFileUri *string

	// The S3 object location of the transcript. Use this URI to access the transcript.
	// If you specified an S3 bucket in the OutputBucketName field when you created the
	// job, this is the URI of that bucket. If you chose to store the transcript in
	// Amazon Transcribe, this is a shareable URL that provides secure access to that
	// location.
	TranscriptFileUri *string
}

// Describes an asynchronous transcription job that was created with the
// StartTranscriptionJob operation.
type TranscriptionJob struct {

	// A timestamp that shows when the job was completed.
	CompletionTime *time.Time

	// An object that describes content redaction settings for the transcription job.
	ContentRedaction *ContentRedaction

	// A timestamp that shows when the job was created.
	CreationTime *time.Time

	// If the TranscriptionJobStatus field is FAILED, this field contains information
	// about why the job failed. The FailureReason field can contain one of the
	// following values:
	//
	// * Unsupported media format - The media format specified in
	// the MediaFormat field of the request isn't valid. See the description of the
	// MediaFormat field for a list of valid values.
	//
	// * The media format provided does
	// not match the detected media format - The media format of the audio file doesn't
	// match the format specified in the MediaFormat field in the request. Check the
	// media format of your media file and make sure that the two values match.
	//
	// *
	// Invalid sample rate for audio file - The sample rate specified in the
	// MediaSampleRateHertz of the request isn't valid. The sample rate must be between
	// 8000 and 48000 Hertz.
	//
	// * The sample rate provided does not match the detected
	// sample rate - The sample rate in the audio file doesn't match the sample rate
	// specified in the MediaSampleRateHertz field in the request. Check the sample
	// rate of your media file and make sure that the two values match.
	//
	// * Invalid file
	// size: file size too large - The size of your audio file is larger than Amazon
	// Transcribe can process. For more information, see Limits
	// (https://docs.aws.amazon.com/transcribe/latest/dg/limits-guidelines.html#limits)
	// in the Amazon Transcribe Developer Guide.
	//
	// * Invalid number of channels: number
	// of channels too large - Your audio contains more channels than Amazon Transcribe
	// is configured to process. To request additional channels, see Amazon Transcribe
	// Limits
	// (https://docs.aws.amazon.com/general/latest/gr/aws_service_limits.html#limits-amazon-transcribe)
	// in the Amazon Web Services General Reference.
	FailureReason *string

	// A value between zero and one that Amazon Transcribe assigned to the language
	// that it identified in the source audio. Larger values indicate that Amazon
	// Transcribe has higher confidence in the language it identified.
	IdentifiedLanguageScore *float32

	// A value that shows if automatic language identification was enabled for a
	// transcription job.
	IdentifyLanguage *bool

	// Provides information about how a transcription job is executed.
	JobExecutionSettings *JobExecutionSettings

	// The language code for the input speech.
	LanguageCode LanguageCode

	// An object that shows the optional array of languages inputted for transcription
	// jobs with automatic language identification enabled.
	LanguageOptions []LanguageCode

	// An object that describes the input media for the transcription job.
	Media *Media

	// The format of the input media file.
	MediaFormat MediaFormat

	// The sample rate, in Hertz, of the audio track in the input media file.
	MediaSampleRateHertz *int32

	// An object containing the details of your custom language model.
	ModelSettings *ModelSettings

	// Optional settings for the transcription job. Use these settings to turn on
	// speaker recognition, to set the maximum number of speakers that should be
	// identified and to specify a custom vocabulary to use when processing the
	// transcription job.
	Settings *Settings

	// A timestamp that shows with the job was started processing.
	StartTime *time.Time

	// An object that describes the output of the transcription job.
	Transcript *Transcript

	// The name of the transcription job.
	TranscriptionJobName *string

	// The status of the transcription job.
	TranscriptionJobStatus TranscriptionJobStatus
}

// Provides a summary of information about a transcription job.
type TranscriptionJobSummary struct {

	// A timestamp that shows when the job was completed.
	CompletionTime *time.Time

	// The content redaction settings of the transcription job.
	ContentRedaction *ContentRedaction

	// A timestamp that shows when the job was created.
	CreationTime *time.Time

	// If the TranscriptionJobStatus field is FAILED, a description of the error.
	FailureReason *string

	// A value between zero and one that Amazon Transcribe assigned to the language it
	// identified in the source audio. A higher score indicates that Amazon Transcribe
	// is more confident in the language it identified.
	IdentifiedLanguageScore *float32

	// Whether automatic language identification was enabled for a transcription job.
	IdentifyLanguage *bool

	// The language code for the input speech.
	LanguageCode LanguageCode

	// The object used to call your custom language model to your transcription job.
	ModelSettings *ModelSettings

	// Indicates the location of the output of the transcription job. If the value is
	// CUSTOMER_BUCKET then the location is the S3 bucket specified in the
	// outputBucketName field when the transcription job was started with the
	// StartTranscriptionJob operation. If the value is SERVICE_BUCKET then the output
	// is stored by Amazon Transcribe and can be retrieved using the URI in the
	// GetTranscriptionJob response's TranscriptFileUri field.
	OutputLocationType OutputLocationType

	// A timestamp that shows when the job started processing.
	StartTime *time.Time

	// The name of the transcription job.
	TranscriptionJobName *string

	// The status of the transcription job. When the status is COMPLETED, use the
	// GetTranscriptionJob operation to get the results of the transcription.
	TranscriptionJobStatus TranscriptionJobStatus
}

// Provides information about a vocabulary filter.
type VocabularyFilterInfo struct {

	// The language code of the words in the vocabulary filter.
	LanguageCode LanguageCode

	// The date and time that the vocabulary was last updated.
	LastModifiedTime *time.Time

	// The name of the vocabulary filter. The name must be unique in the account that
	// holds the filter.
	VocabularyFilterName *string
}

// Provides information about a custom vocabulary.
type VocabularyInfo struct {

	// The language code of the vocabulary entries.
	LanguageCode LanguageCode

	// The date and time that the vocabulary was last modified.
	LastModifiedTime *time.Time

	// The name of the vocabulary.
	VocabularyName *string

	// The processing state of the vocabulary. If the state is READY you can use the
	// vocabulary in a StartTranscriptionJob request.
	VocabularyState VocabularyState
}
