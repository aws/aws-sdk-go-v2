// Code generated by smithy-go-codegen DO NOT EDIT.

package machinelearning

import (
	"context"
	awsmiddleware "github.com/aws/aws-sdk-go-v2/aws/middleware"
	"github.com/aws/aws-sdk-go-v2/aws/retry"
	"github.com/aws/aws-sdk-go-v2/aws/signer/v4"
	smithy "github.com/awslabs/smithy-go"
	"github.com/awslabs/smithy-go/middleware"
	smithyhttp "github.com/awslabs/smithy-go/transport/http"
)

// Generates predictions for a group of observations. The observations to process
// exist in one or more data files referenced by a DataSource. This operation
// creates a new BatchPrediction, and uses an MLModel and the data files referenced
// by the DataSource as information sources.  <p>
// <code>CreateBatchPrediction</code> is an asynchronous operation. In response to
// <code>CreateBatchPrediction</code>, Amazon Machine Learning (Amazon ML)
// immediately returns and sets the <code>BatchPrediction</code> status to
// <code>PENDING</code>. After the <code>BatchPrediction</code> completes, Amazon
// ML sets the status to <code>COMPLETED</code>. </p> <p>You can poll for status
// updates by using the <a>GetBatchPrediction</a> operation and checking the
// <code>Status</code> parameter of the result. After the <code>COMPLETED</code>
// status appears, the results are available in the location specified by the
// <code>OutputUri</code> parameter.</p>
func (c *Client) CreateBatchPrediction(ctx context.Context, params *CreateBatchPredictionInput, optFns ...func(*Options)) (*CreateBatchPredictionOutput, error) {
	stack := middleware.NewStack("CreateBatchPrediction", smithyhttp.NewStackRequest)
	options := c.options.Copy()
	for _, fn := range optFns {
		fn(&options)
	}
	addawsAwsjson11_serdeOpCreateBatchPredictionMiddlewares(stack)
	awsmiddleware.AddRequestInvocationIDMiddleware(stack)
	smithyhttp.AddContentLengthMiddleware(stack)
	AddResolveEndpointMiddleware(stack, options)
	v4.AddComputePayloadSHA256Middleware(stack)
	retry.AddRetryMiddlewares(stack, options)
	addHTTPSignerV4Middleware(stack, options)
	awsmiddleware.AddAttemptClockSkewMiddleware(stack)
	addClientUserAgent(stack)
	smithyhttp.AddErrorCloseResponseBodyMiddleware(stack)
	smithyhttp.AddCloseResponseBodyMiddleware(stack)
	addOpCreateBatchPredictionValidationMiddleware(stack)
	stack.Initialize.Add(newServiceMetadataMiddleware_opCreateBatchPrediction(options.Region), middleware.Before)

	for _, fn := range options.APIOptions {
		if err := fn(stack); err != nil {
			return nil, err
		}
	}
	handler := middleware.DecorateHandler(smithyhttp.NewClientHandler(options.HTTPClient), stack)
	result, metadata, err := handler.Handle(ctx, params)
	if err != nil {
		return nil, &smithy.OperationError{
			ServiceID:     ServiceID,
			OperationName: "CreateBatchPrediction",
			Err:           err,
		}
	}
	out := result.(*CreateBatchPredictionOutput)
	out.ResultMetadata = metadata
	return out, nil
}

type CreateBatchPredictionInput struct {
	// A user-supplied ID that uniquely identifies the BatchPrediction.
	BatchPredictionId *string
	// The location of an Amazon Simple Storage Service (Amazon S3) bucket or directory
	// to store the batch prediction results. The following substrings are not allowed
	// in the s3 key portion of the outputURI field: ':', '//', '/./', '/../'. Amazon
	// ML needs permissions to store and retrieve the logs on your behalf. For
	// information about how to set permissions, see the Amazon Machine Learning
	// Developer Guide (https://docs.aws.amazon.com/machine-learning/latest/dg).
	OutputUri *string
	// A user-supplied name or description of the BatchPrediction. BatchPredictionName
	// can only use the UTF-8 character set.
	BatchPredictionName *string
	// The ID of the DataSource that points to the group of observations to predict.
	BatchPredictionDataSourceId *string
	// The ID of the MLModel that will generate predictions for the group of
	// observations.
	MLModelId *string
}

// Represents the output of a CreateBatchPrediction operation, and is an
// acknowledgement that Amazon ML received the request. The CreateBatchPrediction
// operation is asynchronous. You can poll for status updates by using the
// >GetBatchPrediction operation and checking the Status parameter of the result.
type CreateBatchPredictionOutput struct {
	// A user-supplied ID that uniquely identifies the BatchPrediction. This value is
	// identical to the value of the BatchPredictionId in the request.
	BatchPredictionId *string

	// Metadata pertaining to the operation's result.
	ResultMetadata middleware.Metadata
}

func addawsAwsjson11_serdeOpCreateBatchPredictionMiddlewares(stack *middleware.Stack) {
	stack.Serialize.Add(&awsAwsjson11_serializeOpCreateBatchPrediction{}, middleware.After)
	stack.Deserialize.Add(&awsAwsjson11_deserializeOpCreateBatchPrediction{}, middleware.After)
}

func newServiceMetadataMiddleware_opCreateBatchPrediction(region string) awsmiddleware.RegisterServiceMetadata {
	return awsmiddleware.RegisterServiceMetadata{
		Region:        region,
		ServiceID:     ServiceID,
		SigningName:   "machinelearning",
		OperationName: "CreateBatchPrediction",
	}
}
