// Code generated by smithy-go-codegen DO NOT EDIT.

package rekognition

import (
	"context"
	awsmiddleware "github.com/aws/aws-sdk-go-v2/aws/middleware"
	"github.com/aws/aws-sdk-go-v2/aws/retry"
	"github.com/aws/aws-sdk-go-v2/aws/signer/v4"
	"github.com/aws/aws-sdk-go-v2/service/rekognition/types"
	smithy "github.com/awslabs/smithy-go"
	"github.com/awslabs/smithy-go/middleware"
	smithyhttp "github.com/awslabs/smithy-go/transport/http"
)

// Starts asynchronous detection of unsafe content in a stored video. Amazon
// Rekognition Video can moderate content in a video stored in an Amazon S3 bucket.
// Use Video () to specify the bucket name and the filename of the video.
// StartContentModeration returns a job identifier (JobId) which you use to get the
// results of the analysis. When unsafe content analysis is finished, Amazon
// Rekognition Video publishes a completion status to the Amazon Simple
// Notification Service topic that you specify in NotificationChannel. To get the
// results of the unsafe content analysis, first check that the status value
// published to the Amazon SNS topic is SUCCEEDED. If so, call GetContentModeration
// () and pass the job identifier (JobId) from the initial call to
// StartContentModeration.  <p>For more information, see Detecting Unsafe Content
// in the Amazon Rekognition Developer Guide.</p>
func (c *Client) StartContentModeration(ctx context.Context, params *StartContentModerationInput, optFns ...func(*Options)) (*StartContentModerationOutput, error) {
	stack := middleware.NewStack("StartContentModeration", smithyhttp.NewStackRequest)
	options := c.options.Copy()
	for _, fn := range optFns {
		fn(&options)
	}
	addawsAwsjson11_serdeOpStartContentModerationMiddlewares(stack)
	awsmiddleware.AddRequestInvocationIDMiddleware(stack)
	smithyhttp.AddContentLengthMiddleware(stack)
	AddResolveEndpointMiddleware(stack, options)
	v4.AddComputePayloadSHA256Middleware(stack)
	retry.AddRetryMiddlewares(stack, options)
	addHTTPSignerV4Middleware(stack, options)
	awsmiddleware.AddAttemptClockSkewMiddleware(stack)
	addClientUserAgent(stack)
	smithyhttp.AddErrorCloseResponseBodyMiddleware(stack)
	smithyhttp.AddCloseResponseBodyMiddleware(stack)
	addOpStartContentModerationValidationMiddleware(stack)
	stack.Initialize.Add(newServiceMetadataMiddleware_opStartContentModeration(options.Region), middleware.Before)

	for _, fn := range options.APIOptions {
		if err := fn(stack); err != nil {
			return nil, err
		}
	}
	handler := middleware.DecorateHandler(smithyhttp.NewClientHandler(options.HTTPClient), stack)
	result, metadata, err := handler.Handle(ctx, params)
	if err != nil {
		return nil, &smithy.OperationError{
			ServiceID:     ServiceID,
			OperationName: "StartContentModeration",
			Err:           err,
		}
	}
	out := result.(*StartContentModerationOutput)
	out.ResultMetadata = metadata
	return out, nil
}

type StartContentModerationInput struct {
	// Specifies the minimum confidence that Amazon Rekognition must have in order to
	// return a moderated content label. Confidence represents how certain Amazon
	// Rekognition is that the moderated content is correctly identified. 0 is the
	// lowest confidence. 100 is the highest confidence. Amazon Rekognition doesn't
	// return any moderated content labels with a confidence level lower than this
	// specified value. If you don't specify MinConfidence, GetContentModeration
	// returns labels with confidence values greater than or equal to 50 percent.
	MinConfidence *float32
	// The video in which you want to detect unsafe content. The video must be stored
	// in an Amazon S3 bucket.
	Video *types.Video
	// An identifier you specify that's returned in the completion notification that's
	// published to your Amazon Simple Notification Service topic. For example, you can
	// use JobTag to group related jobs and identify them in the completion
	// notification.
	JobTag *string
	// The Amazon SNS topic ARN that you want Amazon Rekognition Video to publish the
	// completion status of the unsafe content analysis to.
	NotificationChannel *types.NotificationChannel
	// Idempotent token used to identify the start request. If you use the same token
	// with multiple StartContentModeration requests, the same JobId is returned. Use
	// ClientRequestToken to prevent the same job from being accidently started more
	// than once.
	ClientRequestToken *string
}

type StartContentModerationOutput struct {
	// The identifier for the unsafe content analysis job. Use JobId to identify the
	// job in a subsequent call to GetContentModeration.
	JobId *string

	// Metadata pertaining to the operation's result.
	ResultMetadata middleware.Metadata
}

func addawsAwsjson11_serdeOpStartContentModerationMiddlewares(stack *middleware.Stack) {
	stack.Serialize.Add(&awsAwsjson11_serializeOpStartContentModeration{}, middleware.After)
	stack.Deserialize.Add(&awsAwsjson11_deserializeOpStartContentModeration{}, middleware.After)
}

func newServiceMetadataMiddleware_opStartContentModeration(region string) awsmiddleware.RegisterServiceMetadata {
	return awsmiddleware.RegisterServiceMetadata{
		Region:        region,
		ServiceID:     ServiceID,
		SigningName:   "rekognition",
		OperationName: "StartContentModeration",
	}
}
