// Code generated by smithy-go-codegen DO NOT EDIT.

package rekognition

import (
	"context"
	awsmiddleware "github.com/aws/aws-sdk-go-v2/aws/middleware"
	"github.com/aws/aws-sdk-go-v2/aws/retry"
	"github.com/aws/aws-sdk-go-v2/aws/signer/v4"
	"github.com/aws/aws-sdk-go-v2/service/rekognition/types"
	smithy "github.com/awslabs/smithy-go"
	"github.com/awslabs/smithy-go/middleware"
	smithyhttp "github.com/awslabs/smithy-go/transport/http"
)

// Returns an array of celebrities recognized in the input image. For more
// information, see Recognizing Celebrities in the Amazon Rekognition Developer
// Guide. RecognizeCelebrities returns the 100 largest faces in the image. It lists
// recognized celebrities in the CelebrityFaces array and unrecognized faces in the
// UnrecognizedFaces array. RecognizeCelebrities doesn't return celebrities whose
// faces aren't among the largest 100 faces in the image.  <p>For each celebrity
// recognized, <code>RecognizeCelebrities</code> returns a <code>Celebrity</code>
// object. The <code>Celebrity</code> object contains the celebrity name, ID, URL
// links to additional information, match confidence, and a
// <code>ComparedFace</code> object that you can use to locate the celebrity's face
// on the image.</p> <p>Amazon Rekognition doesn't retain information about which
// images a celebrity has been recognized in. Your application must store this
// information and use the <code>Celebrity</code> ID property as a unique
// identifier for the celebrity. If you don't store the celebrity name or
// additional information URLs returned by <code>RecognizeCelebrities</code>, you
// will need the ID to identify the celebrity in a call to the
// <a>GetCelebrityInfo</a> operation.</p> <p>You pass the input image either as
// base64-encoded image bytes or as a reference to an image in an Amazon S3 bucket.
// If you use the AWS CLI to call Amazon Rekognition operations, passing image
// bytes is not supported. The image must be either a PNG or JPEG formatted file.
// </p> <p>For an example, see Recognizing Celebrities in an Image in the Amazon
// Rekognition Developer Guide.</p> <p>This operation requires permissions to
// perform the <code>rekognition:RecognizeCelebrities</code> operation.</p>
func (c *Client) RecognizeCelebrities(ctx context.Context, params *RecognizeCelebritiesInput, optFns ...func(*Options)) (*RecognizeCelebritiesOutput, error) {
	stack := middleware.NewStack("RecognizeCelebrities", smithyhttp.NewStackRequest)
	options := c.options.Copy()
	for _, fn := range optFns {
		fn(&options)
	}
	addawsAwsjson11_serdeOpRecognizeCelebritiesMiddlewares(stack)
	awsmiddleware.AddRequestInvocationIDMiddleware(stack)
	smithyhttp.AddContentLengthMiddleware(stack)
	AddResolveEndpointMiddleware(stack, options)
	v4.AddComputePayloadSHA256Middleware(stack)
	retry.AddRetryMiddlewares(stack, options)
	addHTTPSignerV4Middleware(stack, options)
	awsmiddleware.AddAttemptClockSkewMiddleware(stack)
	addClientUserAgent(stack)
	smithyhttp.AddErrorCloseResponseBodyMiddleware(stack)
	smithyhttp.AddCloseResponseBodyMiddleware(stack)
	addOpRecognizeCelebritiesValidationMiddleware(stack)
	stack.Initialize.Add(newServiceMetadataMiddleware_opRecognizeCelebrities(options.Region), middleware.Before)

	for _, fn := range options.APIOptions {
		if err := fn(stack); err != nil {
			return nil, err
		}
	}
	handler := middleware.DecorateHandler(smithyhttp.NewClientHandler(options.HTTPClient), stack)
	result, metadata, err := handler.Handle(ctx, params)
	if err != nil {
		return nil, &smithy.OperationError{
			ServiceID:     ServiceID,
			OperationName: "RecognizeCelebrities",
			Err:           err,
		}
	}
	out := result.(*RecognizeCelebritiesOutput)
	out.ResultMetadata = metadata
	return out, nil
}

type RecognizeCelebritiesInput struct {
	// The input image as base64-encoded bytes or an S3 object. If you use the AWS CLI
	// to call Amazon Rekognition operations, passing base64-encoded image bytes is not
	// supported. If you are using an AWS SDK to call Amazon Rekognition, you might not
	// need to base64-encode image bytes passed using the Bytes field. For more
	// information, see Images in the Amazon Rekognition developer guide.
	Image *types.Image
}

type RecognizeCelebritiesOutput struct {
	// Details about each unrecognized face in the image.
	UnrecognizedFaces []*types.ComparedFace
	// The orientation of the input image (counterclockwise direction). If your
	// application displays the image, you can use this value to correct the
	// orientation. The bounding box coordinates returned in CelebrityFaces and
	// UnrecognizedFaces represent face locations before the image orientation is
	// corrected. If the input image is in .jpeg format, it might contain exchangeable
	// image (Exif) metadata that includes the image's orientation. If so, and the Exif
	// metadata for the input image populates the orientation field, the value of
	// OrientationCorrection is null. The CelebrityFaces and UnrecognizedFaces bounding
	// box coordinates represent face locations after Exif metadata is used to correct
	// the image orientation. Images in .png format don't contain Exif metadata.
	OrientationCorrection types.OrientationCorrection
	// Details about each celebrity found in the image. Amazon Rekognition can detect a
	// maximum of 15 celebrities in an image.
	CelebrityFaces []*types.Celebrity

	// Metadata pertaining to the operation's result.
	ResultMetadata middleware.Metadata
}

func addawsAwsjson11_serdeOpRecognizeCelebritiesMiddlewares(stack *middleware.Stack) {
	stack.Serialize.Add(&awsAwsjson11_serializeOpRecognizeCelebrities{}, middleware.After)
	stack.Deserialize.Add(&awsAwsjson11_deserializeOpRecognizeCelebrities{}, middleware.After)
}

func newServiceMetadataMiddleware_opRecognizeCelebrities(region string) awsmiddleware.RegisterServiceMetadata {
	return awsmiddleware.RegisterServiceMetadata{
		Region:        region,
		ServiceID:     ServiceID,
		SigningName:   "rekognition",
		OperationName: "RecognizeCelebrities",
	}
}
